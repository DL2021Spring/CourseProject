is_const=True, is_virtual=True)
cls.add_method('IsBridge',
'bool',
[],
is_const=True, is_virtual=True)
cls.add_method('IsPromisc',
'bool',
[])
cls.add_method('NotifyPromiscTrace',
'void',
[param('ns3::Ptr< ns3::Packet >', 'p')])
cls.add_method('DoSend',
'bool',
[param('ns3::Ptr< ns3::Packet >', 'packet'), param('ns3::Mac48Address const &', 'source'), param('ns3::Mac48Address const &', 'dest'), param('uint16_t', 'protocolNumber')],
is_pure_virtual=True, visibility='private', is_virtual=True)
cls.add_method('DoReceive',
'void',
[param('ns3::Ptr< ns3::Packet >', 'packet')],
is_pure_virtual=True, visibility='private', is_virtual=True)
cls.add_method('DoGetChannel',
'ns3::Ptr< ns3::WimaxChannel >',
[],
is_const=True, visibility='private', is_virtual=True)
return
def register_Ns3AddressChecker_methods(root_module, cls):
cls.add_constructor([])
cls.add_constructor([param('ns3::AddressChecker const &', 'arg0')])
return
def register_Ns3AddressValue_methods(root_module, cls):
cls.add_constructor([])
cls.add_constructor([param('ns3::AddressValue const &', 'arg0')])
cls.add_constructor([param('ns3::Address const &', 'value')])
cls.add_method('Copy',
'ns3::Ptr< ns3::AttributeValue >',
[],
is_const=True, is_virtual=True)
cls.add_method('DeserializeFromString',
'bool',
[param('std::string', 'value'), param('ns3::Ptr< ns3::AttributeChecker const >', 'checker')],
is_virtual=True)
cls.add_method('Get',
'ns3::Address',
[],
is_const=True)
cls.add_method('SerializeToString',
'std::string',
[param('ns3::Ptr< ns3::AttributeChecker const >', 'checker')],
is_const=True, is_virtual=True)
cls.add_method('Set',
'void',
[param('ns3::Address const &', 'value')])
return
def register_Ns3BaseStationNetDevice_methods(root_module, cls):
cls.add_method('GetTypeId',
'ns3::TypeId',
[],
is_static=True)
cls.add_constructor([])
cls.add_constructor([param('ns3::Ptr< ns3::Node >', 'node'), param('ns3::Ptr< ns3::WimaxPhy >', 'phy')])
cls.add_constructor([param('ns3::Ptr< ns3::Node >', 'node'), param('ns3::Ptr< ns3::WimaxPhy >', 'phy'), param('ns3::Ptr< ns3::UplinkScheduler >', 'uplinkScheduler'), param('ns3::Ptr< ns3::BSScheduler >', 'bsScheduler')])
cls.add_method('SetInitialRangingInterval',
'void',
[param('ns3::Time', 'initialRangInterval')])
cls.add_method('InitBaseStationNetDevice',
'void',
[])
cls.add_method('GetInitialRangingInterval',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetDcdInterval',
'void',
[param('ns3::Time', 'dcdInterval')])
cls.add_method('GetDcdInterval',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetUcdInterval',
'void',
[param('ns3::Time', 'ucdInterval')])
cls.add_method('GetUcdInterval',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetIntervalT8',
'void',
[param('ns3::Time', 'interval')])
cls.add_method('GetIntervalT8',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetMaxRangingCorrectionRetries',
'void',
[param('uint8_t', 'maxRangCorrectionRetries')])
cls.add_method('GetMaxRangingCorrectionRetries',
'uint8_t',
[],
is_const=True)
cls.add_method('SetMaxInvitedRangRetries',
'void',
[param('uint8_t', 'maxInvitedRangRetries')])
cls.add_method('GetMaxInvitedRangRetries',
'uint8_t',
[],
is_const=True)
cls.add_method('SetRangReqOppSize',
'void',
[param('uint8_t', 'rangReqOppSize')])
cls.add_method('GetRangReqOppSize',
'uint8_t',
[],
is_const=True)
cls.add_method('SetBwReqOppSize',
'void',
[param('uint8_t', 'bwReqOppSize')])
cls.add_method('GetBwReqOppSize',
'uint8_t',
[],
is_const=True)
cls.add_method('SetNrDlSymbols',
'void',
[param('uint32_t', 'dlSymbols')])
cls.add_method('GetNrDlSymbols',
'uint32_t',
[],
is_const=True)
cls.add_method('SetNrUlSymbols',
'void',
[param('uint32_t', 'ulSymbols')])
cls.add_method('GetNrUlSymbols',
'uint32_t',
[],
is_const=True)
cls.add_method('GetNrDcdSent',
'uint32_t',
[],
is_const=True)
cls.add_method('GetNrUcdSent',
'uint32_t',
[],
is_const=True)
cls.add_method('GetDlSubframeStartTime',
'ns3::Time',
[],
is_const=True)
cls.add_method('GetUlSubframeStartTime',
'ns3::Time',
[],
is_const=True)
cls.add_method('GetRangingOppNumber',
'uint8_t',
[],
is_const=True)
cls.add_method('GetSSManager',
'ns3::Ptr< ns3::SSManager >',
[],
is_const=True)
cls.add_method('SetSSManager',
'void',
[param('ns3::Ptr< ns3::SSManager >', 'ssManager')])
cls.add_method('GetUplinkScheduler',
'ns3::Ptr< ns3::UplinkScheduler >',
[],
is_const=True)
cls.add_method('SetUplinkScheduler',
'void',
[param('ns3::Ptr< ns3::UplinkScheduler >', 'ulScheduler')])
cls.add_method('GetLinkManager',
'ns3::Ptr< ns3::BSLinkManager >',
[],
is_const=True)
cls.add_method('SetBSScheduler',
'void',
[param('ns3::Ptr< ns3::BSScheduler >', 'bsSchedule')])
cls.add_method('GetBSScheduler',
'ns3::Ptr< ns3::BSScheduler >',
[],
is_const=True)
cls.add_method('SetLinkManager',
'void',
[param('ns3::Ptr< ns3::BSLinkManager >', 'linkManager')])
cls.add_method('GetBsClassifier',
'ns3::Ptr< ns3::IpcsClassifier >',
[],
is_const=True)
cls.add_method('SetBsClassifier',
'void',
[param('ns3::Ptr< ns3::IpcsClassifier >', 'classifier')])
cls.add_method('GetPsDuration',
'ns3::Time',
[],
is_const=True)
cls.add_method('GetSymbolDuration',
'ns3::Time',
[],
is_const=True)
cls.add_method('Start',
'void',
[],
is_virtual=True)
cls.add_method('Stop',
'void',
[],
is_virtual=True)
cls.add_method('Enqueue',
'bool',
[param('ns3::Ptr< ns3::Packet >', 'packet'), param('ns3::MacHeaderType const &', 'hdrType'), param('ns3::Ptr< ns3::WimaxConnection >', 'connection')],
is_virtual=True)
cls.add_method('GetConnection',
'ns3::Ptr< ns3::WimaxConnection >',
[param('ns3::Cid', 'cid')])
cls.add_method('MarkUplinkAllocations',
'void',
[])
cls.add_method('MarkRangingOppStart',
'void',
[param('ns3::Time', 'rangingOppStartTime')])
cls.add_method('GetServiceFlowManager',
'ns3::Ptr< ns3::BsServiceFlowManager >',
[],
is_const=True)
cls.add_method('SetServiceFlowManager',
'void',
[param('ns3::Ptr< ns3::BsServiceFlowManager >', 'arg0')])
cls.add_method('DoDispose',
'void',
[],
visibility='private', is_virtual=True)
cls.add_method('DoSend',
'bool',
[param('ns3::Ptr< ns3::Packet >', 'packet'), param('ns3::Mac48Address const &', 'source'), param('ns3::Mac48Address const &', 'dest'), param('uint16_t', 'protocolNumber')],
visibility='private', is_virtual=True)
cls.add_method('DoReceive',
'void',
[param('ns3::Ptr< ns3::Packet >', 'packet')],
visibility='private', is_virtual=True)
return
def register_Ns3SimpleOfdmWimaxChannel_methods(root_module, cls):
cls.add_constructor([param('ns3::SimpleOfdmWimaxChannel const &', 'arg0')])
cls.add_constructor([])
cls.add_constructor([param('ns3::SimpleOfdmWimaxChannel::PropModel', 'propModel')])
cls.add_method('Send',
'void',
[param('ns3::Time', 'BlockTime'), param('uint32_t', 'burstSize'), param('ns3::Ptr< ns3::WimaxPhy >', 'phy'), param('bool', 'isFirstBlock'), param('bool', 'isLastBlock'), param('uint64_t', 'frequency'), param('ns3::WimaxPhy::ModulationType', 'modulationType'), param('uint8_t', 'direction'), param('double', 'txPowerDbm'), param('ns3::Ptr< ns3::PacketBurst >', 'burst')])
cls.add_method('SetPropagationModel',
'void',
[param('ns3::SimpleOfdmWimaxChannel::PropModel', 'propModel')])
cls.add_method('DoAttach',
'void',
[param('ns3::Ptr< ns3::WimaxPhy >', 'phy')],
visibility='private', is_virtual=True)
cls.add_method('DoGetDevice',
'ns3::Ptr< ns3::NetDevice >',
[param('uint32_t', 'i')],
is_const=True, visibility='private', is_virtual=True)
cls.add_method('DoGetNDevices',
'uint32_t',
[],
is_const=True, visibility='private', is_virtual=True)
return
def register_Ns3SubscriberStationNetDevice_methods(root_module, cls):
cls.add_instance_attribute('m_linkManager', 'ns3::Ptr< ns3::SSLinkManager >', is_const=False)
cls.add_method('GetTypeId',
'ns3::TypeId',
[],
is_static=True)
cls.add_constructor([])
cls.add_constructor([param('ns3::Ptr< ns3::Node >', 'arg0'), param('ns3::Ptr< ns3::WimaxPhy >', 'arg1')])
cls.add_method('InitSubscriberStationNetDevice',
'void',
[])
cls.add_method('SetLostDlMapInterval',
'void',
[param('ns3::Time', 'lostDlMapInterval')])
cls.add_method('GetLostDlMapInterval',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetLostUlMapInterval',
'void',
[param('ns3::Time', 'lostUlMapInterval')])
cls.add_method('GetLostUlMapInterval',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetMaxDcdInterval',
'void',
[param('ns3::Time', 'maxDcdInterval')])
cls.add_method('GetMaxDcdInterval',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetMaxUcdInterval',
'void',
[param('ns3::Time', 'maxUcdInterval')])
cls.add_method('GetMaxUcdInterval',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetIntervalT1',
'void',
[param('ns3::Time', 'interval1')])
cls.add_method('GetIntervalT1',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetIntervalT2',
'void',
[param('ns3::Time', 'interval2')])
cls.add_method('GetIntervalT2',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetIntervalT3',
'void',
[param('ns3::Time', 'interval3')])
cls.add_method('GetIntervalT3',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetIntervalT7',
'void',
[param('ns3::Time', 'interval7')])
cls.add_method('GetIntervalT7',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetIntervalT12',
'void',
[param('ns3::Time', 'interval12')])
cls.add_method('GetIntervalT12',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetIntervalT20',
'void',
[param('ns3::Time', 'interval20')])
cls.add_method('GetIntervalT20',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetIntervalT21',
'void',
[param('ns3::Time', 'interval21')])
cls.add_method('GetIntervalT21',
'ns3::Time',
[],
is_const=True)
cls.add_method('SetMaxContentionRangingRetries',
'void',
[param('uint8_t', 'maxContentionRangingRetries')])
cls.add_method('GetMaxContentionRangingRetries',
'uint8_t',
[],
is_const=True)
cls.add_method('SetBasicConnection',
'void',
[param('ns3::Ptr< ns3::WimaxConnection >', 'basicConnection')])
cls.add_method('GetBasicConnection',
'ns3::Ptr< ns3::WimaxConnection >',
[],
is_const=True)
cls.add_method('SetPrimaryConnection',
'void',
[param('ns3::Ptr< ns3::WimaxConnection >', 'primaryConnection')])
cls.add_method('GetPrimaryConnection',
'ns3::Ptr< ns3::WimaxConnection >',
[],
is_const=True)
cls.add_method('GetBasicCid',
'ns3::Cid',
[],
is_const=True)
cls.add_method('GetPrimaryCid',
'ns3::Cid',
[],
is_const=True)
cls.add_method('SetModulationType',
'void',
[param('ns3::WimaxPhy::ModulationType', 'modulationType')])
cls.add_method('GetModulationType',
'ns3::WimaxPhy::ModulationType',
[],
is_const=True)
cls.add_method('SetAreManagementConnectionsAllocated',
'void',
[param('bool', 'areManagementConnectionsAllocated')])
cls.add_method('GetAreManagementConnectionsAllocated',
'bool',
[],
is_const=True)
cls.add_method('SetAreServiceFlowsAllocated',
'void',
[param('bool', 'areServiceFlowsAllocated')])
cls.add_method('GetAreServiceFlowsAllocated',
'bool',
[],
is_const=True)
cls.add_method('GetScheduler',
'ns3::Ptr< ns3::SSScheduler >',
[],
is_const=True)
cls.add_method('SetScheduler',
'void',
[param('ns3::Ptr< ns3::SSScheduler >', 'ssScheduler')])
cls.add_method('HasServiceFlows',
'bool',
[],
is_const=True)
cls.add_method('Enqueue',
'bool',
[param('ns3::Ptr< ns3::Packet >', 'packet'), param('ns3::MacHeaderType const &', 'hdrType'), param('ns3::Ptr< ns3::WimaxConnection >', 'connection')],
is_virtual=True)
cls.add_method('SendBurst',
'void',
[param('uint8_t', 'uiuc'), param('uint16_t', 'nrSymbols'), param('ns3::Ptr< ns3::WimaxConnection >', 'connection'), param('ns3::MacHeaderType::HeaderType', 'packetType', default_value='::ns3::MacHeaderType::HEADER_TYPE_GENERIC')])
cls.add_method('Start',
'void',
[],
is_virtual=True)
cls.add_method('Stop',
'void',
[],
is_virtual=True)
cls.add_method('AddServiceFlow',
'void',
[param('ns3::ServiceFlow *', 'sf')])
cls.add_method('AddServiceFlow',
'void',
[param('ns3::ServiceFlow', 'sf')])
cls.add_method('SetTimer',
'void',
[param('ns3::EventId', 'eventId'), param('ns3::EventId &', 'event')])
cls.add_method('IsRegistered',
'bool',
[],
is_const=True)
cls.add_method('GetTimeToAllocation',
'ns3::Time',
[param('ns3::Time', 'defferTime')])
cls.add_method('GetIpcsClassifier',
'ns3::Ptr< ns3::IpcsClassifier >',
[],
is_const=True)
cls.add_method('SetIpcsPacketClassifier',
'void',
[param('ns3::Ptr< ns3::IpcsClassifier >', 'arg0')])
cls.add_method('GetLinkManager',
'ns3::Ptr< ns3::SSLinkManager >',
[],
is_const=True)
cls.add_method('SetLinkManager',
'void',
[param('ns3::Ptr< ns3::SSLinkManager >', 'arg0')])
cls.add_method('GetServiceFlowManager',
'ns3::Ptr< ns3::SsServiceFlowManager >',
[],
is_const=True)
cls.add_method('SetServiceFlowManager',
'void',
[param('ns3::Ptr< ns3::SsServiceFlowManager >', 'arg0')])
cls.add_method('DoDispose',
'void',
[],
visibility='private', is_virtual=True)
cls.add_method('DoSend',
'bool',
[param('ns3::Ptr< ns3::Packet >', 'packet'), param('ns3::Mac48Address const &', 'source'), param('ns3::Mac48Address const &', 'dest'), param('uint16_t', 'protocolNumber')],
visibility='private', is_virtual=True)
cls.add_method('DoReceive',
'void',
[param('ns3::Ptr< ns3::Packet >', 'packet')],
visibility='private', is_virtual=True)
return
def register_functions(root_module):
module = root_module
module.add_function('CRC8Calculate',
'uint8_t',
[param('uint8_t const *', 'data'), param('int', 'length')])
register_functions_ns3_FatalImpl(module.get_submodule('FatalImpl'), root_module)
register_functions_ns3_internal(module.get_submodule('internal'), root_module)
return
def register_functions_ns3_FatalImpl(module, root_module):
return
def register_functions_ns3_internal(module, root_module):
return
def main():
out = FileCodeSink(sys.stdout)
root_module = module_init()
register_types(root_module)
register_methods(root_module)
register_functions(root_module)
root_module.generate(out)
if __name__ == '__main__':
main()
from pybindgen import Module, FileCodeSink, write_preamble, param, retval
def register_types(module):
module.add_class('MyClass')
def register_methods(root_module):
MyClass = root_module['MyClass']
MyClass.add_constructor([], visibility='public')
MyClass.add_constructor([param('double', 's'), param('double', 'l'), param('double', 'mean')], visibility='public')
def register_functions(module):
module.add_function('SomeFunction', 'int', [param('int', 'xpto')])
MOD = 10 ** 9
class Solution(object):
def solve(self, n):
result = []
comb = 1
result.append(comb)
for i in xrange(1, n + 1):
comb = comb * (n + 1 - i) / i
result.append(comb % MOD)
return " ".join(map(str, result))
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = int(f.readline().strip())
s = "%s\n" % (Solution().solve(cipher))
print s,
import numpy as np
import math
from sklearn.neighbors import NearestNeighbors as nn
from facerec_py.facerec.feature import *
from facerec_py.facerec.util import *
class train():
def __init__(self):
self.mat = []
self.labels = []
self.dim = 0
self.N = 0
self.totalClass = 0
class NDAFisher(AbstractFeature):
def __init__(self, num_components=100):
AbstractFeature.__init__(self)
self._num_components = num_components
def compute(self, X, y):
nda = NDA()
pca = PCA(self._num_components)
model = ChainOperator(pca, nda)
model.compute(X, y)
self._eigenvectors = np.dot(pca.eigenvectors, nda.W.T)
features = []
for x in X:
xp = self.project(x.reshape(-1, 1))
features.append(xp)
return features
def extract(self, X):
X = np.asarray(X).reshape(-1, 1)
return self.project(X)
def project(self, X):
return np.dot(self._eigenvectors.T, X)
class NDA(AbstractFeature):
def __init__(self):
AbstractFeature.__init__(self)
def compute(self, X, y, K=1, useweights=0):
self.train = train()
self.train.mat = np.array(X)
self.train.mat = asColumnMatrix(X)
self.train.labels = y
self.train.N = np.size(X, 0)
self.train.dim = np.size(X, 1)
self.train.totalClass = len(np.unique(y))
self.K = K
self.dim = np.size(X, 1)
self.origdim = self.train.dim
self.N = np.size(X, 0)
self.totalClass = self.train.totalClass
self.meandata = np.mean(self.train.mat, 1, dtype='float64')
self.train.mat = self.train.mat - np.dot(self.meandata, np.ones((1, self.train.N)))
self.indIn = np.zeros((K, self.N))
self.indEx = np.zeros((K, self.N))
self.valIn = np.zeros((K, self.N))
self.valEx = np.zeros((K, self.N))
self.compute_within_class_matrix_whitening()
self.mnnInn = self.compute_within_class_scatter_matrix()
self.diffIntra = self.train.mat - self.mnnInn
self.Wscat = np.dot(self.diffIntra, self.diffIntra.transpose())/self.diffIntra.shape[1]
self.eval, self.evec = np.linalg.eig(self.Wscat)
self.ind = np.argsort(self.eval, 0)
self.eval = self.eval[self.ind]
self.eval = np.flipud(self.eval)
self.ind = np.flipud(self.ind)
self.evec = self.evec[:, self.ind]
self.wdim = np.max(np.nonzero(self.eval > math.pow(10, -8))).real
self.evec = self.evec[:, 0:self.wdim]
self.whiteMat = np.dot(np.diag(1/np.sqrt(self.eval[0:self.wdim])), self.evec.transpose())
self.Wtr = np.dot(self.whiteMat, self.train.mat)
self.compute_bet_class_cluster_dist()
self.mnnEx = self.compute_bet_class_cluster_matrix()
self.diffExtra = self.Wtr - self.mnnEx
if useweights:
self.weights = np.minimum(self.valIn[self.K-1, :], self.valEx[self.K-1, :])
temp = np.ones((self.Wtr.shape[1],))
temp = np.dot(temp, self.weights)
temp = temp * self.diffExtra
self.bscat = np.dot(temp, np.transpose(self.diffExtra)) / self.N
else:
self.bscat = np.dot(self.diffExtra, self.diffExtra.conj().transpose())/self.N
self.eigval, self.evec = np.linalg.eig(self.bscat)
self.ind = np.argsort(self.eigval)
self.val = self.eigval[self.ind]
self.ind = np.flipud(self.ind)
self.eigval = self.eigval[self.ind]
self.eigvec = self.evec[:, self.ind[0:min(self.dim, self.wdim)]]
self.mat = np.dot(self.eigvec.conj().transpose(), self.Wtr)
self.W = np.dot(self.eigvec.conj().transpose(), self.whiteMat)
self.proymat = self.W
features = []
for x in X:
xp = self.project(x.reshape(-1, 1))
features.append(xp)
return features
def compute_bet_class_cluster_dist(self):
for x in np.unique(self.train.labels):
who_cl = np.where(self.train.labels == x)[0]
who_notcl = np.where((self.train.labels != x))[0]
self.data_intra = self.Wtr[:, who_cl]
self.data_extra = self.Wtr[:, who_notcl]
knn = nn().fit(self.data_extra.transpose())
self.dextra, self.indextra = knn.kneighbors(self.data_intra.transpose())
self.dextra = self.dextra.transpose()
self.indextra = self.indextra.transpose()
self.indEx[:, who_cl] = who_notcl[self.indextra[1, :]]
self.valEx[:, who_cl] = self.dextra[1, :]
def compute_bet_class_cluster_matrix(self):
if self.K == 1:
mnnEx = self.Wtr[:, map(lambda x: int(x), self.indEx[0, :])]
else:
mnnEx = np.zeros((np.size(self.Wtr, 0), self.train.N))
for n in range(0, self.train.N):
mnnEx[:, n] == np.mean(self.Wtr[:, map(lambda x: int(x), self.indEx[:, n])], 1)
return mnnEx
def compute_within_class_matrix_whitening(self):
for x in np.unique(self.train.labels):
who_cl = np.where(self.train.labels == x)[0]
self.data_intra = self.train.mat[:, who_cl]
knn = nn().fit(self.data_intra.transpose())
self.dintra, self.indintra = knn.kneighbors(self.data_intra.transpose())
self.dintra = self.dintra.transpose()
self.indintra = self.indintra.transpose()
self.dintra[self.K, :] = []
self.indintra[self.K, :] = []
self.valIn[:, who_cl] = self.dintra[1, :]
self.indIn[:, who_cl] = who_cl[self.indintra[1, :]]
def compute_within_class_scatter_matrix(self):
if self.K == 1:
mnnInn = self.train.mat[:, map(lambda x: int(x), self.indIn[0])]
else:
mnnInn = np.zeros((self.train.dim, self.train.N))
for n in range(0, self.train.N):
mean = np.mean(self.train.mat[:, map(lambda x: int(x), self.indIn[:, n])], 1)
for x in range(0, self.train.dim):
mnnInn[x, n] = mean[x]
return mnnInn
def extract(self, X):
X = np.asarray(X).reshape(-1, 1)
return self.project(X)
def project(self, X):
return np.dot(self.W, X)
def __repr__(self):
return "NDA"
from argparse import ArgumentParser
from os.path import join as path_join
from os.path import dirname
try:
from json import dumps
except ImportError:
from sys import path as sys_path
sys_path.append(path_join(dirname(__file__), '../server/lib/ujson'))
from ujson import dumps
from subprocess import PIPE, Popen
from random import choice, randint
from sys import stderr
from urlparse import urlparse
try:
from urlparse import parse_qs
except ImportError:
from cgi import parse_qs
from BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler
import re
from sentencesplit import sentencebreaks_to_newlines
from BIOtoStandoff import BIO_lines_to_standoff
DOCUMENT_BOUNDARY = 'END-DOCUMENT'
NERSUITE_SCRIPT   = path_join(dirname(__file__), './nersuite_tag.sh')
NERSUITE_COMMAND  = [NERSUITE_SCRIPT, '-multidoc', DOCUMENT_BOUNDARY]
ARGPARSER = ArgumentParser(description='An example HTTP tagging service using NERsuite')
ARGPARSER.add_argument('-p', '--port', type=int, default=47111,
help='port to run the HTTP service on (default: 47111)')
tagger_process = None
def run_tagger(cmd):
global tagger_process
try:
tagger_process = Popen(cmd, stdin=PIPE, stdout=PIPE, bufsize=1)
except Exception, e:
print >> stderr, "Error running '%s':" % cmd, e
raise
def _apply_tagger(text):
global tagger_process, tagger_queue
try:
splittext = sentencebreaks_to_newlines(text)
except:
print >> stderr, "Warning: sentence splitting failed for input:\n'%s'" % text
splittext = text
print >> tagger_process.stdin, splittext
print >> tagger_process.stdin, DOCUMENT_BOUNDARY
tagger_process.stdin.flush()
response_lines = []
while True:
l = tagger_process.stdout.readline()
l = l.rstrip('\n')
if l == DOCUMENT_BOUNDARY:
break
response_lines.append(l)
try:
tagged_entities = BIO_lines_to_standoff(response_lines, text)
except:
print >> stderr, "Warning: BIO-to-standoff conversion failed for BIO:\n'%s'" % '\n'.join(response_lines)
return {}
anns = {}
for t in tagged_entities:
anns["T%d" % t.idNum] = {
'type': t.eType,
'offsets': ((t.startOff, t.endOff), ),
'texts': (t.eText, ),
}
return anns
class NERsuiteTaggerHandler(BaseHTTPRequestHandler):
def do_GET(self):
query = parse_qs(urlparse(self.path).query)
try:
json_dic = _apply_tagger(query['text'][0])
except KeyError:
json_dic = {}
self.send_response(200)
self.send_header('Content-type', 'application/json; charset=utf-8')
self.end_headers()
self.wfile.write(dumps(json_dic))
print >> stderr, ('Generated %d annotations' % len(json_dic))
def log_message(self, format, *args):
return
def main(args):
argp = ARGPARSER.parse_args(args[1:])
print >> stderr, 'Starting NERsuite ...'
run_tagger(NERSUITE_COMMAND)
server_class = HTTPServer
httpd = server_class(('localhost', argp.port), NERsuiteTaggerHandler)
print >> stderr, 'NERsuite tagger service started'
try:
httpd.serve_forever()
except KeyboardInterrupt:
pass
httpd.server_close()
print >> stderr, 'NERsuite tagger service stopped'
if __name__ == '__main__':
from sys import argv
exit(main(argv))
import numpy as np
def minmax(X, low, high, minX=None, maxX=None, dtype=np.float):
X = np.asarray(X)
if minX is None:
minX = np.min(X)
if maxX is None:
maxX = np.max(X)
X -= float(minX)
X /= float((maxX - minX))
X = X * (high - low)
X = X + low
return np.asarray(X, dtype=dtype)
def zscore(X, mean=None, std=None):
X = np.asarray(X)
if mean is None:
mean = X.mean()
if std is None:
std = X.std()
X = (X - mean) / std
return X
def gaussian(X, mu, sig):
return (1/(sig*np.sqrt(2*np.pi)))*\
np.exp(-(X-mu)**2/(2*sig**2))
def inverse_dissim(X):
X = np.asarray(X)
X = zscore(X)
X = minmax(X, 0, 10)
return 1./(1+X)
def vector_normalize(x):
return x / np.linalg.norm(x)
def gaussian_kernel(X, mu=None, sig=None):
X = np.asarray(X)
if mu is None:
mu = X.mean()
if sig is None:
sig = X.std()
return np.exp(-np.power(X-mu, 2)/(2*sig**2))
from __future__ import with_statement
import sys
import codecs
from datetime import datetime
from os.path import dirname, basename, splitext, join
import sqlite3 as sqlite
try:
import simstring
except ImportError:
errorstr =
print >> sys.stderr, errorstr
sys.exit(1)
DEFAULT_INPUT_ENCODING = 'UTF-8'
NORM_DB_STRING = 'NORM_DB_VERSION'
NORM_DB_VERSION = '1.0.1'
SQL_DB_FILENAME_EXTENSION = 'db'
SS_DB_FILENAME_EXTENSION = 'ss.db'
DEFAULT_NGRAM_LENGTH = 3
DEFAULT_INCLUDE_MARKS = False
MAX_ERROR_LINES = 100
TYPE_VALUES = ["name", "attr", "info"]
TABLE_FOR_TYPE = {
"name" : "names",
"attr" : "attributes",
"info" : "infos",
}
TABLE_HAS_NORMVALUE = {
"names" : True,
"attributes" : True,
"infos" : False,
}
assert set(TYPE_VALUES) == set(TABLE_FOR_TYPE.keys())
assert set(TABLE_FOR_TYPE.values()) == set(TABLE_HAS_NORMVALUE.keys())
CREATE_TABLE_COMMANDS = [
,
,
,
,
,
]
CREATE_INDEX_COMMANDS = [
"CREATE INDEX entities_uid ON entities (uid);",
"CREATE INDEX names_value ON names (value);",
"CREATE INDEX names_normvalue ON names (normvalue);",
"CREATE INDEX names_entity_id ON names (entity_id);",
"CREATE INDEX attributes_value ON attributes (value);",
"CREATE INDEX attributes_normvalue ON attributes (normvalue);",
"CREATE INDEX attributes_entity_id ON attributes (entity_id);",
"CREATE INDEX infos_entity_id ON infos (entity_id);",
]
SELECT_SIMSTRING_STRINGS_COMMAND =
def string_norm_form(s):
return s.lower().strip().replace('-', ' ')
def default_db_dir():
sys.path.append(join(dirname(__file__), '..'))
try:
from config import WORK_DIR
return WORK_DIR
except ImportError:
print >> sys.stderr, "Warning: failed to determine brat work directory, using current instead."
return "."
def argparser():
import argparse
ap=argparse.ArgumentParser(description="Create normalization DBs for given file")
ap.add_argument("-v", "--verbose", default=False, action="store_true", help="Verbose output")
ap.add_argument("-d", "--database", default=None, help="Base name of databases to create (default by input file name in brat work directory)")
ap.add_argument("-e", "--encoding", default=DEFAULT_INPUT_ENCODING, help="Input text encoding (default "+DEFAULT_INPUT_ENCODING+")")
ap.add_argument("file", metavar="FILE", help="Normalization data")
return ap
def sqldb_filename(dbname):
return join(default_db_dir(), dbname+'.'+SQL_DB_FILENAME_EXTENSION)
def ssdb_filename(dbname):
return join(default_db_dir(), dbname+'.'+SS_DB_FILENAME_EXTENSION)
def main(argv):
arg = argparser().parse_args(argv[1:])
assert DEFAULT_NGRAM_LENGTH == 3, "Error: unsupported n-gram length"
assert DEFAULT_INCLUDE_MARKS == False, "Error: begin/end marks not supported"
infn = arg.file
if arg.database is None:
bn = splitext(basename(infn))[0]
sqldbfn = sqldb_filename(bn)
ssdbfn = ssdb_filename(bn)
else:
sqldbfn = arg.database+'.'+SQL_DB_FILENAME_EXTENSION
ssdbfn = arg.database+'.'+SS_DB_FILENAME_EXTENSION
if arg.verbose:
print >> sys.stderr, "Storing SQL DB as %s and" % sqldbfn
print >> sys.stderr, "  simstring DB as %s" % ssdbfn
start_time = datetime.now()
import_count, duplicate_count, error_count, simstring_count = 0, 0, 0, 0
with codecs.open(infn, 'rU', encoding=arg.encoding) as inf:
try:
connection = sqlite.connect(sqldbfn)
except sqlite.OperationalError, e:
print >> sys.stderr, "Error connecting to DB %s:" % sqldbfn, e
return 1
cursor = connection.cursor()
if arg.verbose:
print >> sys.stderr, "Creating tables ...",
for command in CREATE_TABLE_COMMANDS:
try:
cursor.execute(command)
except sqlite.OperationalError, e:
print >> sys.stderr, "Error creating %s:" % sqldbfn, e, "(DB exists?)"
return 1
if arg.verbose:
print >> sys.stderr, "done."
print >> sys.stderr, "Importing data ...",
next_eid = 1
label_id = {}
next_lid = 1
next_pid = dict([(t,1) for t in TYPE_VALUES])
for i, l in enumerate(inf):
l = l.rstrip('\n')
try:
id_, rest = l.split('\t', 1)
except ValueError:
if error_count < MAX_ERROR_LINES:
print >> sys.stderr, "Error: skipping line %d: expected tab-separated fields, got '%s'" % (i+1, l)
elif error_count == MAX_ERROR_LINES:
print >> sys.stderr, "(Too many errors; suppressing further error messages)"
error_count += 1
continue
try:
triples = []
for triple in rest.split('\t'):
type_, label, string = triple.split(':', 2)
if type_ not in TYPE_VALUES:
print >> sys.stderr, "Unknown TYPE %s" % type_
triples.append((type_, label, string))
except ValueError:
if error_count < MAX_ERROR_LINES:
print >> sys.stderr, "Error: skipping line %d: expected tab-separated TYPE:LABEL:STRING triples, got '%s'" % (i+1, rest)
elif error_count == MAX_ERROR_LINES:
print >> sys.stderr, "(Too many errors; suppressing further error messages)"
error_count += 1
continue
eid = next_eid
next_eid += 1
try:
cursor.execute("INSERT into entities VALUES (?, ?)", (eid, id_))
except sqlite.IntegrityError, e:
if error_count < MAX_ERROR_LINES:
print >> sys.stderr, "Error inserting %s (skipping): %s" % (id_, e)
elif error_count == MAX_ERROR_LINES:
print >> sys.stderr, "(Too many errors; suppressing further error messages)"
error_count += 1
continue
labels = set([l for t,l,s in triples])
new_labels = [l for l in labels if l not in label_id]
for label in new_labels:
lid = next_lid
next_lid += 1
cursor.execute("INSERT into labels VALUES (?, ?)", (lid, label))
label_id[label] = lid
for type_, label, string in triples:
table = TABLE_FOR_TYPE[type_]
pid = next_pid[type_]
next_pid[type_] += 1
lid = label_id[label]
if TABLE_HAS_NORMVALUE[table]:
normstring = string_norm_form(string)
cursor.execute("INSERT into %s VALUES (?, ?, ?, ?, ?)" % table,
(pid, eid, lid, string, normstring))
else:
cursor.execute("INSERT into %s VALUES (?, ?, ?, ?)" % table,
(pid, eid, lid, string))
import_count += 1
if arg.verbose and (i+1)%10000 == 0:
print >> sys.stderr, '.',
if arg.verbose:
print >> sys.stderr, "done."
if arg.verbose:
print >> sys.stderr, "Creating indices ...",
for command in CREATE_INDEX_COMMANDS:
try:
cursor.execute(command)
except sqlite.OperationalError, e:
print >> sys.stderr, "Error creating index", e
return 1
if arg.verbose:
print >> sys.stderr, "done."
connection.commit()
if arg.verbose:
print >> sys.stderr, "Creating simstring DB ...",
try:
ssdb = simstring.writer(ssdbfn)
for row in cursor.execute(SELECT_SIMSTRING_STRINGS_COMMAND):
s = row[0].encode('utf-8')
ssdb.insert(s)
simstring_count += 1
ssdb.close()
except:
print >> sys.stderr, "Error building simstring DB"
raise
if arg.verbose:
print >> sys.stderr, "done."
cursor.close()
delta = datetime.now() - start_time
if arg.verbose:
print >> sys.stderr
print >> sys.stderr, "Done in:", str(delta.seconds)+"."+str(delta.microseconds/10000), "seconds"
print "Done, imported %d entries (%d strings), skipped %d duplicate keys, skipped %d invalid lines" % (import_count, simstring_count, duplicate_count, error_count)
return 0
if __name__ == "__main__":
sys.exit(main(sys.argv))
import sys
import os.path
import sqlite3 as sqlite
TYPE_TABLES = ["names", "attributes", "infos"]
NON_EMPTY_TABLES = set(["names"])
def argparser():
import argparse
ap=argparse.ArgumentParser(description="Print results of lookup in normalization SQL DB for keys read from STDIN.")
ap.add_argument("-v", "--verbose", default=False, action="store_true", help="Verbose output.")
ap.add_argument("-np", "--no-prompt", default=False, action="store_true", help="No prompt.")
ap.add_argument("database", metavar="DATABASE", help="Name of database to read")
return ap
def string_norm_form(s):
return s.lower().strip().replace('-', ' ')
def datas_by_ids(cursor, ids):
responses = {}
for table in TYPE_TABLES:
command =  % (table, ','.join(['?' for i in ids]))
cursor.execute(command, list(ids))
response = cursor.fetchall()
for id_, label, value in response:
if id_ not in responses:
responses[id_] = {}
if table not in responses[id_]:
responses[id_][table] = []
responses[id_][table].append([label, value])
if (table in NON_EMPTY_TABLES and
len([i for i in responses if responses[i][table] == 0]) != 0):
return None
for id_ in responses:
for t in NON_EMPTY_TABLES:
if len(responses[id_][t]) == 0:
return None
datas = {}
for id_ in responses:
datas[id_] = []
for t in TYPE_TABLES:
datas[id_].append(responses[id_].get(t,[]))
return datas
def ids_by_name(cursor, name, exactmatch=False, return_match=False):
return ids_by_names(cursor, [name], exactmatch, return_match)
def ids_by_names(cursor, names, exactmatch=False, return_match=False):
if not return_match:
command = 'SELECT E.uid'
else:
command = 'SELECT E.uid, N.value'
command +=
if exactmatch:
command += 'WHERE N.value IN (%s)' % ','.join(['?' for n in names])
else:
command += 'WHERE N.normvalue IN (%s)' % ','.join(['?' for n in names])
names = [string_norm_form(n) for n in names]
cursor.execute(command, names)
responses = cursor.fetchall()
if not return_match:
return [r[0] for r in responses]
else:
return [(r[0],r[1]) for r in responses]
def main(argv):
arg = argparser().parse_args(argv[1:])
dbn = arg.database
dbpaths = [dbn, os.path.join('work', dbn), os.path.join('work', dbn)+'.db']
dbfn = None
for p in dbpaths:
if os.path.exists(p):
dbfn = p
break
if dbfn is None:
print >> sys.stderr, "Error: %s: no such file" % dbfn
return 1
try:
connection = sqlite.connect(dbfn)
except sqlite.OperationalError, e:
print >> sys.stderr, "Error connecting to DB %s:" % dbfn, e
return 1
cursor = connection.cursor()
while True:
if not arg.no_prompt:
print ">>> ",
l = sys.stdin.readline()
if not l:
break
l = l.rstrip()
try:
r = ids_by_name(cursor, l)
if len(r) != 0:
d = datas_by_ids(cursor, r)
for i in d:
print i+'\t', '\t'.join([' '.join(["%s:%s" % (k,v) for k,v in a]) for a in d[i]])
elif l == '':
print "(Use Ctrl-D to exit)"
else:
print "(no record found for '%s')" % l
except Exception, e:
print >> sys.stderr, "Unexpected error", e
return 1
return 0
if __name__ == "__main__":
sys.exit(main(sys.argv))
import warnings
import sys
import os
import pybindgen.settings
from pybindgen import Module, FileCodeSink, param, retval, cppclass, typehandlers
from pybindgen.module import MultiSectionFactory
import ns3modulegen_core_customizations
pybindgen.settings.wrapper_registry = pybindgen.settings.StdMapWrapperRegistry
class ErrorHandler(pybindgen.settings.ErrorHandler):
def handle_error(self, wrapper, exception, traceback_):
warnings.warn("exception %r in wrapper %s" % (exception, wrapper))
return True
pybindgen.settings.error_handler = ErrorHandler()
pybindgen.settings.gcc_rtti_abi_complete = bool(eval(os.environ["GCC_RTTI_ABI_COMPLETE"]))
class MyMultiSectionFactory(MultiSectionFactory):
def __init__(self, main_file_name):
super(MyMultiSectionFactory, self).__init__()
self.main_file_name = main_file_name
self.main_sink = FileCodeSink(open(main_file_name, "wt"))
self.header_name = "ns3module.h"
header_file_name = os.path.join(os.path.dirname(self.main_file_name), self.header_name)
self.header_sink = FileCodeSink(open(header_file_name, "wt"))
def get_section_code_sink(self, section_name):
return self.main_sink
def get_main_code_sink(self):
return self.main_sink
def get_common_header_code_sink(self):
return self.header_sink
def get_common_header_include(self):
return '"%s"' % self.header_name
def close(self):
self.header_sink.file.close()
self.main_sink.file.close()
def main(argv):
module_abs_src_path, target, extension_name, output_cc_file_name = argv[1:]
module_name = os.path.basename(module_abs_src_path)
out = MyMultiSectionFactory(output_cc_file_name)
sys.path.insert(0, os.path.join(module_abs_src_path, "bindings"))
try:
module_apidefs = __import__("modulegen__%s" % target)
del sys.modules["modulegen__%s" % target]
try:
module_customization = __import__("modulegen_customizations")
del sys.modules["modulegen_customizations"]
except ImportError:
module_customization = object()
try:
from callbacks_list import callback_classes
except ImportError, ex:
print >> sys.stderr, "***************", repr(ex)
callback_classes = []
else:
print >> sys.stderr, ">>>>>>>>>>>>>>>>", repr(callback_classes)
finally:
sys.path.pop(0)
root_module = module_apidefs.module_init()
root_module.set_name(extension_name)
root_module.add_include('"ns3/%s-module.h"' % module_name)
ns3modulegen_core_customizations.add_std_ios_openmode(root_module)
module_apidefs.register_types(root_module)
if hasattr(module_customization, 'post_register_types'):
module_customization.post_register_types(root_module)
ns3modulegen_core_customizations.generate_callback_classes(root_module.after_forward_declarations,
callback_classes)
module_apidefs.register_methods(root_module)
if hasattr(module_customization, 'post_register_methods'):
module_customization.post_register_methods(root_module)
ns3modulegen_core_customizations.Object_customizations(root_module)
ns3modulegen_core_customizations.Attribute_customizations(root_module)
module_apidefs.register_functions(root_module)
if hasattr(module_customization, 'post_register_functions'):
module_customization.post_register_functions(root_module)
root_module.generate(out)
if __name__ == '__main__':
import sys
main(sys.argv)
LOCAL_MODULES = [
]
import sys
import os
sys.path.insert(0, sys.argv[2])
from pybindgen import FileCodeSink, write_preamble
from pybindgen.module import MultiSectionFactory
import pybindgen.settings
pybindgen.settings.deprecated_virtuals = False
from ns3modulegen_generated import module_init, register_types, register_methods, register_functions
import ns3modulegen_core_customizations
import callbacks_list
import traceback
this_script_dir = os.path.dirname(os.path.abspath(sys.argv[0]))
class ErrorHandler(pybindgen.settings.ErrorHandler):
def handle_error(self, wrapper, exception, traceback_):
print >> sys.stderr
print >> sys.stderr, "---- location:"
traceback.print_stack()
print >> sys.stderr, "---- error:"
traceback.print_tb(traceback_)
try:
stack = wrapper.stack_where_defined
except AttributeError:
print >> sys.stderr, "??:??: %s / %r" % (wrapper, exception)
else:
stack = list(stack)
stack.reverse()
for (filename, line_number, function_name, text) in stack:
file_dir = os.path.dirname(os.path.abspath(filename))
if file_dir.startswith(this_script_dir):
print >> sys.stderr, "%s:%i: %r" % (os.path.join("..", "bindings", "python", os.path.basename(filename)),
line_number, exception)
break
return True
pybindgen.settings.error_handler = ErrorHandler()
pybindgen.settings.wrapper_registry = pybindgen.settings.StdMapWrapperRegistry
class MyMultiSectionFactory(MultiSectionFactory):
def __init__(self, main_file_name, modules):
super(MyMultiSectionFactory, self).__init__()
self.main_file_name = main_file_name
self.main_sink = FileCodeSink(open(main_file_name, "wt"))
self.header_name = "ns3module.h"
header_file_name = os.path.join(os.path.dirname(self.main_file_name), 'pch', self.header_name)
self.header_sink = FileCodeSink(open(header_file_name, "wt"))
self.section_sinks = {'__main__': self.main_sink}
for module in modules:
section_name = 'ns3_module_%s' % module.replace('-', '_')
file_name = os.path.join(os.path.dirname(self.main_file_name), "%s.cc" % section_name)
sink = FileCodeSink(open(file_name, "wt"))
self.section_sinks[section_name] = sink
def get_section_code_sink(self, section_name):
return self.section_sinks[section_name]
def get_main_code_sink(self):
return self.main_sink
def get_common_header_code_sink(self):
return self.header_sink
def get_common_header_include(self):
return '"%s"' % self.header_name
def close(self):
self.header_sink.file.close()
self.main_sink.file.close()
for sink in self.section_sinks.itervalues():
sink.file.close()
def main():
out = MyMultiSectionFactory(sys.argv[1], sys.argv[3:])
root_module = module_init()
root_module.add_include('"everything.h"')
register_types(root_module)
ns3modulegen_core_customizations.Simulator_customizations(root_module)
ns3modulegen_core_customizations.CommandLine_customizations(root_module)
ns3modulegen_core_customizations.TypeId_customizations(root_module)
ns3modulegen_core_customizations.add_std_ofstream(root_module)
ns3modulegen_core_customizations.add_ipv4_address_tp_hash(root_module)
for local_module in LOCAL_MODULES:
mod = __import__(local_module)
mod.register_types(root_module)
ns3modulegen_core_customizations.generate_callback_classes(root_module.after_forward_declarations,
callbacks_list.callback_classes)
register_methods(root_module)
for local_module in LOCAL_MODULES:
mod = __import__(local_module)
mod.register_methods(root_module)
ns3modulegen_core_customizations.Object_customizations(root_module)
ns3modulegen_core_customizations.Attribute_customizations(root_module)
register_functions(root_module)
for local_module in LOCAL_MODULES:
mod = __import__(local_module)
mod.register_functions(root_module)
enabled_features = os.environ['NS3_ENABLED_FEATURES'].split(',')
if 'GtkConfigStore' not in enabled_features:
try:
root_module.classes.remove(root_module['ns3::GtkConfigStore'])
except KeyError:
pass
if 'SqliteDataOutput' not in enabled_features:
try:
root_module.classes.remove(root_module['ns3::SqliteDataOutput'])
except KeyError:
pass
if 'Threading' not in enabled_features:
for clsname in ['SystemThread', 'SystemMutex', 'SystemCondition', 'CriticalSection',
'SimpleRefCount< ns3::SystemThread, ns3::empty, ns3::DefaultDeleter<ns3::SystemThread> >']:
root_module.classes.remove(root_module['ns3::%s' % clsname])
if 'EmuNetDevice' not in enabled_features:
for clsname in ['EmuNetDevice', 'EmuHelper']:
root_module.classes.remove(root_module['ns3::%s' % clsname])
root_module.enums.remove(root_module['ns3::EmuNetDevice::EncapsulationMode'])
if 'RealTime' not in enabled_features:
for clsname in ['WallClockSynchronizer', 'RealtimeSimulatorImpl']:
root_module.classes.remove(root_module['ns3::%s' % clsname])
root_module.enums.remove(root_module['ns3::RealtimeSimulatorImpl::SynchronizationMode'])
if 'TapBridge' not in enabled_features:
for clsname in ['TapBridge', 'TapBridgeHelper', 'TapBridgeFdReader']:
root_module.classes.remove(root_module['ns3::%s' % clsname])
root_module.enums.remove(root_module['ns3::TapBridge::Mode'])
root_module.generate(out, '_ns3')
out.close()
if __name__ == '__main__':
if 0:
try:
import cProfile as profile
except ImportError:
main()
else:
print >> sys.stderr, "** running under profiler"
profile.run('main()', 'ns3modulegen.pstat')
else:
main()
import re
from pybindgen.typehandlers import base as typehandlers
from pybindgen import ReturnValue, Parameter
from pybindgen.cppmethod import CustomCppMethodWrapper, CustomCppConstructorWrapper
from pybindgen.typehandlers.codesink import MemoryCodeSink
from pybindgen.typehandlers import ctypeparser
from pybindgen import cppclass
import warnings
from pybindgen.typehandlers.base import CodeGenerationError
import sys
class SmartPointerTransformation(typehandlers.TypeTransformation):
def __init__(self):
super(SmartPointerTransformation, self).__init__()
self.rx = re.compile(r'(ns3::|::ns3::|)Ptr<([^>]+)>\s*$')
def _get_untransformed_type_traits(self, name):
m = self.rx.match(name)
is_const = False
if m is None:
return None, False
else:
name1 = m.group(2).strip()
if name1.startswith('const '):
name1 = name1[len('const '):]
is_const = True
if name1.endswith(' const'):
name1 = name1[:-len(' const')]
is_const = True
new_name = name1+' *'
if new_name.startswith('::'):
new_name = new_name[2:]
return new_name, is_const
def get_untransformed_name(self, name):
new_name, dummy_is_const = self._get_untransformed_type_traits(name)
return new_name
def create_type_handler(self, type_handler, *args, **kwargs):
if issubclass(type_handler, Parameter):
kwargs['transfer_ownership'] = False
elif issubclass(type_handler, ReturnValue):
kwargs['caller_owns_return'] = False
else:
raise AssertionError
orig_ctype, is_const = self._get_untransformed_type_traits(args[0])
if is_const:
correct_ctype = 'ns3::Ptr< %s const >' % orig_ctype[:-2]
else:
correct_ctype = 'ns3::Ptr< %s >' % orig_ctype[:-2]
args = tuple([correct_ctype] + list(args[1:]))
handler = type_handler(*args, **kwargs)
handler.set_tranformation(self, orig_ctype)
return handler
def untransform(self, type_handler, declarations, code_block, expression):
return 'const_cast<%s> (ns3::PeekPointer (%s))' % (type_handler.untransformed_ctype, expression)
def transform(self, type_handler, declarations, code_block, expression):
assert type_handler.untransformed_ctype[-1] == '*'
return 'ns3::Ptr< %s > (%s)' % (type_handler.untransformed_ctype[:-1], expression)
transf = SmartPointerTransformation()
typehandlers.return_type_matcher.register_transformation(transf)
typehandlers.param_type_matcher.register_transformation(transf)
del transf
class ArgvParam(Parameter):
DIRECTIONS = [Parameter.DIRECTION_IN]
CTYPES = []
def convert_c_to_python(self, wrapper):
raise NotImplementedError
def convert_python_to_c(self, wrapper):
py_name = wrapper.declarations.declare_variable('PyObject*', 'py_' + self.name)
argc_var = wrapper.declarations.declare_variable('int', 'argc')
name = wrapper.declarations.declare_variable('char**', self.name)
idx = wrapper.declarations.declare_variable('Py_ssize_t', 'idx')
wrapper.parse_params.add_parameter('O!', ['&PyList_Type', '&'+py_name], self.name)
wrapper.before_call.write_code("%s = (char **) malloc(sizeof(char*)*PyList_Size(%s));"
% (name, py_name))
wrapper.before_call.add_cleanup_code('free(%s);' % name)
wrapper.before_call.write_code( % vars())
wrapper.before_call.sink.indent()
wrapper.before_call.write_code( % vars())
wrapper.before_call.write_error_check(
'!PyString_Check(item)',
failure_cleanup=('PyErr_SetString(PyExc_TypeError, '
'"argument %s must be a list of strings");') % self.name)
wrapper.before_call.write_code(
'%s[%s] = PyString_AsString(item);' % (name, idx))
wrapper.before_call.sink.unindent()
wrapper.before_call.write_code('}')
wrapper.before_call.write_code('%s = PyList_Size(%s);' % (argc_var, py_name))
wrapper.call_params.append(argc_var)
wrapper.call_params.append(name)
class CallbackImplProxyMethod(typehandlers.ReverseWrapperBase):
def __init__(self, return_value, parameters):
super(CallbackImplProxyMethod, self).__init__(return_value, parameters)
def generate_python_call(self):
build_params = self.build_params.get_parameters(force_tuple_creation=True)
if build_params[0][0] == '"':
build_params[0] = '(char *) ' + build_params[0]
args = self.before_call.declare_variable('PyObject*', 'args')
self.before_call.write_code('%s = Py_BuildValue(%s);'
% (args, ', '.join(build_params)))
self.before_call.add_cleanup_code('Py_DECREF(%s);' % args)
self.before_call.write_code('py_retval = PyObject_CallObject(m_callback, %s);' % args)
self.before_call.write_error_check('py_retval == NULL')
self.before_call.add_cleanup_code('Py_DECREF(py_retval);')
def generate_callback_classes(out, callbacks):
for callback_impl_num, template_parameters in enumerate(callbacks):
sink = MemoryCodeSink()
cls_name = "ns3::Callback< %s >" % ', '.join(template_parameters)
class_name = "PythonCallbackImpl%i" % callback_impl_num
sink.writeln( % (class_name, ', '.join(template_parameters), class_name, class_name, class_name, class_name))
sink.indent()
callback_return = template_parameters[0]
return_ctype = ctypeparser.parse_type(callback_return)
if ('const' in return_ctype.remove_modifiers()):
kwargs = {'is_const': True}
else:
kwargs = {}
try:
return_type = ReturnValue.new(str(return_ctype), **kwargs)
except (typehandlers.TypeLookupError, typehandlers.TypeConfigurationError), ex:
warnings.warn("***** Unable to register callback; Return value '%s' error (used in %s): %r"
% (callback_return, cls_name, ex),
Warning)
continue
arguments = []
ok = True
callback_parameters = [arg for arg in template_parameters[1:] if arg != 'ns3::empty']
for arg_num, arg_type in enumerate(callback_parameters):
arg_name = 'arg%i' % (arg_num+1)
param_ctype = ctypeparser.parse_type(arg_type)
if ('const' in param_ctype.remove_modifiers()):
kwargs = {'is_const': True}
else:
kwargs = {}
try:
arguments.append(Parameter.new(str(param_ctype), arg_name, **kwargs))
except (typehandlers.TypeLookupError, typehandlers.TypeConfigurationError), ex:
warnings.warn("***** Unable to register callback; parameter '%s %s' error (used in %s): %r"
% (arg_type, arg_name, cls_name, ex),
Warning)
ok = False
if not ok:
continue
wrapper = CallbackImplProxyMethod(return_type, arguments)
wrapper.generate(sink, 'operator()', decl_modifiers=[])
sink.unindent()
sink.writeln('};\n')
sink.flush_to(out)
class PythonCallbackParameter(Parameter):
"Class handlers"
CTYPES = [cls_name]
print >> sys.stderr, "***** registering callback handler: %r" % ctypeparser.normalize_type_string(cls_name)
DIRECTIONS = [Parameter.DIRECTION_IN]
PYTHON_CALLBACK_IMPL_NAME = class_name
TEMPLATE_ARGS = template_parameters
def convert_python_to_c(self, wrapper):
"parses python args to get C++ value"
assert isinstance(wrapper, typehandlers.ForwardWrapperBase)
if self.default_value is None:
py_callback = wrapper.declarations.declare_variable('PyObject*', self.name)
wrapper.parse_params.add_parameter('O', ['&'+py_callback], self.name)
wrapper.before_call.write_error_check(
'!PyCallable_Check(%s)' % py_callback,
'PyErr_SetString(PyExc_TypeError, "parameter \'%s\' must be callbale");' % self.name)
callback_impl = wrapper.declarations.declare_variable(
'ns3::Ptr<%s>' % self.PYTHON_CALLBACK_IMPL_NAME,
'%s_cb_impl' % self.name)
wrapper.before_call.write_code("%s = ns3::Create<%s> (%s);"
% (callback_impl, self.PYTHON_CALLBACK_IMPL_NAME, py_callback))
wrapper.call_params.append(
'ns3::Callback<%s> (%s)' % (', '.join(self.TEMPLATE_ARGS), callback_impl))
else:
py_callback = wrapper.declarations.declare_variable('PyObject*', self.name, 'NULL')
wrapper.parse_params.add_parameter('O', ['&'+py_callback], self.name, optional=True)
value = wrapper.declarations.declare_variable(
'ns3::Callback<%s>' % ', '.join(self.TEMPLATE_ARGS),
self.name+'_value',
self.default_value)
wrapper.before_call.write_code("if (%s) {" % (py_callback,))
wrapper.before_call.indent()
wrapper.before_call.write_error_check(
'!PyCallable_Check(%s)' % py_callback,
'PyErr_SetString(PyExc_TypeError, "parameter \'%s\' must be callbale");' % self.name)
wrapper.before_call.write_code("%s = ns3::Callback<%s> (ns3::Create<%s> (%s));"
% (value, ', '.join(self.TEMPLATE_ARGS),
self.PYTHON_CALLBACK_IMPL_NAME, py_callback))
wrapper.before_call.unindent()
wrapper.before_call.write_code("}")
wrapper.call_params.append(value)
def convert_c_to_python(self, wrapper):
raise typehandlers.NotSupportedError("Reverse wrappers for ns3::Callback<...> types "
"(python using callbacks defined in C++) not implemented.")
def Simulator_customizations(module):
Simulator = module['ns3::Simulator']
Simulator.add_custom_method_wrapper("Schedule", "_wrap_Simulator_Schedule",
flags=["METH_VARARGS", "METH_KEYWORDS", "METH_STATIC"])
Simulator.add_custom_method_wrapper("ScheduleNow", "_wrap_Simulator_ScheduleNow",
flags=["METH_VARARGS", "METH_KEYWORDS", "METH_STATIC"])
Simulator.add_custom_method_wrapper("ScheduleDestroy", "_wrap_Simulator_ScheduleDestroy",
flags=["METH_VARARGS", "METH_KEYWORDS", "METH_STATIC"])
Simulator.add_custom_method_wrapper("Run", "_wrap_Simulator_Run",
flags=["METH_VARARGS", "METH_KEYWORDS", "METH_STATIC"])
def CommandLine_customizations(module):
CommandLine = module['ns3::CommandLine']
CommandLine.add_method('Parse', None, [ArgvParam(None, 'argv')],
is_static=False)
CommandLine.add_custom_method_wrapper("AddValue", "_wrap_CommandLine_AddValue",
flags=["METH_VARARGS", "METH_KEYWORDS"])
def Object_customizations(module):
try:
Object = module['ns3::Object']
except KeyError:
return
def helper_class_hook(helper_class):
decl =   % (helper_class.name, helper_class.class_.full_name)
helper_class.add_custom_method(decl)
helper_class.add_post_generation_code(
"NS_OBJECT_ENSURE_REGISTERED (%s);" % helper_class.name)
Object.add_helper_class_hook(helper_class_hook)
def ns3_object_instance_creation_function(cpp_class, code_block, lvalue,
parameters, construct_type_name):
assert lvalue
assert not lvalue.startswith('None')
if cpp_class.cannot_be_constructed:
raise CodeGenerationError("%s cannot be constructed (%s)"
% cpp_class.full_name)
if cpp_class.incomplete_type:
raise CodeGenerationError("%s cannot be constructed (incomplete type)"
% cpp_class.full_name)
code_block.write_code("%s = new %s(%s);" % (lvalue, construct_type_name, parameters))
code_block.write_code("%s->Ref ();" % (lvalue))
def ns3_object_post_instance_creation_function(cpp_class, code_block, lvalue,
parameters, construct_type_name):
code_block.write_code("ns3::CompleteConstruct(%s);" % (lvalue, ))
Object.set_instance_creation_function(ns3_object_instance_creation_function)
Object.set_post_instance_creation_function(ns3_object_post_instance_creation_function)
def Attribute_customizations(module):
for cls in module.classes:
for meth in cls.get_all_methods():
for param in meth.parameters:
if isinstance(param, cppclass.CppClassRefParameter):
if param.cpp_class.name == 'AttributeValue' \
and param.default_value is not None \
and param.default_value_type is None:
param.default_value_type = 'ns3::EmptyAttributeValue'
def TypeId_customizations(module):
TypeId = module['ns3::TypeId']
TypeId.add_custom_method_wrapper("LookupByNameFailSafe", "_wrap_TypeId_LookupByNameFailSafe",
flags=["METH_VARARGS", "METH_KEYWORDS", "METH_STATIC"])
def add_std_ofstream(module):
module.add_include('<fstream>')
ostream = module.add_class('ostream', foreign_cpp_namespace='::std')
ostream.set_cannot_be_constructed("abstract base class")
ofstream = module.add_class('ofstream', foreign_cpp_namespace='::std', parent=ostream)
ofstream.add_enum('openmode', [
('app', 'std::ios_base::app'),
('ate', 'std::ios_base::ate'),
('binary', 'std::ios_base::binary'),
('in', 'std::ios_base::in'),
('out', 'std::ios_base::out'),
('trunc', 'std::ios_base::trunc'),
])
ofstream.add_constructor([Parameter.new("const char *", 'filename'),
Parameter.new("::std::ofstream::openmode", 'mode', default_value="std::ios_base::out")])
ofstream.add_method('close', None, [])
add_std_ios_openmode(module)
def add_std_ios_openmode(module):
import pybindgen.typehandlers.base
for alias in "std::_Ios_Openmode", "std::ios::openmode":
pybindgen.typehandlers.base.param_type_matcher.add_type_alias(alias, "int")
for flag in 'in', 'out', 'ate', 'app', 'trunc', 'binary':
module.after_init.write_code('PyModule_AddIntConstant(m, (char *) "STD_IOS_%s", std::ios::%s);'
% (flag.upper(), flag))
def add_ipv4_address_tp_hash(module):
module.body.writeln()
module.header.writeln('long _ns3_Ipv4Address_tp_hash (PyObject *obj);')
module['Ipv4Address'].pytype.slots['tp_hash'] = "_ns3_Ipv4Address_tp_hash"
import sys
import os.path
import pybindgen.settings
from pybindgen.gccxmlparser import ModuleParser, PygenClassifier, PygenSection, WrapperWarning, find_declaration_from_name
from pybindgen.typehandlers.codesink import FileCodeSink
from pygccxml.declarations import templates
from pygccxml.declarations.enumeration import enumeration_t
from pygccxml.declarations.class_declaration import class_t
from pygccxml.declarations.calldef import free_function_t, member_function_t, constructor_t, calldef_t
import ns3modulegen_core_customizations
class ErrorHandler(pybindgen.settings.ErrorHandler):
def handle_error(self, dummy_wrapper, dummy_exception, dummy_traceback_):
return True
pybindgen.settings.error_handler = ErrorHandler()
import warnings
warnings.filterwarnings(category=WrapperWarning, action='ignore')
import ns3modulescan
type_annotations = ns3modulescan.type_annotations
def get_ns3_relative_path(path):
l = []
head = path
while head:
new_head, tail = os.path.split(head)
if new_head == head:
raise ValueError
head = new_head
if tail == 'ns3':
return os.path.join(*l)
l.insert(0, tail)
raise AssertionError("is the path %r inside ns3?!" % path)
class PreScanHook:
def __init__(self, headers_map, module):
self.headers_map = headers_map
self.module = module
def __call__(self, module_parser,
pygccxml_definition,
global_annotations,
parameter_annotations):
try:
ns3_header = get_ns3_relative_path(pygccxml_definition.location.file_name)
except ValueError:
return
definition_module = self.headers_map[ns3_header]
global_annotations['pygen_comment'] = "%s (module %r): %s" % \
(ns3_header, definition_module, pygccxml_definition)
if isinstance(pygccxml_definition, member_function_t) \
and pygccxml_definition.parent.name == 'Object' \
and pygccxml_definition.name == 'GetObject':
template_args = templates.args(pygccxml_definition.demangled_name)
if template_args == ['ns3::Object']:
global_annotations['template_instance_names'] = 'ns3::Object=>GetObject'
if isinstance(pygccxml_definition, member_function_t) \
and pygccxml_definition.parent.name == 'Simulator' \
and pygccxml_definition.name.startswith('Schedule'):
global_annotations['ignore'] = None
if isinstance(pygccxml_definition, member_function_t) \
and pygccxml_definition.parent.name == 'Simulator' \
and pygccxml_definition.name == 'Run':
global_annotations['ignore'] = True
if isinstance(pygccxml_definition, calldef_t):
for arg in pygccxml_definition.arguments:
if arg.default_value is None:
continue
elif arg.default_value == "ns3::MilliSeconds( )":
arg.default_value = "ns3::MilliSeconds(0)"
elif arg.default_value == "ns3::Seconds( )":
arg.default_value = "ns3::Seconds(0)"
if isinstance(pygccxml_definition, class_t):
print >> sys.stderr, pygccxml_definition
if templates.is_instantiation(pygccxml_definition.decl_string):
cls_name, template_parameters = templates.split(pygccxml_definition.name)
template_parameters_decls = [find_declaration_from_name(module_parser.global_ns, templ_param)
for templ_param in template_parameters]
template_parameters_modules = []
for templ in template_parameters_decls:
if not hasattr(templ, 'location'):
continue
try:
h = get_ns3_relative_path(templ.location.file_name)
except ValueError:
continue
template_parameters_modules.append(self.headers_map[h])
for templ_mod in template_parameters_modules:
if templ_mod == self.module:
definition_module = templ_mod
break
if definition_module != self.module:
global_annotations['import_from_module'] = 'ns.%s' % (definition_module.replace('-', '_'),)
if pygccxml_definition.decl_string.startswith('::ns3::SimpleRefCount<'):
global_annotations['incref_method'] = 'Ref'
global_annotations['decref_method'] = 'Unref'
global_annotations['peekref_method'] = 'GetReferenceCount'
global_annotations['automatic_type_narrowing'] = 'true'
return
if pygccxml_definition.decl_string.startswith('::ns3::Callback<'):
global_annotations['ignore'] = None
return
if pygccxml_definition.decl_string.startswith('::ns3::TracedCallback<'):
global_annotations['ignore'] = None
return
if pygccxml_definition.decl_string.startswith('::ns3::Ptr<'):
global_annotations['ignore'] = None
return
try:
annotations = type_annotations[pygccxml_definition.decl_string]
except KeyError:
pass
else:
global_annotations.update(annotations)
if isinstance(pygccxml_definition, enumeration_t):
if definition_module != self.module:
global_annotations['import_from_module'] = 'ns.%s' % definition_module
if isinstance(pygccxml_definition, free_function_t):
if definition_module != self.module:
global_annotations['ignore'] = None
return
if pygccxml_definition.name == 'PeekPointer':
global_annotations['ignore'] = None
return
if isinstance(pygccxml_definition, (free_function_t, member_function_t, constructor_t)):
try:
annotations = type_annotations[str(pygccxml_definition)]
except KeyError:
pass
else:
for key,value in annotations.items():
if key == 'params':
parameter_annotations.update (value)
del annotations['params']
global_annotations.update(annotations)
def scan_callback_classes(module_parser, callback_classes_file):
callback_classes_file.write("callback_classes = [\n")
for cls in module_parser.module_namespace.classes(function=module_parser.location_filter,
recursive=False):
if not cls.name.startswith("Callback<"):
continue
assert templates.is_instantiation(cls.decl_string), "%s is not a template instantiation" % cls
dummy_cls_name, template_parameters = templates.split(cls.decl_string)
callback_classes_file.write("    %r,\n" % template_parameters)
callback_classes_file.write("]\n")
def ns3_module_scan(top_builddir, module_name, headers_map, output_file_name, cflags):
module_parser = ModuleParser('ns.%s' % module_name.replace('-', '_'), 'ns3')
module_parser.add_pre_scan_hook(PreScanHook(headers_map, module_name))
gccxml_options = dict(
include_paths=[top_builddir],
define_symbols={
},
cflags=('--gccxml-cxxflags "%s -DPYTHON_SCAN"' % cflags)
)
try:
os.unlink(output_file_name)
except OSError:
pass
try:
os.makedirs(os.path.dirname(output_file_name))
except OSError:
pass
output_file = open(output_file_name, "wt")
output_sink = FileCodeSink(output_file)
scan_header = os.path.join(os.path.dirname(output_file_name), "scan-header.h")
if not os.path.exists(scan_header):
scan_header = os.path.join(top_builddir, "ns3", "%s-module.h" % module_name)
module_parser.parse_init([scan_header],
None, whitelist_paths=[top_builddir],
pygen_sink=output_sink,
gccxml_options=gccxml_options)
module_parser.scan_types()
callback_classes_file = open(os.path.join(os.path.dirname(output_file_name), "callbacks_list.py"), "wt")
scan_callback_classes(module_parser, callback_classes_file)
callback_classes_file.close()
module_parser.scan_methods()
module_parser.scan_functions()
module_parser.parse_finalize()
output_file.close()
os.chmod(output_file_name, 0400)
if __name__ == '__main__':
if len(sys.argv) != 6:
print "ns3modulescan-modular.py top_builddir module_path module_headers output_file_name cflags"
sys.exit(1)
ns3_module_scan(sys.argv[1], sys.argv[2], eval(sys.argv[3]), sys.argv[4], sys.argv[5])
sys.exit(0)
import sys
import os.path
import pybindgen.settings
from pybindgen.gccxmlparser import ModuleParser, PygenClassifier, PygenSection, WrapperWarning
from pybindgen.typehandlers.codesink import FileCodeSink
from pygccxml.declarations import templates
from pygccxml.declarations.class_declaration import class_t
from pygccxml.declarations.calldef import free_function_t, member_function_t, constructor_t, calldef_t
import ns3modulegen_core_customizations
class ErrorHandler(pybindgen.settings.ErrorHandler):
def handle_error(self, dummy_wrapper, dummy_exception, dummy_traceback_):
return True
pybindgen.settings.error_handler = ErrorHandler()
import warnings
warnings.filterwarnings(category=WrapperWarning, action='ignore')
type_annotations = {
'::ns3::AttributeChecker': {
'automatic_type_narrowing': 'true',
'allow_subclassing': 'false',
},
'::ns3::AttributeValue': {
'automatic_type_narrowing': 'true',
'allow_subclassing': 'false',
},
'::ns3::CommandLine': {
'allow_subclassing': 'true',
},
'::ns3::NscTcpL4Protocol': {
'ignore': 'true',
},
'ns3::RandomVariable::RandomVariable(ns3::RandomVariableBase const & variable) [constructor]': {
'ignore': None,
},
'ns3::RandomVariableBase * ns3::RandomVariable::Peek() const [member function]': {
'ignore': None,
},
'void ns3::RandomVariable::GetSeed(uint32_t * seed) const [member function]': {
'params': {'seed':{'direction':'out',
'array_length':'6'}}
},
'bool ns3::TypeId::LookupAttributeByName(std::string name, ns3::TypeId::AttributeInfo * info) const [member function]': {
'params': {'info':{'transfer_ownership': 'false'}}
},
'static bool ns3::TypeId::LookupByNameFailSafe(std::string name, ns3::TypeId * tid) [member function]': {
'ignore': None,
},
'bool ns3::TraceSourceAccessor::ConnectWithoutContext(ns3::ObjectBase * obj, ns3::CallbackBase const & cb) const [member function]': {
'params': {'obj': {'transfer_ownership':'false'}}
},
'bool ns3::TraceSourceAccessor::Connect(ns3::ObjectBase * obj, std::string context, ns3::CallbackBase const & cb) const [member function]': {
'params': {'obj': {'transfer_ownership':'false'}}
},
'bool ns3::TraceSourceAccessor::DisconnectWithoutContext(ns3::ObjectBase * obj, ns3::CallbackBase const & cb) const [member function]': {
'params': {'obj': {'transfer_ownership':'false'}}
},
'bool ns3::TraceSourceAccessor::Disconnect(ns3::ObjectBase * obj, std::string context, ns3::CallbackBase const & cb) const [member function]': {
'params': {'obj': {'transfer_ownership':'false'}}
},
'bool ns3::AttributeAccessor::Set(ns3::ObjectBase * object, ns3::AttributeValue const & value) const [member function]': {
'params': {'object': {'transfer_ownership':'false'}}
},
'ns3::EmpiricalVariable::EmpiricalVariable(ns3::RandomVariableBase const & variable) [constructor]': {
'ignore': None
},
'static ns3::AttributeList * ns3::AttributeList::GetGlobal() [member function]': {
'caller_owns_return': 'false'
},
'void ns3::CommandLine::Parse(int argc, char * * argv) const [member function]': {
'ignore': None
},
'extern void ns3::PythonCompleteConstruct(ns3::Ptr<ns3::Object> object, ns3::TypeId typeId, ns3::AttributeList const & attributes) [free function]': {
'ignore': None
},
'ns3::Ptr<ns3::Ipv4RoutingProtocol> ns3::Ipv4ListRouting::GetRoutingProtocol(uint32_t index, int16_t & priority) const [member function]': {
'params': {'priority':{'direction':'out'}}
},
'ns3::Ipv4RoutingTableEntry * ns3::GlobalRouter::GetInjectedRoute(uint32_t i) [member function]': {
'params': {'return': { 'caller_owns_return': 'false',}},
},
'ns3::Ipv4RoutingTableEntry * ns3::Ipv4GlobalRouting::GetRoute(uint32_t i) const [member function]': {
'params': {'return': { 'caller_owns_return': 'false',}},
},
'::ns3::TestCase': {
'ignore': 'true',
},
'::ns3::TestRunner': {
'ignore': 'true',
},
'::ns3::TestSuite': {
'ignore': 'true',
},
}
def get_ns3_relative_path(path):
l = []
head = path
while head:
head, tail = os.path.split(head)
if tail == 'ns3':
return os.path.join(*l)
l.insert(0, tail)
raise AssertionError("is the path %r inside ns3?!" % path)
def pre_scan_hook(dummy_module_parser,
pygccxml_definition,
global_annotations,
parameter_annotations):
ns3_header = get_ns3_relative_path(pygccxml_definition.location.file_name)
global_annotations['pygen_comment'] = "%s: %s" % \
(ns3_header, pygccxml_definition)
if isinstance(pygccxml_definition, member_function_t) \
and pygccxml_definition.parent.name == 'Object' \
and pygccxml_definition.name == 'GetObject':
template_args = templates.args(pygccxml_definition.demangled_name)
if template_args == ['ns3::Object']:
global_annotations['template_instance_names'] = 'ns3::Object=>GetObject'
if isinstance(pygccxml_definition, member_function_t) \
and pygccxml_definition.parent.name == 'Simulator' \
and pygccxml_definition.name.startswith('Schedule'):
global_annotations['ignore'] = None
if isinstance(pygccxml_definition, member_function_t) \
and pygccxml_definition.parent.name == 'Simulator' \
and pygccxml_definition.name == 'Run':
global_annotations['ignore'] = True
if isinstance(pygccxml_definition, calldef_t):
for arg in pygccxml_definition.arguments:
if arg.default_value is None:
continue
if "ns3::MilliSeconds( )" == arg.default_value:
arg.default_value = "ns3::MilliSeconds(0)"
if "ns3::Seconds( )" == arg.default_value:
arg.default_value = "ns3::Seconds(0)"
if isinstance(pygccxml_definition, class_t):
if pygccxml_definition.decl_string.startswith('::ns3::SimpleRefCount<'):
global_annotations['incref_method'] = 'Ref'
global_annotations['decref_method'] = 'Unref'
global_annotations['peekref_method'] = 'GetReferenceCount'
global_annotations['automatic_type_narrowing'] = 'true'
return
if pygccxml_definition.decl_string.startswith('::ns3::Callback<'):
global_annotations['ignore'] = None
return
if pygccxml_definition.decl_string.startswith('::ns3::TracedCallback<'):
global_annotations['ignore'] = None
return
if pygccxml_definition.decl_string.startswith('::ns3::Ptr<'):
global_annotations['ignore'] = None
return
try:
annotations = type_annotations[pygccxml_definition.decl_string]
except KeyError:
pass
else:
global_annotations.update(annotations)
if isinstance(pygccxml_definition, free_function_t):
if pygccxml_definition.name == 'PeekPointer':
global_annotations['ignore'] = None
return
if isinstance(pygccxml_definition, (free_function_t, member_function_t, constructor_t)):
try:
annotations = type_annotations[str(pygccxml_definition)]
except KeyError:
pass
else:
for key,value in annotations.items():
if key == 'params':
parameter_annotations.update (value)
del annotations['params']
global_annotations.update(annotations)
def scan_callback_classes(module_parser, callback_classes_file):
callback_classes_file.write("callback_classes = [\n")
for cls in module_parser.module_namespace.classes(function=module_parser.location_filter,
recursive=False):
if not cls.name.startswith("Callback<"):
continue
assert templates.is_instantiation(cls.decl_string), "%s is not a template instantiation" % cls
dummy_cls_name, template_parameters = templates.split(cls.decl_string)
callback_classes_file.write("    %r,\n" % template_parameters)
callback_classes_file.write("]\n")
class MyPygenClassifier(PygenClassifier):
def __init__(self, headers_map, section_precendences):
self.headers_map = headers_map
self.section_precendences = section_precendences
def classify(self, pygccxml_definition):
name = os.path.basename(pygccxml_definition.location.file_name)
try:
return self.headers_map[name]
except KeyError:
return '__main__'
def get_section_precedence(self, section_name):
if section_name == '__main__':
return -1
return self.section_precendences[section_name]
def ns3_module_scan(top_builddir, pygen_file_name, everything_h, cflags):
ns3_modules = eval(sys.stdin.readline())
from topsort import topsort
graph = []
module_names = ns3_modules.keys()
module_names.sort()
for ns3_module_name in module_names:
ns3_module_deps = list(ns3_modules[ns3_module_name][0])
ns3_module_deps.sort()
for dep in ns3_module_deps:
graph.append((dep, ns3_module_name))
sorted_ns3_modules = topsort(graph)
sections = [PygenSection('__main__', FileCodeSink(open(pygen_file_name, "wt")))]
headers_map = {}
section_precendences = {}
for prec, ns3_module in enumerate(sorted_ns3_modules):
section_name = "ns3_module_%s" % ns3_module.replace('-', '_')
file_name = os.path.join(os.path.dirname(pygen_file_name), "%s.py" % section_name)
sections.append(PygenSection(section_name, FileCodeSink(open(file_name, "wt")),
section_name + "__local"))
for header in ns3_modules[ns3_module][1]:
headers_map[header] = section_name
section_precendences[section_name] = prec
module_parser = ModuleParser('ns3', 'ns3')
module_parser.add_pre_scan_hook(pre_scan_hook)
gccxml_options = dict(
include_paths=[top_builddir],
define_symbols={
},
cflags=('--gccxml-cxxflags "%s -DPYTHON_SCAN"' % cflags)
)
module_parser.parse_init([everything_h],
None, whitelist_paths=[top_builddir, os.path.dirname(everything_h)],
pygen_sink=sections,
pygen_classifier=MyPygenClassifier(headers_map, section_precendences),
gccxml_options=gccxml_options)
module_parser.scan_types()
callback_classes_file = open(os.path.join(os.path.dirname(pygen_file_name), "callbacks_list.py"), "wt")
scan_callback_classes(module_parser, callback_classes_file)
callback_classes_file.close()
module_parser.scan_methods()
module_parser.scan_functions()
module_parser.parse_finalize()
for section in sections:
section.code_sink.file.close()
if __name__ == '__main__':
ns3_module_scan(sys.argv[1], sys.argv[3], sys.argv[2], sys.argv[4])
from _ns3 import *
import atexit
atexit.register(Simulator.Destroy)
del atexit
try:
from http.client import HTTPSConnection
except ImportError:
from httplib import HTTPSConnection
from logging import getLogger
from ntlm import ntlm
from urllib3 import HTTPSConnectionPool
log = getLogger(__name__)
class NTLMConnectionPool(HTTPSConnectionPool):
scheme = 'https'
def __init__(self, user, pw, authurl, *args, **kwargs):
super(NTLMConnectionPool, self).__init__(*args, **kwargs)
self.authurl = authurl
self.rawuser = user
user_parts = user.split('\\', 1)
self.domain = user_parts[0].upper()
self.user = user_parts[1]
self.pw = pw
def _new_conn(self):
self.num_connections += 1
log.debug('Starting NTLM HTTPS connection no. %d: https://%s%s' %
(self.num_connections, self.host, self.authurl))
headers = {}
headers['Connection'] = 'Keep-Alive'
req_header = 'Authorization'
resp_header = 'www-authenticate'
conn = HTTPSConnection(host=self.host, port=self.port)
headers[req_header] = (
'NTLM %s' % ntlm.create_NTLM_NEGOTIATE_MESSAGE(self.rawuser))
log.debug('Request headers: %s' % headers)
conn.request('GET', self.authurl, None, headers)
res = conn.getresponse()
reshdr = dict(res.getheaders())
log.debug('Response status: %s %s' % (res.status, res.reason))
log.debug('Response headers: %s' % reshdr)
log.debug('Response data: %s [...]' % res.read(100))
res.fp = None
auth_header_values = reshdr[resp_header].split(', ')
auth_header_value = None
for s in auth_header_values:
if s[:5] == 'NTLM ':
auth_header_value = s[5:]
if auth_header_value is None:
raise Exception('Unexpected %s response header: %s' %
(resp_header, reshdr[resp_header]))
ServerChallenge, NegotiateFlags = \
ntlm.parse_NTLM_CHALLENGE_MESSAGE(auth_header_value)
auth_msg = ntlm.create_NTLM_AUTHENTICATE_MESSAGE(ServerChallenge,
self.user,
self.domain,
self.pw,
NegotiateFlags)
headers[req_header] = 'NTLM %s' % auth_msg
log.debug('Request headers: %s' % headers)
conn.request('GET', self.authurl, None, headers)
res = conn.getresponse()
log.debug('Response status: %s %s' % (res.status, res.reason))
log.debug('Response headers: %s' % dict(res.getheaders()))
log.debug('Response data: %s [...]' % res.read()[:100])
if res.status != 200:
if res.status == 401:
raise Exception('Server rejected request: wrong '
'username or password')
raise Exception('Wrong server response: %s %s' %
(res.status, res.reason))
res.fp = None
log.debug('Connection established')
return conn
def urlopen(self, method, url, body=None, headers=None, retries=3,
redirect=True, assert_same_host=True):
if headers is None:
headers = {}
headers['Connection'] = 'Keep-Alive'
return super(NTLMConnectionPool, self).urlopen(method, url, body,
headers, retries,
redirect,
assert_same_host)
class Solution(object):
def solve(self, cipher):
N, K, A = cipher
total = N * (N + 1) / 2
total_only_s = 0
i = 0
while i < N:
if A[i] > K:
i += 1
else:
j = i + 1
while j < N and A[j] <= K: j += 1
l = j - i
total_only_s += l * (l + 1) / 2
i = j
return total - total_only_s
if __name__ == "__main__":
import sys
f = open("0.in", "r")
solution = Solution()
testcases = int(f.readline().strip())
for t in xrange(testcases):
N, K = map(int, f.readline().strip().split(' '))
A = map(int, f.readline().strip().split(' '))
cipher = N, K, A
s = "%s\n" % (solution.solve(cipher))
print s,
class Interval(object):
def __init__(self, start, end):
self.start = start
self.end = end
class Solution:
@staticmethod
def cmp(a, b):
if a.start != b.start:
return a.start-b.start
else:
return a.end-b.end
def countOfAirplanes(self, airplanes):
return self.count_heap(airplanes)
def count_heap(self, intervals):
import heapq
intervals.sort(cmp=Solution.cmp)
heap = []
cnt = 0
for intv in intervals:
heapq.heappush(heap, intv.end)
while heap[0] <= intv.start:
heapq.heappop(heap)
cnt = max(cnt, len(heap))
return cnt
if __name__ == "__main__":
assert Solution().countOfAirplanes([Interval(i[0], i[1]) for i in [[1, 10], [2, 3], [5, 8], [4, 7]]]) == 3
import random
class Point(object):
def __init__(self, a=0, b=0):
self.x = a
self.y = b
def __repr__(self):
return "[%d, %d]" % (self.x, self.y)
class UnionFind(object):
def __init__(self, rows, cols):
self.pi = [-1 for _ in xrange(rows*cols)]
self.sz = [-1 for _ in xrange(rows*cols)]
self.count = 0
def add(self, item):
if self.pi[item] == -1:
self.pi[item] = item
self.sz[item] = 1
self.count += 1
def union(self, a, b):
pi1 = self._pi(a)
pi2 = self._pi(b)
if pi1 != pi2:
if self.sz[pi1] > self.sz[pi2]:
pi1, pi2 = pi2, pi1
self.pi[pi1] = pi2
self.sz[pi2] += self.sz[pi1]
self.count -= 1
def _pi(self, item):
pi = self.pi[item]
if item != pi:
self.pi[item] = self._pi(pi)
return self.pi[item]
class Solution:
def __init__(self):
self.dirs = ((-1, 0), (1, 0), (0, -1), (0, 1))
def numIslands2(self, n, m, operators):
rows = n
cols = m
unroll = lambda x, y: x*cols+y
mat = [[0 for _ in xrange(cols)] for _ in xrange(rows)]
uf = UnionFind(rows, cols)
ret = []
for op in operators:
uf.add(unroll(op.x, op.y))
mat[op.x][op.y] = 1
for dir in self.dirs:
x1 = op.x+dir[0]
y1 = op.y+dir[1]
if 0 <= x1 < rows and 0 <= y1 < cols and mat[x1][y1] == 1:
uf.union(unroll(op.x, op.y), unroll(x1, y1))
ret.append(uf.count)
return ret
class TestCaseGenerator(object):
def _generate(self):
dim = 10
m = random.randrange(1, dim)
n = random.randrange(1, dim)
k = random.randrange(1, max(2, m*n/3))
operators = []
visited = set()
while len(operators) < k:
p = random.randrange(m*n)
if p not in visited:
x = p/n
y = p%n
operators.append(Point(x, y))
visited.add(p)
print(m)
print(n)
print(operators)
def generate(self, T=50):
for _ in xrange(T):
self._generate()
if __name__ == "__main__":
assert Solution().numIslands2(3, 3, map(lambda x: Point(x[0], x[1]), [(0, 0), (0, 1), (2, 2), (2, 1)])) == [1, 1, 2,
2]
testcase = TestCaseGenerator()
testcase.generate()
class Solution:
def __init__(self):
self.dirs = [[0, -1], [0, 1], [1, 0], [-1, 0]]
def numIslands(self, grid):
if not grid: return 0
m = len(grid)
if not m: return 0
n = len(grid[0])
visited = [[False for _ in xrange(n)] for _ in xrange(m)]
cnt = 0
for i in xrange(m):
for j in xrange(n):
if not visited[i][j] and grid[i][j]:
cnt += 1
self.dfs(grid, i, j, visited)
return cnt
def dfs(self, grid, i, j, visited):
m = len(grid)
n = len(grid[0])
visited[i][j] = True
for dir in self.dirs:
i1 = i+dir[0]
j1 = j+dir[1]
if 0 <= i1 < m and 0 <= j1 < n and not visited[i1][j1] and grid[i1][j1]:
self.dfs(grid, i1, j1, visited)
try:
from lintcode import Compare
except ImportError:
class Compare:
@classmethod
def cmp(cls, a, b):
a = a.lower()
b = b.lower()
diff = ord(a)-ord(b)
if diff < 0:
return -1
elif diff > 0:
return 1
else:
return 0
class Solution:
def sortNutsAndBolts(self, nuts, bolts):
assert len(nuts) == len(bolts)
self.quick_sort(nuts, bolts, 0, len(nuts))
def quick_sort(self, nuts, bolts, start, end):
if start >= end:
return
pivot = self.partition(nuts, bolts[start], start, end)
self.partition(bolts, nuts[pivot], start, end)
self.quick_sort(nuts, bolts, start, pivot)
self.quick_sort(nuts, bolts, pivot+1, end)
def partition(self, A, pivot, start, end):
left = start
i = start+1
while i < end:
if Compare.cmp(A[i], pivot) == -1 or Compare.cmp(pivot, A[i]) == 1:
left += 1
A[left], A[i] = A[i], A[left]
i += 1
elif Compare.cmp(A[i], pivot) == 0 or Compare.cmp(pivot, A[i]) == 0:
A[start], A[i] = A[i], A[start]
else:
i += 1
A[start], A[left] = A[left], A[start]
return left
if __name__ == "__main__":
nuts = ['a', 'b', 'd', 'g']
bolts = ['A', 'G', 'D', 'B']
Solution().sortNutsAndBolts(nuts, bolts)
assert nuts == ['a', 'b', 'd', 'g']
assert bolts == ['A', 'B', 'D', 'G']
import sys
import re
from string import lowercase
options = None
def case_normalize_initial(s):
if re.match(r'^[A-Z][a-z]{2,}', s):
return s[0].lower()+s[1:]
else:
return s
def case_normalize_all_words(s):
return " ".join([case_normalize_initial(w) for w in s.split(" ")])
class Term:
def __init__(self, tid, name, synonyms=None, defs=None,
is_a=None, part_of=None):
self.tid      = tid
self.name     = name
self.synonyms = synonyms if synonyms is not None else []
self.defs     = defs     if defs     is not None else []
self.is_a     = is_a     if is_a     is not None else []
self.part_of  = part_of  if part_of  is not None else []
self.parents  = []
self.children = []
self.objects    = []
self.components = []
self.cleanup()
def obo_idspace(self):
if ":" in self.tid:
s = self.tid[:self.tid.index(":")]
if len([c for c in s if c in lowercase]) == len(s):
return s.upper()
else:
return s
else:
m = re.match(r'^(.[A-Za-z_]+)', self.tid)
return m.group(1)
def resolve_references(self, term_by_id, term_by_name=None):
for ptid, pname in self.is_a:
if ptid not in term_by_id:
print >> sys.stderr, "Warning: is_a term '%s' not found, ignoring" % ptid
continue
parent = term_by_id[ptid]
if pname is not None and term_by_name is not None and term_by_name[pname] is not None:
assert parent == term_by_name[pname]
if self in parent.children:
print >> sys.stderr, "Warning: dup is-a parent %s for %s, ignoring" % (ptid, str(self))
else:
self.parents.append(parent)
parent.children.append(self)
for prel, ptid, pname in self.part_of:
if ptid not in term_by_id:
print >> sys.stderr, "Error: part_of term '%s' not found, ignoring" % ptid
continue
pobject = term_by_id[ptid]
if pname is not None and term_by_name is not None and term_by_name[pname] is not None:
assert pobject == term_by_name[pname]
if self in pobject.components:
print >> sys.stderr, "Warning: dup part-of parent %s for %s, ignoring" % (ptid, str(self))
else:
self.objects.append((prel, pobject))
pobject.components.append((prel, self))
def _case_normalize(self, cn_func):
self.name = cn_func(self.name)
for i in range(len(self.synonyms)):
self.synonyms[i] = (cn_func(self.synonyms[i][0]), self.synonyms[i][1])
for i in range(len(self.is_a)):
if self.is_a[i][1] is not None:
self.is_a[i] = (self.is_a[i][0], cn_func(self.is_a[i][1]))
def case_normalize_initial(self):
global case_normalize_initial
self._case_normalize(case_normalize_initial)
def case_normalize_all_words(self):
global case_normalize_all_words
self._case_normalize(case_normalize_all_words)
def cleanup(self):
for i, s in enumerate(self.synonyms):
if s[-1] == ".":
if re.search(r'\b[a-z]{2,}\.$', s):
c = s[:-1]
print >> sys.stderr, "Note: cleanup: '%s' -> '%s'" % (s, c)
self.synonyms[i] = c
def __str__(self):
return "%s (%s)" % (self.name, self.tid)
def parse_obo(f, limit_prefixes=None, include_nameless=False):
all_terms = []
term_by_id = {}
skip_block = True
tid, prefix, name, synonyms, definitions, is_a, part_of, obsolete = None, None, None, [], [], [], [], False
for ln, l in enumerate(f):
if l.strip() == "[Term]":
assert tid is None
assert name is None
assert is_a == []
skip_block = False
if l.strip() == "[Typedef]":
skip_block = True
elif re.match(r'^id:.*', l) and not skip_block:
assert tid is None, str(ln)+' '+tid
l = re.sub(r'\s*\!.*', '', l)
m = re.match(r'^id: (([A-Za-z](?:\S*(?=:)|[A-Za-z_]*)):?\S+)\s*$', l)
if m is None:
print >> sys.stderr, "line %d: failed to match id, ignoring: %s" % (ln, l.rstrip())
tid, prefix, name, synonyms, is_a, part_of, obsolete = None, None, None, [], [], [], False
skip_block = True
else:
tid, prefix = m.groups()
elif re.match(r'^name:.*', l) and not skip_block:
assert tid is not None
assert name is None
m = re.match(r'^name: (.*?)\s*$', l)
assert m is not None
name = m.group(1)
elif re.match(r'^is_a:.*', l) and not skip_block:
assert tid is not None
m = re.match(r'^is_a: (\S+) *(?:\{[^{}]*\} *)?(?:\!.*?)?\! *(.*?)\s*$', l)
if m:
is_a.append(m.groups())
else:
m = re.match(r'^is_a: (\S+)\s*$', l)
if m is not None:
is_a.append((m.group(1), None))
else:
print >> sys.stderr, "Error: failed to parse '%s'; ignoring is_a" % l
elif re.match(r'^relationship:\s*\S*part_of', l) and not skip_block:
assert tid is not None
assert name is not None
m = re.match(r'^relationship: +(?:OBO_REL:)?(\S+) +(\S+) *(?:\{[^{}]*\} *)?\! *(.*?)\s*$', l)
if m:
part_of.append(m.groups())
else:
m = re.match(r'^relationship: +(?:OBO_REL:)?(\S+) +(\S+)\s*$', l)
if m is not None:
part_of.append((m.group(1), m.group(2), None))
else:
print >> sys.stderr, "Error: failed to parse '%s'; ignoring part_of" % l
elif re.match(r'^synonym:.*', l) and not skip_block:
assert tid is not None
assert name is not None
m = re.match(r'^synonym: "(.*)" ([A-Za-z_ ]*?) *\[.*\]\s*$', l)
assert m is not None, "Error: failed to parse '%s'" % l
synstr, syntype = m.groups()
if synstr == "":
print >> sys.stderr, "Note: ignoring empty synonym on line %d: %s" % (ln, l.strip())
else:
synonyms.append((synstr,syntype))
elif re.match(r'^def:.*', l) and not skip_block:
assert tid is not None
assert name is not None
m = re.match(r'^def: "(.*)" *\[.*\]\s*$', l)
assert m is not None, "Error: failed to parse '%s'" % l
definition = m.group(1)
if definition == "":
print >> sys.stderr, "Note: ignoring empty def on line %d: %s" % (ln, l.strip())
else:
definitions.append(definition)
elif re.match(r'^is_obsolete:', l):
m = re.match(r'^is_obsolete:\s*true', l)
if m:
obsolete = True
elif re.match(r'^\s*$', l):
if (tid is None and prefix is None and name is None and
synonyms == [] and definitions == [] and
is_a == [] and part_of == []):
continue
if (obsolete or
(limit_prefixes is not None and prefix not in limit_prefixes)):
tid, prefix, name, synonyms, definitions, is_a, part_of, obsolete = None, None, None, [], [], [], [], False
elif not skip_block:
assert tid is not None, "line %d: no ID for '%s'!" % (ln, name)
if name is None and not include_nameless:
print >> sys.stderr, "Note: ignoring term without name (%s) on line %d" % (tid, ln)
else:
if tid not in term_by_id:
t = Term(tid, name, synonyms, definitions,
is_a, part_of)
all_terms.append(t)
term_by_id[tid] = t
else:
print >> sys.stderr, "Error: duplicate ID '%s'; discarding all but first definition" % tid
tid, prefix, name, synonyms, definitions, is_a, part_of, obsolete = None, None, None, [], [], [], [], False
else:
pass
else:
pass
assert tid is None
assert name is None
assert is_a == []
return all_terms, term_by_id
def argparser():
import argparse
ap=argparse.ArgumentParser(description="Extract terms from OBO ontology.")
ap.add_argument("-l", "--limit", default=None, metavar="PREFIX", help="Limit processing to given ontology prefix or prefixes (multiple separated by \"|\").")
ap.add_argument("-d", "--depth", default=None, metavar="INT", help="Limit extraction to given depth from initial nodes.")
ap.add_argument("-nc", "--no-case-normalization", default=False, action="store_true", help="Skip heuristic case normalization of ontology terms.")
ap.add_argument("-nm", "--no-multiple-inheritance", default=False, action="store_true", help="Exclude subtrees involving multiple inheritance.")
ap.add_argument("-ns", "--no-synonyms", default=False, action="store_true", help="Do not extract synonyms.")
ap.add_argument("-nd", "--no-definitions", default=False, action="store_true", help="Do not extract definitions.")
ap.add_argument("-e", "--exclude", default=[], metavar="TERM", nargs="+", help="Exclude subtrees rooted at given TERMs.")
ap.add_argument("-s", "--separate-children", default=[], default=False, action="store_true", help="Separate subontologies found as children of the given term.")
ap.add_argument("file", metavar="OBO-FILE", help="Source ontology.")
ap.add_argument("-p", "--separate-parents", default=[], default=False, action="store_true", help="Separate subontologies of parents of the given terms.")
ap.add_argument("terms", default=[], metavar="TERM", nargs="*", help="Root terms from which to extract.")
return ap
multiple_parent_skip_count = 0
def get_subtree_terms(root, collection=None, depth=0):
global options
global multiple_parent_skip_count
if collection is None:
collection = []
if root.traversed or root.excluded:
return False
if options.depth is not None and depth > options.depth:
return False
if options.no_multiple_inheritance and len(root.parents) > 1:
if multiple_parent_skip_count < 10:
print >> sys.stderr, "Note: not traversing subtree at %s %s: %d parents" % (root.tid, root.name, len(root.parents))
elif multiple_parent_skip_count == 10:
print >> sys.stderr, "(further 'not traversing subtree; multiple parents' notes suppressed)"
multiple_parent_skip_count += 1
return False
root.traversed = True
collection.append(root)
for child in root.children:
get_subtree_terms(child, collection, depth+1)
return collection
def exclude_subtree(root):
if root.traversed:
return False
root.traversed = True
root.excluded = True
for child in root.children:
exclude_subtree(child)
def main(argv=None):
global options
arg = argparser().parse_args(argv[1:])
options = arg
if arg.depth is not None:
arg.depth = int(arg.depth)
assert arg.depth > 0, "Depth limit cannot be less than or equal to zero"
limit_prefix = arg.limit
if limit_prefix is None:
limit_prefixes = None
else:
limit_prefixes = limit_prefix.split("|")
fn = arg.file
if not arg.no_case_normalization:
for i in range(len(arg.terms)):
arg.terms[i] = case_normalize_initial(arg.terms[i])
f = open(fn)
all_terms, term_by_id = parse_obo(f, limit_prefixes)
for t in all_terms:
t.resolve_references(term_by_id)
if not arg.no_case_normalization:
for t in all_terms:
if t.obo_idspace() in ("FMA", "WBbt"):
t.case_normalize_initial()
elif t.obo_idspace() == "SAO":
t.case_normalize_all_words()
print >> sys.stderr, "OK, parsed %d (non-obsolete) terms." % len(all_terms)
term_by_name = {}
for t in all_terms:
if t.name not in term_by_name:
term_by_name[t.name] = t
else:
print >> sys.stderr, "Warning: duplicate name '%s'; no name->ID mapping possible" % t.name
term_by_name[t.name] = None
for rootterm in arg.terms:
assert arg.separate_parents or rootterm in term_by_name, "Error: given term '%s' not found (or obsolete) in ontology!" % rootterm
for t in all_terms:
t.children = []
t.parents  = []
for t in all_terms:
for ptid, pname in t.is_a:
if ptid not in term_by_id:
print >> sys.stderr, "Error: is_a term '%s' not found, removing" % ptid
continue
parent = term_by_id[ptid]
if pname is not None and pname in term_by_name and term_by_name[pname] is not None:
if parent != term_by_name[pname]:
print >> sys.stderr, "Warning: given parent name '%s' mismatches parent term name (via ID) '%s'" % (parent.name, pname)
if t in parent.children:
print >> sys.stderr, "Warning: ignoring dup parent %s for %s" % (ptid, str(t))
else:
t.parents.append(parent)
parent.children.append(t)
for t in all_terms:
t.traversed = False
t.excluded  = False
for excludeterm in arg.exclude:
assert excludeterm in term_by_name, "Error: exclude term '%s' not found (or obsolete) in ontology!" % excludeterm
exclude_subtree(term_by_name[excludeterm])
for t in all_terms:
t.traversed = False
rootterms = []
if not arg.separate_parents:
for t in arg.terms:
if t not in term_by_name:
print >> sys.stderr, "Error: given term '%s' not found!" % t
return 1
else:
rootterms.append(term_by_name[t])
if len(rootterms) == 0:
for t in all_terms:
if len(t.parents) == 0:
rootterms.append(t)
print >> sys.stderr, "Extracting from %d root terms." % len(rootterms)
else:
assert not arg.separate_children, "Incompatible arguments"
unique_parents = {}
for t in arg.terms:
if t in term_by_name:
for p in term_by_name[t].parents:
unique_parents[p] = True
assert len(unique_parents) != 0, "Failed to find any of given terms"
for p in unique_parents:
p.excluded = True
rootterms = [p for p in unique_parents]
rootterms.sort(lambda a,b: cmp(a.name,b.name))
arg.separate_children = True
print >> sys.stderr, "Splitting at the following:", ",".join(rootterms)
for rootterm in rootterms:
if not arg.separate_children:
for t in get_subtree_terms(rootterm):
strs = []
strs.append("name:Name:"+t.name)
if not arg.no_synonyms:
for synstr, syntype in t.synonyms:
strs.append("name:Synonym:"+synstr)
if not arg.no_definitions:
for d in t.defs:
strs.append("info:Definition:"+d)
id_ = t.tid.replace(t.obo_idspace()+':', '', 1)
print id_ + '\t' + '\t'.join(strs)
else:
for c in rootterm.children:
stt = []
get_subtree_terms(c, stt)
for n, tid, ntype in stt:
print "%s\t%s\t%s\t%s" % (c.name, n, tid, ntype)
if __name__ == "__main__":
sys.exit(main(sys.argv))
import sys
from urlparse import urlparse, urljoin
from os.path import dirname, join as joinpath
from os import makedirs
from urllib import urlopen
from simplejson import loads
try:
base_url = sys.argv[1]
url = urlparse(base_url)
except:
print sys.argv[1]
print "Syntax: %s <url>" % sys.argv[0]
sys.exit(1)
this_dir = dirname(sys.argv[0])
datadir = joinpath(this_dir, '../offline_data')
coll_and_doc = url.fragment
coll = dirname(coll_and_doc)[1:]
def convert_coll(coll):
if coll == '':
ajax_coll = '/'
else:
ajax_coll = '/%s/' % coll
coll_query_url = urljoin(base_url, 'ajax.cgi?action=getCollectionInformation&collection=%s' % ajax_coll)
coll_dir = joinpath(datadir, coll)
try:
makedirs(coll_dir)
except:
pass
print ajax_coll
conn = urlopen(coll_query_url)
jsonp = conn.read()
conn.close
with open(joinpath(coll_dir, 'collection.js'), 'w') as f:
f.write("jsonp=")
f.write(jsonp)
coll_data = loads(jsonp)
for item in coll_data['items']:
if item[0] == 'd':
doc = item[2]
print "  %s" % doc
doc_query_url = urljoin(base_url, 'ajax.cgi?action=getDocument&collection=%s&document=%s' % (ajax_coll, doc))
conn = urlopen(doc_query_url)
jsonp = conn.read()
conn.close
with open(joinpath(coll_dir, '%s.data.js' % doc), 'w') as f:
f.write("jsonp=")
f.write(jsonp)
elif item[0] == 'c' and item[2] != '..':
convert_coll(item[2])
convert_coll(coll)
import gtk
import ns.core
import ns.network
import ns.internet
import ns.olsr
from visualizer.base import InformationWindow
class ShowOlsrRoutingTable(InformationWindow):
(
COLUMN_DESTINATION,
COLUMN_NEXT_HOP,
COLUMN_INTERFACE,
COLUMN_NUM_HOPS,
) = range(4)
def __init__(self, visualizer, node_index):
InformationWindow.__init__(self)
self.win = gtk.Dialog(parent=visualizer.window,
flags=gtk.DIALOG_DESTROY_WITH_PARENT|gtk.DIALOG_NO_SEPARATOR,
buttons=(gtk.STOCK_CLOSE, gtk.RESPONSE_CLOSE))
self.win.set_default_size(gtk.gdk.screen_width()/2, gtk.gdk.screen_height()/2)
self.win.connect("response", self._response_cb)
self.win.set_title("OLSR routing table for node %i" % node_index)
self.visualizer = visualizer
self.node_index = node_index
self.table_model = gtk.ListStore(str, str, str, int)
treeview = gtk.TreeView(self.table_model)
treeview.show()
sw = gtk.ScrolledWindow()
sw.set_properties(hscrollbar_policy=gtk.POLICY_AUTOMATIC,
vscrollbar_policy=gtk.POLICY_AUTOMATIC)
sw.show()
sw.add(treeview)
self.win.vbox.add(sw)
column = gtk.TreeViewColumn('Destination', gtk.CellRendererText(),
text=self.COLUMN_DESTINATION)
treeview.append_column(column)
column = gtk.TreeViewColumn('Next hop', gtk.CellRendererText(),
text=self.COLUMN_NEXT_HOP)
treeview.append_column(column)
column = gtk.TreeViewColumn('Interface', gtk.CellRendererText(),
text=self.COLUMN_INTERFACE)
treeview.append_column(column)
column = gtk.TreeViewColumn('Num. Hops', gtk.CellRendererText(),
text=self.COLUMN_NUM_HOPS)
treeview.append_column(column)
self.visualizer.add_information_window(self)
self.win.show()
def _response_cb(self, win, response):
self.win.destroy()
self.visualizer.remove_information_window(self)
def update(self):
node = ns.network.NodeList.GetNode(self.node_index)
olsr = node.GetObject(ns.olsr.olsr.RoutingProtocol.GetTypeId())
ipv4 = node.GetObject(ns.internet.Ipv4.GetTypeId())
if olsr is None:
return
self.table_model.clear()
for route in olsr.GetRoutingTableEntries():
tree_iter = self.table_model.append()
netdevice = ipv4.GetNetDevice(route.interface)
if netdevice is None:
interface_name = 'lo'
else:
interface_name = ns.core.Names.FindName(netdevice)
if not interface_name:
interface_name = "(interface %i)" % route.interface
self.table_model.set(tree_iter,
self.COLUMN_DESTINATION, str(route.destAddr),
self.COLUMN_NEXT_HOP, str(route.nextAddr),
self.COLUMN_INTERFACE, interface_name,
self.COLUMN_NUM_HOPS, route.distance)
def populate_node_menu(viz, node, menu):
ns3_node = ns.network.NodeList.GetNode(node.node_index)
olsr = ns3_node.GetObject(ns.olsr.olsr.RoutingProtocol.GetTypeId())
if olsr is None:
print "No OLSR"
return
menu_item = gtk.MenuItem("Show OLSR Routing Table")
menu_item.show()
def _show_ipv4_routing_table(dummy_menu_item):
ShowOlsrRoutingTable(viz, node.node_index)
menu_item.connect("activate", _show_ipv4_routing_table)
menu.add(menu_item)
def register(viz):
viz.connect("populate-node-menu", populate_node_menu)
from facerec_py.facerec.feature import AbstractFeature
import numpy as np
class FeatureOperator(AbstractFeature):
def __init__(self, model1, model2):
if (not isinstance(model1, AbstractFeature)) or (not isinstance(model2, AbstractFeature)):
raise Exception("A FeatureOperator only works on classes implementing an AbstractFeature!")
self.model1 = model1
self.model2 = model2
def __repr__(self):
return "FeatureOperator(" + repr(self.model1) + "," + repr(self.model2) + ")"
class ChainOperator(FeatureOperator):
def __init__(self, model1, model2):
FeatureOperator.__init__(self, model1, model2)
def compute(self, X, y):
X = self.model1.compute(X, y)
return self.model2.compute(X, y)
def extract(self, X):
X = self.model1.extract(X)
return self.model2.extract(X)
def __repr__(self):
return "ChainOperator(" + repr(self.model1) + "," + repr(self.model2) + ")"
class CombineOperator(FeatureOperator):
def __init__(self, model1, model2):
FeatureOperator.__init__(self, model1, model2)
def compute(self, X, y):
A = self.model1.compute(X, y)
B = self.model2.compute(X, y)
C = []
for i in range(0, len(A)):
ai = np.asarray(A[i]).reshape(1, -1)
bi = np.asarray(B[i]).reshape(1, -1)
C.append(np.hstack((ai, bi)))
return C
def extract(self, X):
ai = self.model1.extract(X)
bi = self.model2.extract(X)
ai = np.asarray(ai).reshape(1, -1)
bi = np.asarray(bi).reshape(1, -1)
return np.hstack((ai, bi))
def __repr__(self):
return "CombineOperator(" + repr(self.model1) + "," + repr(self.model2) + ")"
class CombineOperatorND(FeatureOperator):
def __init__(self, model1, model2, hstack=True):
FeatureOperator.__init__(self, model1, model2)
self._hstack = hstack
def compute(self, X, y):
A = self.model1.compute(X, y)
B = self.model2.compute(X, y)
C = []
for i in range(0, len(A)):
if self._hstack:
C.append(np.hstack((A[i], B[i])))
else:
C.append(np.vstack((A[i], B[i])))
return C
def extract(self, X):
ai = self.model1.extract(X)
bi = self.model2.extract(X)
if self._hstack:
return np.hstack((ai, bi))
return np.vstack((ai, bi))
def __repr__(self):
return "CombineOperatorND(" + repr(self.model1) + "," + repr(self.model2) + ", hstack=" + str(
self._hstack) + ")"
try:
from thread import get_ident as _get_ident
except ImportError:
from dummy_thread import get_ident as _get_ident
try:
from _abcoll import KeysView, ValuesView, ItemsView
except ImportError:
pass
class OrderedDict(dict):
'Dictionary that remembers insertion order'
def __init__(self, *args, **kwds):
if len(args) > 1:
raise TypeError('expected at most 1 arguments, got %d' % len(args))
try:
self.__root
except AttributeError:
self.__root = root = []
root[:] = [root, root, None]
self.__map = {}
self.__update(*args, **kwds)
def __setitem__(self, key, value, dict_setitem=dict.__setitem__):
'od.__setitem__(i, y) <==> od[i]=y'
if key not in self:
root = self.__root
last = root[0]
last[1] = root[0] = self.__map[key] = [last, root, key]
dict_setitem(self, key, value)
def __delitem__(self, key, dict_delitem=dict.__delitem__):
'od.__delitem__(y) <==> del od[y]'
dict_delitem(self, key)
link_prev, link_next, key = self.__map.pop(key)
link_prev[1] = link_next
link_next[0] = link_prev
def __iter__(self):
'od.__iter__() <==> iter(od)'
root = self.__root
curr = root[1]
while curr is not root:
yield curr[2]
curr = curr[1]
def __reversed__(self):
'od.__reversed__() <==> reversed(od)'
root = self.__root
curr = root[0]
while curr is not root:
yield curr[2]
curr = curr[0]
def clear(self):
'od.clear() -> None.  Remove all items from od.'
try:
for node in self.__map.itervalues():
del node[:]
root = self.__root
root[:] = [root, root, None]
self.__map.clear()
except AttributeError:
pass
dict.clear(self)
def popitem(self, last=True):
if not self:
raise KeyError('dictionary is empty')
root = self.__root
if last:
link = root[0]
link_prev = link[0]
link_prev[1] = root
root[0] = link_prev
else:
link = root[1]
link_next = link[1]
root[1] = link_next
link_next[0] = root
key = link[2]
del self.__map[key]
value = dict.pop(self, key)
return key, value
def keys(self):
'od.keys() -> list of keys in od'
return list(self)
def values(self):
'od.values() -> list of values in od'
return [self[key] for key in self]
def items(self):
'od.items() -> list of (key, value) pairs in od'
return [(key, self[key]) for key in self]
def iterkeys(self):
'od.iterkeys() -> an iterator over the keys in od'
return iter(self)
def itervalues(self):
'od.itervalues -> an iterator over the values in od'
for k in self:
yield self[k]
def iteritems(self):
'od.iteritems -> an iterator over the (key, value) items in od'
for k in self:
yield (k, self[k])
def update(*args, **kwds):
if len(args) > 2:
raise TypeError('update() takes at most 2 positional '
'arguments (%d given)' % (len(args),))
elif not args:
raise TypeError('update() takes at least 1 argument (0 given)')
self = args[0]
other = ()
if len(args) == 2:
other = args[1]
if isinstance(other, dict):
for key in other:
self[key] = other[key]
elif hasattr(other, 'keys'):
for key in other.keys():
self[key] = other[key]
else:
for key, value in other:
self[key] = value
for key, value in kwds.items():
self[key] = value
__update = update
__marker = object()
def pop(self, key, default=__marker):
if key in self:
result = self[key]
del self[key]
return result
if default is self.__marker:
raise KeyError(key)
return default
def setdefault(self, key, default=None):
'od.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in od'
if key in self:
return self[key]
self[key] = default
return default
def __repr__(self, _repr_running={}):
'od.__repr__() <==> repr(od)'
call_key = id(self), _get_ident()
if call_key in _repr_running:
return '...'
_repr_running[call_key] = 1
try:
if not self:
return '%s()' % (self.__class__.__name__,)
return '%s(%r)' % (self.__class__.__name__, self.items())
finally:
del _repr_running[call_key]
def __reduce__(self):
'Return state information for pickling'
items = [[k, self[k]] for k in self]
inst_dict = vars(self).copy()
for k in vars(OrderedDict()):
inst_dict.pop(k, None)
if inst_dict:
return (self.__class__, (items,), inst_dict)
return self.__class__, (items,)
def copy(self):
'od.copy() -> a shallow copy of od'
return self.__class__(self)
@classmethod
def fromkeys(cls, iterable, value=None):
d = cls()
for key in iterable:
d[key] = value
return d
def __eq__(self, other):
if isinstance(other, OrderedDict):
return len(self)==len(other) and self.items() == other.items()
return dict.__eq__(self, other)
def __ne__(self, other):
return not self == other
def viewkeys(self):
"od.viewkeys() -> a set-like object providing a view on od's keys"
return KeysView(self)
def viewvalues(self):
"od.viewvalues() -> an object providing a view on od's values"
return ValuesView(self)
def viewitems(self):
"od.viewitems() -> a set-like object providing a view on od's items"
return ItemsView(self)
class Solution(object):
def solve(self, cipher):
N, K, lst = cipher
hm = {}
for val in lst:
if val in hm:
hm[val] += 1
else:
hm[val] = 1
cnt = 0
for val in lst:
target = val + K
if target in hm:
cnt += hm[target]
return cnt
if __name__ == "__main__":
import sys
f = open("1.in", "r")
N, K = map(int, f.readline().strip().split(' '))
lst = map(int, f.readline().strip().split(' '))
cipher = N, K, lst
s = "%s\n" % (Solution().solve(cipher))
print s,
class Solution_TLE(object):
def solve(self, cipher):
for i in xrange(len(cipher)):
if self.__is_palindrome(cipher[:i] + cipher[i + 1:]):
return i
return -1
def __is_palindrome(self, s):
return s == s[::-1]
class Solution(object):
def solve(self, cipher):
l = len(cipher)
start = 0
end = l - 1
while start < end and cipher[start] == cipher[end]:
start += 1
end -= 1
if self.__is_palindrome(cipher[:start] + cipher[start + 1:]):
return start
if self.__is_palindrome(cipher[:end] + cipher[end + 1:]):
return end
if start >= end:
return -1
def __is_palindrome(self, s):
return s == s[::-1]
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = f.readline().strip()
s = "%s\n" % (Solution().solve(cipher))
print s,
class Solution:
def partition(self, s):
ret = []
self.backtrack(s, [], ret)
return ret
def backtrack(self, s, cur_lvl, ret):
if not s:
ret.append(list(cur_lvl))
for i in xrange(1, len(s)+1):
if self.predicate(s[:i]):
cur_lvl.append(s[:i])
self.backtrack(s[i:], cur_lvl, ret)
cur_lvl.pop()
def predicate(self, s):
return s == s[::-1]
if __name__ == "__main__":
assert Solution().partition("aabbc") == [['a', 'a', 'b', 'b', 'c'], ['a', 'a', 'bb', 'c'], ['aa', 'b', 'b', 'c'], ['aa', 'bb', 'c']]
class Solution(object):
def solve(self, cipher):
bucket = [False for _ in xrange(26)]
for char in cipher:
char = char.lower()
ind = ord(char) - ord('a')
try:
bucket[ind] = True
except IndexError:
pass
is_pangram = all(bucket)
if is_pangram:
return "pangram"
else:
return "not pangram"
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = 1
for t in xrange(testcases):
cipher = f.readline().strip()
s = "%s\n" % (Solution().solve(cipher))
print s,
import numpy as np
def parzen_estimation(x_samples, point_x, h):
k_n = 0
for row in x_samples:
x_i = (point_x - row[:, np.newaxis]) / h
for row in x_i:
if np.abs(row) > 1/2:
break
else:
k_n += 1
return (k_n / len(x_samples)) / (h**point_x.shape[1])
class Image(object):
def __init__(self, id, caption, url):
self.id = id
self.caption = caption
self.url = url
class Image(object):
__slots__ = ['id', 'caption', 'url']
def __init__(self, id, caption, url):
self.id = id
self.caption = caption
self.url = url
from collections import defaultdict
class Solution(object):
def permutationIndexII(self, A):
idx = 0
factor = 1
cnt = defaultdict(int)
cnt[A[-1]] += 1
n = len(A)
for i in xrange(n-2, -1, -1):
cnt[A[i]] += 1
for k, v in cnt.items():
if k < A[i]:
idx += v * factor / cnt[A[i]]
factor = factor * (n-i) / cnt[A[i]]
return idx+1
if __name__ == "__main__":
print Solution().permutationIndexII([1, 4, 2, 2])
import math
class Solution:
def permutationIndex(self, A):
n = len(A)
idx = 0
for i, v in enumerate(A):
inv = 0
for j in xrange(i+1, n):
if A[i] > A[j]:
inv += 1
idx += inv * math.factorial(n-1-i)
return idx+1
import math
class Solution:
def getPermutation(self, n, k):
k -= 1
array = range(1, n+1)
k %= math.factorial(n)
ret = []
for i in xrange(n-1, -1, -1):
idx, k = divmod(k, math.factorial(i))
ret.append(array.pop(idx))
return "".join(map(str, ret))
MOD = 1000000007
class Solution(object):
def solve(self, cipher):
N, A = cipher
cnts = [0 for _ in xrange(N + 1)]
for num in A:
cnts[num] += 1
if 0 not in cnts:
return 0
result = 1
paths = cnts[0]
for i in xrange(1, N):
if paths <= 0:
return 0
result *= paths
result %= MOD
paths += cnts[i]
paths -= 1
return result
if __name__ == "__main__":
import sys
f = open("1.in", "r")
solution = Solution()
testcases = int(f.readline().strip())
for t in xrange(testcases):
N = int(f.readline().strip())
A = map(int, f.readline().strip().split(' '))
cipher = N, A
s = "%s\n" % (solution.solve(cipher))
print s,
import pickle
import os
import codecs
def dump_pickles(out, dirname, filename, path):
f = open(os.path.join(dirname, filename), 'r')
data = pickle.load(f)
fragment_file = codecs.open(data['current_page_name'] + '.frag', mode='w', encoding='utf-8')
fragment_file.write(data['body'])
fragment_file.close()
out.write('  <page url="%s">\n' % path)
out.write('    <fragment>%s.frag</fragment>\n' % data['current_page_name'])
if data['prev'] is not None:
out.write('    <prev url="%s">%s</prev>\n' %
(os.path.normpath(os.path.join(path, data['prev']['link'])),
data['prev']['title']))
if data['next'] is not None:
out.write('    <next url="%s">%s</next>\n' %
(os.path.normpath(os.path.join(path, data['next']['link'])),
data['next']['title']))
out.write('  </page>\n')
f.close()
if data['next'] is not None:
next_path = os.path.normpath(os.path.join(path, data['next']['link']))
next_filename = os.path.basename(next_path) + '.fpickle'
dump_pickles(out, dirname, next_filename, next_path)
return
import sys
sys.stdout.write('<pages>\n')
dump_pickles(sys.stdout, os.path.dirname(sys.argv[1]), os.path.basename(sys.argv[1]), '/')
sys.stdout.write('</pages>')
import Options
import Configure
import subprocess
import config_c
import sys
def configure(conf):
pkg_config = conf.find_program('pkg-config', var='PKG_CONFIG')
if not pkg_config: return
@Configure.conf
def pkg_check_modules(conf, uselib_name, expression, mandatory=True):
pkg_config = conf.env['PKG_CONFIG']
if not pkg_config:
if mandatory:
conf.fatal("pkg-config is not available")
else:
return False
if Options.options.verbose:
extra_msg = ' (%s)' % expression
else:
extra_msg = ''
conf.start_msg('Checking for pkg-config flags for %s%s' % (uselib_name, extra_msg))
argv = [pkg_config, '--cflags', '--libs', expression]
cmd = subprocess.Popen(argv, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
out, err = cmd.communicate()
retval = cmd.wait()
conf.to_log('%r: %r (exit code %i)\n%s' % (argv, out, retval, err))
if retval != 0:
conf.end_msg(False)
sys.stderr.write(err)
else:
if Options.options.verbose:
conf.end_msg(out)
else:
conf.end_msg(True)
if retval == 0:
conf.parse_flags(out, uselib_name, conf.env)
conf.env[uselib_name] = True
return True
else:
conf.env[uselib_name] = False
if mandatory:
raise Configure.ConfigurationError('pkg-config check failed')
else:
return False
@Configure.conf
def pkg_check_module_variable(conf, module, variable):
pkg_config = conf.env['PKG_CONFIG']
if not pkg_config:
conf.fatal("pkg-config is not available")
argv = [pkg_config, '--variable', variable, module]
cmd = subprocess.Popen(argv, stdout=subprocess.PIPE)
out, dummy = cmd.communicate()
retval = cmd.wait()
out = out.rstrip()
msg_checking = ("Checking for pkg-config variable %r in %s" % (variable, module,))
conf.check_message_custom(msg_checking, '', out)
conf.log.write('%r: %r (exit code %i)\n' % (argv, out, retval))
if retval == 0:
return out
else:
raise Configure.ConfigurationError('pkg-config check failed')
class Solution(object):
def solve(self, cipher):
N, v = cipher
v.reverse()
s = [0 for _ in xrange(N + 1)]
for i in xrange(1, N + 1):
s[i] = s[i - 1] + v[i - 1]
f = [[0, 0] for _ in xrange(N + 1)]
for i in xrange(1, N + 1):
local_max = 0
for k in xrange(1, 4):
if i - k >= 0:
local_max = max(local_max, s[i] - s[i - k] + s[i - k] - f[i - k][1])
f[i][0] = local_max
local_max = 0
for k in xrange(1, 4):
if i - k >= 0:
local_max = max(local_max, s[i] - s[i - k] + s[i - k] - f[i - k][0])
f[i][1] = local_max
return f[-1][0]
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
N = int(f.readline().strip())
lst = map(lambda x: int(x), f.readline().strip().split(" "))
cipher = [N, lst]
s = "%s\n" % (Solution().solve(cipher))
print s,
import matplotlib.pyplot as plt
class Plotter(object):
def plot(self, L_lst):
plt.figure("Log_likelihood")
plt.ylabel("L: Log-likelihood")
plt.xlabel("N: number of iterations")
plt.plot([i+1 for i in xrange(len(L_lst))], L_lst)
plt.show()
class Plotter2D(object):
def label(self, name, x_label, y_label):
plt.figure(name)
plt.xlabel(x_label)
plt.ylabel(y_label)
def plot_line(self, x1, y1, x2, y2):
plt.plot([x1, x2], [y1, y2])
def plot_scatter(self, X, Y, color="b"):
plt.scatter(X, Y, c=color)
def show(self):
plt.show()
import math
class Solution(object):
def solve(self, cipher):
cipher.sort(cmp=self.cmp)
def cmp_polar(self, a, b):
x1 = a[0]
y1 = a[1]
x2 = b[0]
y2 = b[1]
cross_product = x1 * y2 - x2 * y1
if cross_product > 0:
return -1
elif cross_product < 0:
return 1
else:
if x1 * x1 >= 0 and y1 * y1 >= 0:
return x1 * x1 + y1 * y1 - x2 * x2 - y2 * y2
else:
if y1 > 0:
return -1
if y2 > 0:
return 1
if y1 == 0 and x1 > 0:
return -1
else:
return 1
def cmp(self, a, b):
x1 = a[0]
y1 = a[1]
x2 = b[0]
y2 = b[1]
r1 = x1 * x1 + y1 * y1
r2 = x2 * x2 + y2 * y2
phi1 = math.atan2(y1, x1)
phi2 = math.atan2(y2, x2)
if phi1 < 0:
phi1 += math.pi * 2
if phi2 < 0:
phi2 += math.pi * 2
if phi1 < phi2:
return -1
elif phi1 > phi2:
return 1
else:
return r1 - r2
if __name__ == "__main__":
import sys
f = open("1.in", "r")
N = int(f.readline().strip())
cipher = []
for t in xrange(N):
cipher.append(map(int, f.readline().strip().split(' ')))
Solution().solve(cipher)
for point in cipher:
print "%d %d" % (point[0], point[1])
import logging
from ._collections import RecentlyUsedContainer
from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool
from .connectionpool import connection_from_url, port_by_scheme
from .request import RequestMethods
from .util import parse_url
__all__ = ['PoolManager', 'ProxyManager', 'proxy_from_url']
pool_classes_by_scheme = {
'http': HTTPConnectionPool,
'https': HTTPSConnectionPool,
}
log = logging.getLogger(__name__)
class PoolManager(RequestMethods):
def __init__(self, num_pools=10, headers=None, **connection_pool_kw):
RequestMethods.__init__(self, headers)
self.connection_pool_kw = connection_pool_kw
self.pools = RecentlyUsedContainer(num_pools,
dispose_func=lambda p: p.close())
def clear(self):
self.pools.clear()
def connection_from_host(self, host, port=None, scheme='http'):
port = port or port_by_scheme.get(scheme, 80)
pool_key = (scheme, host, port)
pool = self.pools.get(pool_key)
if pool:
return pool
pool_cls = pool_classes_by_scheme[scheme]
pool = pool_cls(host, port, **self.connection_pool_kw)
self.pools[pool_key] = pool
return pool
def connection_from_url(self, url):
u = parse_url(url)
return self.connection_from_host(u.host, port=u.port, scheme=u.scheme)
def urlopen(self, method, url, redirect=True, **kw):
u = parse_url(url)
conn = self.connection_from_host(u.host, port=u.port, scheme=u.scheme)
kw['assert_same_host'] = False
kw['redirect'] = False
if 'headers' not in kw:
kw['headers'] = self.headers
response = conn.urlopen(method, u.request_uri, **kw)
redirect_location = redirect and response.get_redirect_location()
if not redirect_location:
return response
if response.status == 303:
method = 'GET'
log.info("Redirecting %s -> %s" % (url, redirect_location))
kw['retries'] = kw.get('retries', 3) - 1
return self.urlopen(method, redirect_location, **kw)
class ProxyManager(RequestMethods):
def __init__(self, proxy_pool):
self.proxy_pool = proxy_pool
def _set_proxy_headers(self, headers=None):
headers_ = {'Accept': '*/*'}
if headers:
headers_.update(headers)
return headers_
def urlopen(self, method, url, **kw):
"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute."
kw['assert_same_host'] = False
kw['headers'] = self._set_proxy_headers(kw.get('headers'))
return self.proxy_pool.urlopen(method, url, **kw)
def proxy_from_url(url, **pool_kw):
proxy_pool = connection_from_url(url, **pool_kw)
return ProxyManager(proxy_pool)
class Solution(object):
def solve(self, cipher):
a, b, x, y = cipher
if self.gcd(a, b) == self.gcd(x, y):
return "YES"
else:
return "NO"
def gcd(self, a, b):
while b:
a, b = b, a % b
return a
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = map(int, f.readline().strip().split(' '))
s = "%s\n" % (Solution().solve(cipher))
print s,
class Solution:
def postOffice_TLE(self, A, K):
A.sort()
N = len(A)
F = [[0 for _ in xrange(K+1)] for _ in xrange(N+1)]
c = [[0 for _ in xrange(N+1)] for _ in xrange(N+1)]
for i in xrange(N):
for j in xrange(i+1, N+1):
m = (i+j)/2
for l in xrange(i, j):
c[i][j] += abs(A[m]-A[l])
for n in xrange(1, N+1):
F[n][1] = c[0][n]
for n in xrange(1, N+1):
for k in xrange(2, K+1):
F[n][k] = min(
F[l][k-1]+c[l][n] for l in xrange(n)
)
return F[N][K]
def postOffice_TLE(self, A, K):
if __name__ == "__main__":
assert Solution().postOffice([112,122,360,311,85,225,405,53,405,43,342,13,588,424,299,37,104,289,404,414], 3) == 673
from multiprocessing import Process
import requests
from docopt import docopt
N = 100
class Poster(Process):
def __init__(self, url, data=None):
self.client = requests.session()
self.common_headers = {
"Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
"Accept-Encoding": "gzip,deflate,sdch",
"Accept-Language": "en-US,en;q=0.8,zh;q=0.6,zh-CN;q=0.4",
"Cache-Control": "max-age=0",
"Content-Type": "application/json",
"Connection": "keep-alive",
"User-Agent": "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 Safari/537.36"
}
self.url = url
self.data = data
super(Poster, self).__init__()
def post(self):
response = self.client.post(self.url, json=self.data,
headers=self.common_headers)
return response
def run(self):
while True:
response = self.post()
print response.text
if __name__ == "__main__":
options = docopt(__doc__, version='poster 0.0.1')
url = options['<url>']
data = options['<post_data>']
n = N
if options['--num_process']:
n = int(options['<num>'])
print "running with number of processes: %d" % n
for i in xrange(n):
Poster(url, data).start()
import numpy as np
from facerec_py.facerec.feature import AbstractFeature
from facerec_py.facerec.util import asColumnMatrix
from scipy import ndimage
from scipy.misc import imresize
class Resize(AbstractFeature):
def __init__(self, size):
AbstractFeature.__init__(self)
self._size = size
def compute(self, X, y):
Xp = []
for xi in X:
Xp.append(self.extract(xi))
return Xp
def extract(self, X):
return imresize(X, self._size)
def __repr__(self):
return "Resize (size=%s)" % (self._size,)
class HistogramEqualization(AbstractFeature):
def __init__(self, num_bins=256):
AbstractFeature.__init__(self)
self._num_bins = num_bins
def compute(self, X, y):
Xp = []
for xi in X:
Xp.append(self.extract(xi))
return Xp
def extract(self, X):
h, b = np.histogram(X.flatten(), self._num_bins, normed=True)
cdf = h.cumsum()
cdf = 255 * cdf / cdf[-1]
return np.interp(X.flatten(), b[:-1], cdf).reshape(X.shape)
def __repr__(self):
return "HistogramEqualization (num_bins=%s)" % (self._num_bins)
class TanTriggsPreprocessing(AbstractFeature):
def __init__(self, alpha=0.1, tau=10.0, gamma=0.2, sigma0=1.0, sigma1=2.0):
AbstractFeature.__init__(self)
self._alpha = float(alpha)
self._tau = float(tau)
self._gamma = float(gamma)
self._sigma0 = float(sigma0)
self._sigma1 = float(sigma1)
def compute(self, X, y):
Xp = []
for xi in X:
Xp.append(self.extract(xi))
return Xp
def extract(self, X):
X = np.array(X, dtype=np.float32)
X = np.power(X, self._gamma)
X = np.asarray(ndimage.gaussian_filter(X, self._sigma1) - ndimage.gaussian_filter(X, self._sigma0))
X = X / np.power(np.mean(np.power(np.abs(X), self._alpha)), 1.0 / self._alpha)
X = X / np.power(np.mean(np.power(np.minimum(np.abs(X), self._tau), self._alpha)), 1.0 / self._alpha)
X = self._tau * np.tanh(X / self._tau)
return X
def __repr__(self):
return "TanTriggsPreprocessing (alpha=%.3f,tau=%.3f,gamma=%.3f,sigma0=%.3f,sigma1=%.3f)" % (
self._alpha, self._tau, self._gamma, self._sigma0, self._sigma1)
from facerec_py.facerec.lbp import ExtendedLBP
class LBPPreprocessing(AbstractFeature):
def __init__(self, lbp_operator=ExtendedLBP(radius=1, neighbors=8)):
AbstractFeature.__init__(self)
self._lbp_operator = lbp_operator
def compute(self, X, y):
Xp = []
for xi in X:
Xp.append(self.extract(xi))
return Xp
def extract(self, X):
return self._lbp_operator(X)
def __repr__(self):
return "LBPPreprocessing (lbp_operator=%s)" % (repr(self._lbp_operator))
from facerec_py.facerec.normalization import zscore, minmax
class MinMaxNormalizePreprocessing(AbstractFeature):
def __init__(self, low=0, high=1):
AbstractFeature.__init__(self)
self._low = low
self._high = high
def compute(self, X, y):
Xp = []
XC = asColumnMatrix(X)
self._min = np.min(XC)
self._max = np.max(XC)
for xi in X:
Xp.append(self.extract(xi))
return Xp
def extract(self, X):
return minmax(X, self._low, self._high, self._min, self._max)
def __repr__(self):
return "MinMaxNormalizePreprocessing (low=%s, high=%s)" % (self._low, self._high)
class ZScoreNormalizePreprocessing(AbstractFeature):
def __init__(self):
AbstractFeature.__init__(self)
self._mean = 0.0
self._std = 1.0
def compute(self, X, y):
XC = asColumnMatrix(X)
self._mean = XC.mean()
self._std = XC.std()
Xp = []
for xi in X:
Xp.append(self.extract(xi))
return Xp
def extract(self, X):
return zscore(X, self._mean, self._std)
def __repr__(self):
return "ZScoreNormalizePreprocessing (mean=%s, std=%s)" % (self._mean, self._std)
import sys, os
sys.path.append("../..")
from facerec.feature import Fisherfaces, PCA, SpatialHistogram, Identity
from facerec.distance import EuclideanDistance, ChiSquareDistance
from facerec.classifier import NearestNeighbor
from facerec.model import PredictableModel
from facerec.validation import KFoldCrossValidation
from facerec.visual import subplot
from facerec.util import minmax_normalize
from facerec.serialization import save_model, load_model
import numpy as np
try:
from PIL import Image
except ImportError:
import Image
import matplotlib.cm as cm
import logging
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from facerec.lbp import LPQ, ExtendedLBP
class FileNameFilter:
def __init__(self, name):
self._name = name
def __call__(self, filename):
return True
def __repr__(self):
return "FileNameFilter (name=%s)" % (self._name)
class YaleBaseFilter(FileNameFilter):
def __init__(self, min_azimuth, max_azimuth, min_elevation, max_elevation):
FileNameFilter.__init__(self, "Filter YaleFDB Subset1")
self._min_azimuth = min_azimuth
self._max_azimuth = max_azimuth
self._min_elevation = min_elevation
self._max_elevation = max_elevation
def __call__(self, filename):
filetype = filename[-4:]
if filetype != ".pgm":
return False
if "Ambient" in filename:
return False
azimuth = int(filename[12:16])
elevation = int(filename[17:20])
if azimuth < self._min_azimuth or azimuth > self._max_azimuth:
return False
if elevation < self._min_elevation or elevation > self._max_elevation:
return False
return True
def read_images(path, fileNameFilter=FileNameFilter("None"), sz=None):
c = 0
X,y = [], []
for dirname, dirnames, filenames in os.walk(path):
for subdirname in dirnames:
subject_path = os.path.join(dirname, subdirname)
for filename in os.listdir(subject_path):
if fileNameFilter(filename):
print filename
try:
im = Image.open(os.path.join(subject_path, filename))
im = im.convert("L")
if (sz is not None):
im = im.resize(self.sz, Image.ANTIALIAS)
X.append(np.asarray(im, dtype=np.uint8))
y.append(c)
except IOError, (errno, strerror):
print "I/O error({0}): {1}".format(errno, strerror)
except:
print "Unexpected error:", sys.exc_info()[0]
raise
c = c+1
return [X,y]
if __name__ == "__main__":
out_dir = None
if len(sys.argv) < 2:
print "USAGE: facerec_demo.py </path/to/images>"
sys.exit()
yale_filter = YaleBaseFilter(-25, 25, -25, 25)
[X,y] = read_images(sys.argv[1], yale_filter)
handler = logging.StreamHandler(sys.stdout)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger = logging.getLogger("facerec")
logger.addHandler(handler)
logger.setLevel(logging.DEBUG)
feature = PCA()
classifier = NearestNeighbor(dist_metric=EuclideanDistance(), k=1)
model = PredictableModel(feature=feature, classifier=classifier)
model.compute(X, y)
E = []
for i in xrange(min(model.feature.eigenvectors.shape[1], 16)):
e = model.feature.eigenvectors[:,i].reshape(X[0].shape)
E.append(minmax_normalize(e,0,255, dtype=np.uint8))
subplot(title="Fisherfaces", images=E, rows=4, cols=4, sptitle="Fisherface", colormap=cm.jet, filename="fisherfaces.png")
cv = KFoldCrossValidation(model, k=10)
cv.validate(X, y)
cv.print_results()
class Solution:
def previousPermuation(self, num):
n = len(num)
partition = n-2
while partition >= 0 and num[partition] <= num[partition+1]:
partition -= 1
if partition < 0:
return num[::-1]
change = n-1
while change >= 0 and num[change] >= num[partition]:
change -= 1
num[partition], num[change] = num[change], num[partition]
num[partition+1:] = reversed(num[partition+1:])
return num
if __name__ == "__main__":
print Solution().previousPermuation([1, 3, 2, 3])
class Solution(object):
def numbersByRecursion(self, n):
return self.rec(n)
def rec(self, n):
if n == 0:
return []
if n == 1:
return [i+1 for i in xrange(9)]
else:
lst = self.rec(n-1)
l = len(lst)
cur = []
prev = lst[-1]+1
for i in xrange(prev-prev/10):
for j in xrange(10):
cur.append(lst[prev/10-1+i]*10+j)
lst.extend(cur)
return lst
if __name__ == "__main__":
print Solution().numbersByRecursion(2)
assert Solution().numbersByRecursion(2) == [i+1 for i in xrange(99)]
class Solution(object):
def solve(self, cipher):
A = sorted(cipher)
cur = -5
cnt = 0
for a in A:
if cur + 4 < a:
cur = a
cnt += 1
return cnt
if __name__ == "__main__":
import sys
f = open("0.in", "r")
solution = Solution()
n = int(f.readline().strip())
cipher = map(int, f.readline().strip().split(' '))
s = "%s\n" % (solution.solve(cipher))
print s,
from celery import Celery
import consumer
app_name = 'consumer'
app = Celery(app_name, broker=consumer.redis_url)
for i in range(100):
a = 1
b = 2
consumer.consume.delay(a, b)
from Queue import Queue
from threading import Thread
import time
class SimpleProducerConsumer(object):
def __init__(self):
self.queue = Queue(1)
def consumer(self):
time.sleep(0.1)
self.queue.get()
print('Consumer got 1')
self.queue.get()
print('Consumer got 2')
def run(self):
thread = Thread(target=self.consumer)
thread.start()
self.queue.put(object())
print('Producer put 1')
self.queue.put(object())
print('Producer put 2')
thread.join()
print('Producer done')
def consumer_queue_join(self):
time.sleep(0.1)
self.queue.get()
print('Consumer got 1')
self.queue.get()
print('Consumer got 2')
self.queue.task_done()
def run_queue_join(self):
thread = Thread(target=self.consumer_queue_join())
thread.start()
self.queue.put(object())
print('Producer put 1')
self.queue.put(object())
print('Producer put 2')
self.queue.join()
print('Producer done')
class ClosableQueue(Queue):
STOP = object()
def close(self):
self.put(self.STOP)
def __iter__(self):
while True:
item = self.get()
try:
if item is self.STOP: return
yield item
finally:
self.task_done()
class StoppableWorker(Thread):
def __init__(self, func, in_queue, out_queue):
self.func = func
self.in_queue = in_queue
self.out_queue = out_queue
def run(self):
for item in self.in_queue:
result = self.func(item)
self.out_queue.put(result)
@staticmethod
def test():
download_queue = ClosableQueue()
resize_queue = ClosableQueue()
upload_queue = ClosableQueue()
done_queue = ClosableQueue()
threads = [
StoppableWorker(lambda x: x, download_queue, resize_queue),
StoppableWorker(lambda x: x, resize_queue, upload_queue),
StoppableWorker(lambda x: x, upload_queue, download_queue)
]
for thread in threads:
thread.start()
N = 1000
for _ in xrange(N):
download_queue.put(object())
download_queue.close()
download_queue.join()
resize_queue.close()
resize_queue.join()
upload_queue.close()
upload_queue.join()
assert done_queue.qsize() == N
class Solution:
def productExcludeItself(self, A):
n = len(A)
if n == 1:
return []
dp = [[1, 1] for _ in xrange(n)]
for i in xrange(1, n):
dp[i][0] = A[i-1]*dp[i-1][0]
dp[n-i-1][1] = A[n-i]*dp[n-i][1]
B = [dp[i][0]*dp[i][1] for i in xrange(n)]
return B
if __name__=="__main__":
assert Solution().productExcludeItself([1, 2, 3]) == [6, 3, 2]
from cProfile import Profile
from pstats import Stats
def demo():
f = lambda x: x
profiler = Profile()
profiler.runcall(f)
stats = Stats(profiler)
stats.strip_dirs()
stats.sort_stats('cumulative')
stats.print_stats()
stats.print_callers()
stats.print_callees()
from argparse import ArgumentParser
from cgi import FieldStorage
try:
from json import dumps
except ImportError:
from sys import path as sys_path
from os.path import join as path_join
from os.path import dirname
sys_path.append(path_join(dirname(__file__), '../server/lib/ujson'))
from ujson import dumps
from random import choice, randint
from sys import stderr
from urlparse import urlparse
try:
from urlparse import parse_qs
except ImportError:
from cgi import parse_qs
from BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler
import json
import urllib
import urllib2
import base64
ARGPARSER = ArgumentParser(description='An example HTTP tagging service, '
'tagging Confuse-a-Cat **AND** Dead-parrot mentions!')
ARGPARSER.add_argument('-p', '--port', type=int, default=56789,
help='port to run the HTTP service on (default: 56789)')
def build_headers(email="", password=""):
headers = {
'Content-Type': 'application/json',
'Accept': 'application/json',
'Authorization': b'Basic ' + base64.b64encode(email + b':' + password),
}
return headers
def build_data(text):
return json.dumps({'text': text}).encode('utf-8')
def convert_for_brat(pubdic_result, text):
anns = {}
for idx, entity in enumerate(pubdic_result):
ann_id = 'T%d' % idx
anns[ann_id] = {
'type': entity['obj'],
'offsets': ((entity['begin'], entity['end']), ),
'texts': (text[entity['begin']:entity['end']], ),
}
return anns
class RandomTaggerHandler(BaseHTTPRequestHandler):
def do_POST(self):
field_storage = FieldStorage(
headers=self.headers,
environ={
'REQUEST_METHOD':'POST',
'CONTENT_TYPE':self.headers['Content-type'],
},
fp=self.rfile)
try:
headers = build_headers("", "")
text    = field_storage.value.decode('utf-8')
data    = build_data(text)
annotator_url = "http://pubdictionaries.dbcls.jp:80/dictionaries/EntrezGene%20-%20Homo%20Sapiens/text_annotation?matching_method=approximate&max_tokens=6&min_tokens=1&threshold=0.8&top_n=0"
request = urllib2.Request(annotator_url, data=data, headers=headers)
f   = urllib2.urlopen(request)
res = f.read()
f.close()
json_dic = convert_for_brat(json.loads(res), text)
except KeyError:
json_dic = {}
self.send_response(200)
self.send_header('Content-type', 'application/json; charset=utf-8')
self.end_headers()
self.wfile.write(dumps(json_dic))
print >> stderr, ('Generated %d annotations' % len(json_dic))
def log_message(self, format, *args):
return
def main(args):
argp = ARGPARSER.parse_args(args[1:])
server_class = HTTPServer
httpd = server_class(('localhost', argp.port), RandomTaggerHandler)
print >> stderr, 'PubDictionary NER tagger service started on port %s' % (argp.port)
try:
httpd.serve_forever()
except KeyboardInterrupt:
pass
httpd.server_close()
print >> stderr, 'PubDictionary tagger service stopped'
if __name__ == '__main__':
from sys import argv
exit(main(argv))
import unittest
from ns.core import Simulator, Seconds, Config, int64x64_t
import ns.core
import ns.network
import ns.internet
import ns.mobility
import ns.csma
class TestSimulator(unittest.TestCase):
def testScheduleNow(self):
def callback(args):
self._args_received = args
self._cb_time = Simulator.Now()
Simulator.Destroy()
self._args_received = None
self._cb_time = None
Simulator.ScheduleNow(callback, "args")
Simulator.Run()
self.assertEqual(self._args_received, "args")
self.assertEqual(self._cb_time.GetSeconds(), 0.0)
def testSchedule(self):
def callback(args):
self._args_received = args
self._cb_time = Simulator.Now()
Simulator.Destroy()
self._args_received = None
self._cb_time = None
Simulator.Schedule(Seconds(123), callback, "args")
Simulator.Run()
self.assertEqual(self._args_received, "args")
self.assertEqual(self._cb_time.GetSeconds(), 123.0)
def testScheduleDestroy(self):
def callback(args):
self._args_received = args
self._cb_time = Simulator.Now()
Simulator.Destroy()
self._args_received = None
self._cb_time = None
def null(): pass
Simulator.Schedule(Seconds(123), null)
Simulator.ScheduleDestroy(callback, "args")
Simulator.Run()
Simulator.Destroy()
self.assertEqual(self._args_received, "args")
self.assertEqual(self._cb_time.GetSeconds(), 123.0)
def testTimeComparison(self):
self.assert_(Seconds(123) == Seconds(123))
self.assert_(Seconds(123) >= Seconds(123))
self.assert_(Seconds(123) <= Seconds(123))
self.assert_(Seconds(124) > Seconds(123))
self.assert_(Seconds(123) < Seconds(124))
def testTimeNumericOperations(self):
self.assertEqual(Seconds(10) + Seconds(5), Seconds(15))
self.assertEqual(Seconds(10) - Seconds(5), Seconds(5))
v1 = int64x64_t(5.0)*int64x64_t(10)
self.assertEqual(v1, int64x64_t(50))
def testConfig(self):
Config.SetDefault("ns3::OnOffApplication::PacketSize", ns.core.UintegerValue(123))
def testSocket(self):
node = ns.network.Node()
internet = ns.internet.InternetStackHelper()
internet.Install(node)
self._received_packet = None
def rx_callback(socket):
assert self._received_packet is None
self._received_packet = socket.Recv()
sink = ns.network.Socket.CreateSocket(node, ns.core.TypeId.LookupByName("ns3::UdpSocketFactory"))
sink.Bind(ns.network.InetSocketAddress(ns.network.Ipv4Address.GetAny(), 80))
sink.SetRecvCallback(rx_callback)
source = ns.network.Socket.CreateSocket(node, ns.core.TypeId.LookupByName("ns3::UdpSocketFactory"))
source.SendTo(ns.network.Packet(19), 0, ns.network.InetSocketAddress(ns.network.Ipv4Address("127.0.0.1"), 80))
Simulator.Run()
self.assert_(self._received_packet is not None)
self.assertEqual(self._received_packet.GetSize(), 19)
def testAttributes(self):
queue = ns.network.DropTailQueue()
queue.SetAttribute("MaxPackets", ns.core.UintegerValue(123456))
limit = ns.core.UintegerValue()
queue.GetAttribute("MaxPackets", limit)
self.assertEqual(limit.Get(), 123456)
mobility = ns.mobility.RandomWaypointMobilityModel()
ptr = ns.core.PointerValue()
mobility.GetAttribute("PositionAllocator", ptr)
self.assertEqual(ptr.GetObject(), None)
pos = ns.mobility.ListPositionAllocator()
mobility.SetAttribute("PositionAllocator", ns.core.PointerValue(pos))
ptr = ns.core.PointerValue()
mobility.GetAttribute("PositionAllocator", ptr)
self.assert_(ptr.GetObject() is not None)
def testIdentity(self):
csma = ns.csma.CsmaNetDevice()
channel = ns.csma.CsmaChannel()
csma.Attach(channel)
c1 = csma.GetChannel()
c2 = csma.GetChannel()
self.assert_(c1 is c2)
def testTypeId(self):
typeId1 = ns.core.TypeId.LookupByNameFailSafe("ns3::UdpSocketFactory")
self.assertEqual(typeId1.GetName (), "ns3::UdpSocketFactory")
self.assertRaises(KeyError, ns.core.TypeId.LookupByNameFailSafe, "__InvalidTypeName__")
def testCommandLine(self):
cmd = ns.core.CommandLine()
cmd.AddValue("Test1", "this is a test option")
cmd.AddValue("Test2", "this is a test option")
cmd.AddValue("Test3", "this is a test option", variable="test_xxx")
cmd.Test1 = None
cmd.Test2 = None
cmd.test_xxx = None
class Foo:
pass
foo = Foo()
foo.test_foo = None
cmd.AddValue("Test4", "this is a test option", variable="test_foo", namespace=foo)
cmd.Parse(["python", "--Test1=value1", "--Test2=value2", "--Test3=123", "--Test4=xpto"])
self.assertEqual(cmd.Test1, "value1")
self.assertEqual(cmd.Test2, "value2")
self.assertEqual(cmd.test_xxx, "123")
self.assertEqual(foo.test_foo, "xpto")
def testSubclass(self):
class MyNode(ns.network.Node):
def __init__(self):
super(MyNode, self).__init__()
node = MyNode()
if __name__ == '__main__':
unittest.main()
import os, sys
from waflib import Utils, Options, Errors
from waflib.Logs import debug, warn, info, error
from waflib.TaskGen import extension, before_method, after_method, feature
from waflib.Configure import conf
FRAG =
INST =
@extension('.py')
def process_py(self, node):
try:
if not self.bld.is_install:
return
except:
return
try:
if not self.install_path:
return
except AttributeError:
self.install_path = '${PYTHONDIR}'
def inst_py(ctx):
install_from = getattr(self, 'install_from', None)
if install_from:
install_from = self.path.find_dir(install_from)
install_pyfile(self, node, install_from)
self.bld.add_post_fun(inst_py)
def install_pyfile(self, node, install_from=None):
from_node = install_from or node.parent
tsk = self.bld.install_as(self.install_path + '/' + node.path_from(from_node), node, postpone=False)
path = tsk.get_install_path()
if self.bld.is_install < 0:
info("+ removing byte compiled python files")
for x in 'co':
try:
os.remove(path + x)
except OSError:
pass
if self.bld.is_install > 0:
try:
st1 = os.stat(path)
except:
error('The python file is missing, this should not happen')
for x in ['c', 'o']:
do_inst = self.env['PY' + x.upper()]
try:
st2 = os.stat(path + x)
except OSError:
pass
else:
if st1.st_mtime <= st2.st_mtime:
do_inst = False
if do_inst:
lst = (x == 'o') and [self.env['PYFLAGS_OPT']] or []
(a, b, c) = (path, path + x, tsk.get_install_path(destdir=False) + x)
argv = self.env['PYTHON'] + lst + ['-c', INST, a, b, c]
info('+ byte compiling %r' % (path + x))
ret = Utils.subprocess.Popen(argv).wait()
if ret:
raise Errors.WafError('py%s compilation failed %r' % (x, path))
@feature('py')
def feature_py(self):
pass
@feature('pyext')
@before_method('propagate_uselib_vars', 'apply_link')
@after_method('apply_bundle')
def init_pyext(self):
try:
if not self.install_path:
return
except AttributeError:
self.install_path = '${PYTHONARCHDIR}'
self.uselib = self.to_list(getattr(self, 'uselib', []))
if not 'PYEXT' in self.uselib:
self.uselib.append('PYEXT')
self.env['cshlib_PATTERN'] = self.env['cxxshlib_PATTERN'] = self.env['macbundle_PATTERN'] = self.env['pyext_PATTERN']
@feature('pyext')
@before_method('apply_link', 'apply_bundle')
def set_bundle(self):
if sys.platform.startswith('darwin'):
self.mac_bundle = True
@before_method('propagate_uselib_vars')
@feature('pyembed')
def init_pyembed(self):
self.uselib = self.to_list(getattr(self, 'uselib', []))
if not 'PYEMBED' in self.uselib:
self.uselib.append('PYEMBED')
@conf
def get_python_variables(conf, variables, imports=['import sys']):
program = list(imports)
program.append('')
for v in variables:
program.append("print(repr(%s))" % v)
os_env = dict(os.environ)
try:
del os_env['MACOSX_DEPLOYMENT_TARGET']
except KeyError:
pass
try:
out = conf.cmd_and_log(conf.env.PYTHON + ['-c', '\n'.join(program)], env=os_env)
except Errors.WafError:
conf.fatal('The distutils module is unusable: install "python-devel"?')
return_values = []
for s in out.split('\n'):
s = s.strip()
if not s:
continue
if s == 'None':
return_values.append(None)
elif s[0] == "'" and s[-1] == "'":
return_values.append(s[1:-1])
elif s[0].isdigit():
return_values.append(int(s))
else: break
return return_values
@conf
def check_python_headers(conf):
if not conf.env['CC_NAME'] and not conf.env['CXX_NAME']:
conf.fatal('load a compiler first (gcc, g++, ..)')
if not conf.env['PYTHON_VERSION']:
conf.check_python_version()
env = conf.env
pybin = conf.env.PYTHON
if not pybin:
conf.fatal('could not find the python executable')
v = 'prefix SO LDFLAGS LIBDIR LIBPL INCLUDEPY Py_ENABLE_SHARED MACOSX_DEPLOYMENT_TARGET LDSHARED CFLAGS'.split()
try:
lst = conf.get_python_variables(["get_config_var('%s') or ''" % x for x in v],
['from distutils.sysconfig import get_config_var'])
except RuntimeError:
conf.fatal("Python development headers not found (-v for details).")
vals = ['%s = %r' % (x, y) for (x, y) in zip(v, lst)]
conf.to_log("Configuration returned from %r:\n%r\n" % (pybin, '\n'.join(vals)))
dct = dict(zip(v, lst))
x = 'MACOSX_DEPLOYMENT_TARGET'
if dct[x]:
conf.env[x] = conf.environ[x] = dct[x]
env['pyext_PATTERN'] = '%s' + dct['SO']
all_flags = dct['LDFLAGS'] + ' ' + dct['CFLAGS']
conf.parse_flags(all_flags, 'PYEMBED')
all_flags = dct['LDFLAGS'] + ' ' + dct['LDSHARED'] + ' ' + dct['CFLAGS']
conf.parse_flags(all_flags, 'PYEXT')
result = None
for name in ('python' + env['PYTHON_VERSION'], 'python' + env['PYTHON_VERSION'].replace('.', '')):
if not result and env['LIBPATH_PYEMBED']:
path = env['LIBPATH_PYEMBED']
conf.to_log("\n\n
result = conf.check(lib=name, uselib='PYEMBED', libpath=path, mandatory=False, msg='Checking for library %s in LIBPATH_PYEMBED' % name)
if not result and dct['LIBDIR']:
path = [dct['LIBDIR']]
conf.to_log("\n\n
result = conf.check(lib=name, uselib='PYEMBED', libpath=path, mandatory=False, msg='Checking for library %s in LIBDIR' % name)
if not result and dct['LIBPL']:
path = [dct['LIBPL']]
conf.to_log("\n\n
result = conf.check(lib=name, uselib='PYEMBED', libpath=path, mandatory=False, msg='Checking for library %s in python_LIBPL' % name)
if not result:
path = [os.path.join(dct['prefix'], "libs")]
conf.to_log("\n\n
result = conf.check(lib=name, uselib='PYEMBED', libpath=path, mandatory=False, msg='Checking for library %s in $prefix/libs' % name)
if result:
break
if result:
env['LIBPATH_PYEMBED'] = path
env.append_value('LIB_PYEMBED', [name])
else:
conf.to_log("\n\n
if (Utils.is_win32 or sys.platform.startswith('os2')
or dct['Py_ENABLE_SHARED']):
env['LIBPATH_PYEXT'] = env['LIBPATH_PYEMBED']
env['LIB_PYEXT'] = env['LIB_PYEMBED']
num = '.'.join(env['PYTHON_VERSION'].split('.')[:2])
conf.find_program(['python%s-config' % num, 'python-config-%s' % num, 'python%sm-config' % num], var='PYTHON_CONFIG', mandatory=False)
includes = []
if conf.env.PYTHON_CONFIG:
for incstr in conf.cmd_and_log([ conf.env.PYTHON_CONFIG, '--includes']).strip().split():
if (incstr.startswith('-I') or incstr.startswith('/I')):
incstr = incstr[2:]
if incstr not in includes:
includes.append(incstr)
conf.to_log("Include path for Python extensions "
"(found via python-config --includes): %r\n" % (includes,))
env['INCLUDES_PYEXT'] = includes
env['INCLUDES_PYEMBED'] = includes
else:
conf.to_log("Include path for Python extensions "
"(found via distutils module): %r\n" % (dct['INCLUDEPY'],))
env['INCLUDES_PYEXT'] = [dct['INCLUDEPY']]
env['INCLUDES_PYEMBED'] = [dct['INCLUDEPY']]
if env['CC_NAME'] == 'gcc':
env.append_value('CFLAGS_PYEMBED', ['-fno-strict-aliasing'])
env.append_value('CFLAGS_PYEXT', ['-fno-strict-aliasing'])
if env['CXX_NAME'] == 'gcc':
env.append_value('CXXFLAGS_PYEMBED', ['-fno-strict-aliasing'])
env.append_value('CXXFLAGS_PYEXT', ['-fno-strict-aliasing'])
if env.CC_NAME == "msvc":
from distutils.msvccompiler import MSVCCompiler
dist_compiler = MSVCCompiler()
dist_compiler.initialize()
env.append_value('CFLAGS_PYEXT', dist_compiler.compile_options)
env.append_value('CXXFLAGS_PYEXT', dist_compiler.compile_options)
env.append_value('LINKFLAGS_PYEXT', dist_compiler.ldflags_shared)
try:
conf.check(header_name='Python.h', define_name='HAVE_PYTHON_H',
uselib='PYEMBED', fragment=FRAG,
errmsg='Could not find the python development headers')
except conf.errors.ConfigurationError:
conf.check_cfg(path=conf.env.PYTHON_CONFIG, package='', uselib_store='PYEMBED', args=['--cflags', '--libs'])
conf.check(header_name='Python.h', define_name='HAVE_PYTHON_H', msg='Getting the python flags from python-config',
uselib='PYEMBED', fragment=FRAG,
errmsg='Could not find the python development headers elsewhere')
@conf
def check_python_version(conf, minver=None):
assert minver is None or isinstance(minver, tuple)
pybin = conf.env['PYTHON']
if not pybin:
conf.fatal('could not find the python executable')
cmd = pybin + ['-c', 'import sys\nfor x in sys.version_info: print(str(x))']
debug('python: Running python command %r' % cmd)
lines = conf.cmd_and_log(cmd).split()
assert len(lines) == 5, "found %i lines, expected 5: %r" % (len(lines), lines)
pyver_tuple = (int(lines[0]), int(lines[1]), int(lines[2]), lines[3], int(lines[4]))
result = (minver is None) or (pyver_tuple >= minver)
if result:
pyver = '.'.join([str(x) for x in pyver_tuple[:2]])
conf.env['PYTHON_VERSION'] = pyver
if 'PYTHONDIR' in conf.environ:
pydir = conf.environ['PYTHONDIR']
else:
if Utils.is_win32:
(python_LIBDEST, pydir) = \
conf.get_python_variables(
["get_config_var('LIBDEST') or ''",
"get_python_lib(standard_lib=0, prefix=%r) or ''" % conf.env['PREFIX']],
['from distutils.sysconfig import get_config_var, get_python_lib'])
else:
python_LIBDEST = None
(pydir,) = \
conf.get_python_variables(
["get_python_lib(standard_lib=0, prefix=%r) or ''" % conf.env['PREFIX']],
['from distutils.sysconfig import get_python_lib'])
if python_LIBDEST is None:
if conf.env['LIBDIR']:
python_LIBDEST = os.path.join(conf.env['LIBDIR'], "python" + pyver)
else:
python_LIBDEST = os.path.join(conf.env['PREFIX'], "lib", "python" + pyver)
if 'PYTHONARCHDIR' in conf.environ:
pyarchdir = conf.environ['PYTHONARCHDIR']
else:
(pyarchdir, ) = conf.get_python_variables(
["get_python_lib(plat_specific=1, standard_lib=0, prefix=%r) or ''" % conf.env['PREFIX']],
['from distutils.sysconfig import get_python_lib'])
if not pyarchdir:
pyarchdir = pydir
if hasattr(conf, 'define'):
conf.define('PYTHONDIR', pydir)
conf.define('PYTHONARCHDIR', pyarchdir)
conf.env['PYTHONDIR'] = pydir
conf.env['PYTHONARCHDIR'] = pyarchdir
pyver_full = '.'.join(map(str, pyver_tuple[:3]))
if minver is None:
conf.msg('Checking for python version', pyver_full)
else:
minver_str = '.'.join(map(str, minver))
conf.msg('Checking for python version', pyver_tuple, ">= %s" % (minver_str,) and 'GREEN' or 'YELLOW')
if not result:
conf.fatal('The python version is too old, expecting %r' % (minver,))
PYTHON_MODULE_TEMPLATE =
@conf
def check_python_module(conf, module_name):
conf.start_msg('Python module %s' % module_name)
try:
conf.cmd_and_log(conf.env['PYTHON'] + ['-c', PYTHON_MODULE_TEMPLATE % module_name])
except:
conf.end_msg(False)
conf.fatal('Could not find the python module %r' % module_name)
conf.end_msg(True)
def configure(conf):
try:
conf.find_program('python', var='PYTHON')
except conf.errors.ConfigurationError:
warn("could not find a python executable, setting to sys.executable '%s'" % sys.executable)
conf.env.PYTHON = sys.executable
if conf.env.PYTHON != sys.executable:
warn("python executable '%s' different from sys.executable '%s'" % (conf.env.PYTHON, sys.executable))
conf.env.PYTHON = conf.cmd_to_list(conf.env.PYTHON)
v = conf.env
v['PYCMD'] = '"import sys, py_compile;py_compile.compile(sys.argv[1], sys.argv[2])"'
v['PYFLAGS'] = ''
v['PYFLAGS_OPT'] = '-O'
v['PYC'] = getattr(Options.options, 'pyc', 1)
v['PYO'] = getattr(Options.options, 'pyo', 1)
def options(opt):
opt.add_option('--nopyc',
action='store_false',
default=1,
help = 'Do not install bytecode compiled .pyc files (configuration) [Default:install]',
dest = 'pyc')
opt.add_option('--nopyo',
action='store_false',
default=1,
help='Do not install optimised compiled .pyo files (configuration) [Default:install]',
dest='pyo')
__date__ = '$Date: 2007/03/27 03:15:06 $'
__version__ = '$Revision: 0.45 $'
__credits__ =
import re
import sys
import time
import random
try:
True, False
except NameError:
True, False = (1==1, 0==1)
def int2bin(i, n):
hex2bin = {'0': '0000', '1': '0001', '2': '0010', '3': '0011',
'4': '0100', '5': '0101', '6': '0110', '7': '0111',
'8': '1000', '9': '1001', 'a': '1010', 'b': '1011',
'c': '1100', 'd': '1101', 'e': '1110', 'f': '1111'}
result = ''.join([hex2bin[x] for x in hex(i).lower().replace('l','')[2:]])
if '1' in result[:-n]:
raise ValueError("Value too large for given number of bits.")
result = result[-n:]
result = '0'*(n-len(result)) + result
return result
def bin2int(bin_string):
return int(bin_string, 2)
def reverse(input_string):
str_list = list(input_string)
str_list.reverse()
return ''.join(str_list)
def transpose(matrix):
result = zip(*matrix)
result = map(list, result)
return result
def polygon_area(points_list, precision=100):
for i in range(len(points_list)):
points_list[i] = (int(points_list[i][0] * precision),
int(points_list[i][1] * precision))
if points_list[-1] != points_list[0]:
points_list.append(points_list[0])
area = 0
for i in range(len(points_list)-1):
(x_i, y_i) = points_list[i]
(x_i_plus_1, y_i_plus_1) = points_list[i+1]
area = area + (x_i_plus_1 * y_i) - (y_i_plus_1 * x_i)
area = abs(area / 2)
area = float(area)/(precision**2)
return area
def timestamp():
return time.asctime()
def pt2str(point):
return "(%s, %s)" % (str(point[0]), str(point[1]))
def gcf(a, b, epsilon=1e-16):
result = max(a, b)
remainder = min(a, b)
while remainder and abs(remainder) > epsilon:
new_remainder = result % remainder
result = remainder
remainder = new_remainder
return abs(result)
def lcm(a, b, precision=None):
denom = gcf(a, b)
if denom == 0:
result = 0
else:
result = a * (b / denom)
return result
def permutations(input_list):
out_lists = []
if len(input_list) > 1:
item = input_list[0]
sub_lists = permutations(input_list[1:])
for sub_list in sub_lists:
for i in range(len(input_list)):
new_list = sub_list[:]
new_list.insert(i, item)
out_lists.append(new_list)
else:
out_lists = [input_list]
return out_lists
def reduce_fraction(fraction):
(numerator, denominator) = fraction
common_factor = abs(gcf(numerator, denominator))
result = (numerator/common_factor, denominator/common_factor)
return result
def quantile(l, p):
l_sort = l[:]
l_sort.sort()
n = len(l)
r = 1 + ((n - 1) * p)
i = int(r)
f = r - i
if i < n:
result =  (1-f)*l_sort[i-1] + f*l_sort[i]
else:
result = l_sort[i-1]
return result
def trim(l):
l_sort = l[:]
l_sort.sort()
if len(l_sort) % 2 == 0:
index = int(len(l_sort) / 2)
median = float(l_sort[index] + l_sort[index-1]) / 2
else:
index = int(len(l_sort) / 2)
median = l_sort[index]
q1 = quantile(l_sort, 0.25)
q3 = quantile(l_sort, 0.75)
iqr = q3 - q1
iqr_extra = iqr * 1.5
def in_interval(x, i=iqr_extra, q1=q1, q3=q3):
return (x >= q1-i and x <= q3+i)
l_trimmed = [x for x in l_sort if in_interval(x)]
return l_trimmed
def nice_units(value, dp=0, sigfigs=None, suffix='', space=' ',
use_extra_prefixes=False, use_full_name=False, mode='si'):
si_prefixes = {1e24:  ('Y', 'yotta'),
1e21:  ('Z', 'zetta'),
1e18:  ('E', 'exa'),
1e15:  ('P', 'peta'),
1e12:  ('T', 'tera'),
1e9:   ('G', 'giga'),
1e6:   ('M', 'mega'),
1e3:   ('k', 'kilo'),
1e-3:  ('m', 'milli'),
1e-6:  ('u', 'micro'),
1e-9:  ('n', 'nano'),
1e-12: ('p', 'pico'),
1e-15: ('f', 'femto'),
1e-18: ('a', 'atto'),
1e-21: ('z', 'zepto'),
1e-24: ('y', 'yocto')
}
if use_extra_prefixes:
si_prefixes.update({1e2:  ('h', 'hecto'),
1e1:  ('da', 'deka'),
1e-1: ('d', 'deci'),
1e-2: ('c', 'centi')
})
bin_prefixes = {2**10: ('K', 'kilo'),
2**20: ('M', 'mega'),
2**30: ('G', 'mega'),
2**40: ('T', 'tera'),
2**50: ('P', 'peta'),
2**60: ('E', 'exa')
}
if mode == 'bin':
prefixes = bin_prefixes
else:
prefixes = si_prefixes
prefixes[1] = ('', '')
multipliers = prefixes.keys()
multipliers.sort()
mult = None
for i in range(len(multipliers) - 1):
lower_mult = multipliers[i]
upper_mult = multipliers[i+1]
if lower_mult <= value < upper_mult:
mult_i = i
break
if mult is None:
if value < multipliers[0]:
mult_i = 0
elif value >= multipliers[-1]:
mult_i = len(multipliers) - 1
mult = multipliers[mult_i]
new_value = value / mult
if sigfigs is None:
if mult_i < (len(multipliers) - 1) and \
round(new_value, dp) == \
round((multipliers[mult_i+1] / mult), dp):
mult = multipliers[mult_i + 1]
new_value = value / mult
if use_full_name:
label_type = 1
else:
label_type = 0
if sigfigs is None:
str_value = eval('"%.'+str(dp)+'f" % new_value', locals(), {})
else:
str_value = eval('"%.'+str(sigfigs)+'g" % new_value', locals(), {})
return str_value + space + prefixes[mult][label_type] + suffix
def uniquify(seq, preserve_order=False):
try:
d = {}
if preserve_order:
return [x for x in seq if (x not in d) and not d.__setitem__(x, 0)]
else:
for x in seq:
d[x] = 0
return d.keys()
except TypeError:
result = []
app = result.append
for x in seq:
if x not in result:
app(x)
return result
unique = uniquify
def reverse_dict(d):
result = {}
for key, value in d.items():
result[value] = key
return result
def lsb(x, n):
return x & ((2 ** n) - 1)
def gray_encode(i):
return i ^ (i >> 1)
def random_vec(bits, max_value=None):
vector = ""
for _ in range(int(bits / 10) + 1):
i = int((2**10) * random.random())
vector += int2bin(i, 10)
if max_value and (max_value < 2 ** bits - 1):
vector = int2bin((int(vector, 2) / (2 ** bits - 1)) * max_value, bits)
return vector[0:bits]
def binary_range(bits):
l = []
v = ['0'] * bits
toggle = [1] + [0] * bits
while toggle[bits] != 1:
v_copy = v[:]
v_copy.reverse()
l.append(''.join(v_copy))
toggle = [1] + [0]*bits
i = 0
while i < bits and toggle[i] == 1:
if toggle[i]:
if v[i] == '0':
v[i] = '1'
toggle[i+1] = 0
else:
v[i] = '0'
toggle[i+1] = 1
i += 1
return l
def float_range(start, stop=None, step=None):
if stop is None:
stop = float(start)
start = 0.0
if step is None:
step = 1.0
cur = float(start)
l = []
while cur < stop:
l.append(cur)
cur += step
return l
def find_common_fixes(s1, s2):
prefix = []
suffix = []
i = 0
common_len = min(len(s1), len(s2))
while i < common_len:
if s1[i] != s2[i]:
break
prefix.append(s1[i])
i += 1
i = 1
while i < (common_len + 1):
if s1[-i] != s2[-i]:
break
suffix.append(s1[-i])
i += 1
suffix.reverse()
prefix = ''.join(prefix)
suffix = ''.join(suffix)
return (prefix, suffix)
def is_rotated(seq1, seq2):
if len(seq1) != len(seq2):
return False
start_indexes = []
head_item = seq2[0]
for index1 in range(len(seq1)):
if seq1[index1] == head_item:
start_indexes.append(index1)
double_seq1 = seq1 + seq1
for index1 in start_indexes:
if double_seq1[index1:index1+len(seq1)] == seq2:
return True
return False
def getmodule(obj):
if hasattr(obj, 'func_globals'):
func = obj
else:
func = None
for item in obj.__dict__.values():
if hasattr(item, 'func_globals'):
func = item
break
if func is None:
raise ValueError("No functions attached to object: %r" % obj)
module_name = func.func_globals['__name__']
module = sys.modules[module_name]
return module
def round_grid(value, grid, mode=0):
off_grid = value % grid
if mode == 0:
add_one = int(off_grid >= (grid / 2.0))
elif mode == 1 and off_grid:
add_one = 1
elif mode == -1 and off_grid:
add_one = 0
result = ((int(value / grid) + add_one) * grid)
return result
def get_args(argv):
d = {}
args = []
for arg in argv:
if arg.startswith('-'):
parts = re.sub(r'^-+', '', arg).split('=')
if len(parts) == 2:
d[parts[0]] = parts[1]
else:
d[parts[0]] = None
else:
args.append(arg)
d['args'] = args
return d
if __name__ == '__main__':
import doctest
doctest.testmod(sys.modules['__main__'])
import re
import operator
import os
BASE_DIR = (os.path.dirname(os.path.abspath(__file__)))
debug = False
def is_number(s):
try:
float(s) if '.' in s else int(s)
return True
except ValueError:
return False
def load_stop_words(stop_word_file):
stop_words = []
for line in open(stop_word_file):
if line.strip()[0:1] != "#":
for word in line.split():
stop_words.append(word)
return stop_words
def separate_words(text, min_word_return_size):
splitter = re.compile(r'[^a-zA-Z0-9_\+\-/]')
words = []
for single_word in splitter.split(text):
current_word = single_word.strip().lower()
if len(current_word) > min_word_return_size and current_word != '' and not is_number(current_word):
words.append(current_word)
return words
def split_sentences(text):
sentence_delimiters = re.compile(r'[!\?;:\[\]\t\"\(\)]|\s\-\s|[^0-9],[^a-zA-Z0-9]|\.[^a-zA-Z0-9]|\.$')
sentences = sentence_delimiters.split(text)
return sentences
def build_stop_word_regex(stop_word_file_path):
stop_word_list = load_stop_words(stop_word_file_path)
stop_word_regex_list = []
for word in stop_word_list:
word_regex = r'\b'+word+r'(?![\w-])'
stop_word_regex_list.append(word_regex)
stop_word_pattern = re.compile('|'.join(stop_word_regex_list), re.IGNORECASE)
return stop_word_pattern
def generate_candidate_keywords(sentence_list, stopword_pattern):
phrase_list = []
for s in sentence_list:
tmp = re.sub(stopword_pattern, '|', s.strip())
phrases = tmp.split("|")
for phrase in phrases:
phrase = phrase.strip().lower()
if phrase != "":
phrase_list.append(phrase)
return phrase_list
def calculate_word_scores(phraseList):
word_frequency = {}
word_degree = {}
for phrase in phraseList:
word_list = separate_words(phrase, 0)
word_list_length = len(word_list)
word_list_degree = word_list_length-1
for word in word_list:
word_frequency.setdefault(word, 0)
word_frequency[word] += 1
word_degree.setdefault(word, 0)
word_degree[word] += word_list_degree
for item in word_frequency:
word_degree[item] = word_degree[item]+word_frequency[item]
word_score = {}
for item in word_frequency:
word_score.setdefault(item, 0)
word_score[item] = word_degree[item]/(word_frequency[item]*1.0)
return word_score
def generate_candidate_keyword_scores(phrase_list, word_score):
keyword_candidates = {}
for phrase in phrase_list:
keyword_candidates.setdefault(phrase, 0)
word_list = separate_words(phrase, 0)
candidate_score = 0
for word in word_list:
candidate_score += word_score[word]
keyword_candidates[phrase] = candidate_score
return keyword_candidates
class Rake(object):
def __init__(self, stop_words_path=os.path.join(BASE_DIR, "SmartStoplist.txt")):
self.stop_words_path = stop_words_path
self.__stop_words_pattern = build_stop_word_regex(stop_words_path)
def run(self, text):
sentence_list = split_sentences(text)
phrase_list = generate_candidate_keywords(sentence_list, self.__stop_words_pattern)
word_scores = calculate_word_scores(phrase_list)
keyword_candidates = generate_candidate_keyword_scores(phrase_list, word_scores)
sorted_keywords = sorted(keyword_candidates.iteritems(), key=operator.itemgetter(1), reverse=True)
return sorted_keywords
if __name__ == "__main__":
text = "Compatibility of systems of linear constraints over the set of natural numbers. Criteria of compatibility of a system of linear Diophantine equations, strict inequations, and nonstrict inequations are considered. Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given. These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types of systems and systems of mixed types."
sentenceList = split_sentences(text)
stoppath = os.path.join(BASE_DIR, "SmartStoplist.txt")
stopwordpattern = build_stop_word_regex(stoppath)
phraseList = generate_candidate_keywords(sentenceList, stopwordpattern)
wordscores = calculate_word_scores(phraseList)
keywordcandidates = generate_candidate_keyword_scores(phraseList, wordscores)
if debug: print keywordcandidates
sortedKeywords = sorted(keywordcandidates.iteritems(), key=operator.itemgetter(1), reverse=True)
if debug: print sortedKeywords
totalKeywords = len(sortedKeywords)
if debug: print totalKeywords
print sortedKeywords[0:(totalKeywords/3)]
rake = Rake(stoppath)
keywords = rake.run(text)
print keywords
class Solution(object):
def solve(self, cipher):
if __name__ == "__main__":
import sys
f = open("0.in", "r")
solution = Solution()
n, a, b = map(int, f.readline().strip().split(' '))
D = map(int, f.readline().strip().split(' '))
cipher = n, a, b, D
s = "%s\n" % (solution.solve(cipher))
print s,
from argparse import ArgumentParser
from cgi import FieldStorage
try:
from json import dumps
except ImportError:
from sys import path as sys_path
from os.path import join as path_join
from os.path import dirname
sys_path.append(path_join(dirname(__file__), '../server/lib/ujson'))
from ujson import dumps
from random import choice, randint
from sys import stderr
from urlparse import urlparse
try:
from urlparse import parse_qs
except ImportError:
from cgi import parse_qs
from BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler
ARGPARSER = ArgumentParser(description='An example HTTP tagging service, '
'tagging Confuse-a-Cat **AND** Dead-parrot mentions!')
ARGPARSER.add_argument('-p', '--port', type=int, default=47111,
help='port to run the HTTP service on (default: 47111)')
def _random_span(text):
attempt = 1
while True:
start = randint(0, len(text))
end = randint(start + 3, start + 25)
if (
end > len(text) or
'\n' in text[start:end] or
(text[start:end][-1] == ' ' or text[start:end][0] == ' ')
):
if attempt >= 100:
return None, None, None
attempt += 1
continue
else:
return start, end, text[start:end]
def _random_tagger(text):
anns = {}
if not text:
return anns
num_anns = randint(1, len(text) / 100)
for ann_num in xrange(num_anns):
ann_id = 'T%d' % ann_num
_type = choice(('Confuse-a-Cat', 'Dead-parrot', ))
start, end, span_text = _random_span(text)
if start is None:
continue
anns[ann_id] = {
'type': _type,
'offsets': ((start, end), ),
'texts': (span_text, ),
}
return anns
class RandomTaggerHandler(BaseHTTPRequestHandler):
def do_POST(self):
field_storage = FieldStorage(
headers=self.headers,
environ={
'REQUEST_METHOD':'POST',
'CONTENT_TYPE':self.headers['Content-type'],
},
fp=self.rfile)
try:
json_dic = _random_tagger(field_storage.value.decode('utf-8'))
except KeyError:
json_dic = {}
self.send_response(200)
self.send_header('Content-type', 'application/json; charset=utf-8')
self.end_headers()
self.wfile.write(dumps(json_dic))
print >> stderr, ('Generated %d random annotations' % len(json_dic))
def log_message(self, format, *args):
return
def main(args):
argp = ARGPARSER.parse_args(args[1:])
server_class = HTTPServer
httpd = server_class(('localhost', argp.port), RandomTaggerHandler)
print >> stderr, 'Random tagger service started on port %s' % (argp.port)
try:
httpd.serve_forever()
except KeyboardInterrupt:
pass
httpd.server_close()
print >> stderr, 'Random tagger service stopped'
if __name__ == '__main__':
from sys import argv
exit(main(argv))
percol.import_keymap({
"C-h" : lambda percol: percol.command.delete_backward_char(),
"C-d" : lambda percol: percol.command.delete_forward_char(),
"C-k" : lambda percol: percol.command.kill_end_of_line(),
"C-y" : lambda percol: percol.command.yank(),
"C-t" : lambda percol: percol.command.transpose_chars(),
"C-a" : lambda percol: percol.command.beginning_of_line(),
"C-e" : lambda percol: percol.command.end_of_line(),
"C-b" : lambda percol: percol.command.backward_char(),
"C-f" : lambda percol: percol.command.forward_char(),
"M-f" : lambda percol: percol.command.forward_word(),
"M-b" : lambda percol: percol.command.backward_word(),
"M-d" : lambda percol: percol.command.delete_forward_word(),
"M-h" : lambda percol: percol.command.delete_backward_word(),
"C-n" : lambda percol: percol.command.select_next(),
"C-p" : lambda percol: percol.command.select_previous(),
"C-v" : lambda percol: percol.command.select_next_page(),
"M-v" : lambda percol: percol.command.select_previous_page(),
"M-<" : lambda percol: percol.command.select_top(),
"M->" : lambda percol: percol.command.select_bottom(),
"C-m" : lambda percol: percol.finish(),
"C-j" : lambda percol: percol.finish(),
"C-g" : lambda percol: percol.cancel(),
})
import sys
import tty
import termios
import fcntl
import os
from . import keys
def get_symbol():
ch = read_char()
ch_code = ord(ch)
if ch_code == keys.ESC:
ch = read_char_no_blocking()
if ch == '':
return keys.ESC
elif ch != 'O' and ch != '[':
return ord(ch)
else:
ch = read_char_no_blocking()
if ch == 'A':
return keys.UP
elif ch == 'B':
return keys.DOWN
elif ch == 'C':
return keys.RIGHT
elif ch == 'D':
return keys.LEFT
elif ch == 'Z':
return keys.SHIFTTAB
return ch_code
def read_char():
fd = sys.stdin.fileno()
old_settings = termios.tcgetattr(fd)
try:
tty.setraw(fd, termios.TCSADRAIN)
ch = sys.stdin.read(1)
finally:
termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
return ch
def read_char_no_blocking():
fd = sys.stdin.fileno()
old_settings = termios.tcgetattr(fd)
old_flags = fcntl.fcntl(fd, fcntl.F_GETFL)
try:
tty.setraw(fd, termios.TCSADRAIN)
fcntl.fcntl(fd, fcntl.F_SETFL, old_flags | os.O_NONBLOCK)
return sys.stdin.read(1)
except IOError as e:
ErrorNumber = e[0]
if (sys.platform.startswith("linux") and ErrorNumber != 11) or (sys.platform == "darwin" and ErrorNumber != 35):
raise
return ""
finally:
fcntl.fcntl(fd, fcntl.F_SETFL, old_flags)
termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
import linecache
import random
class ReadFile(object):
def __init__(self, pth1, num=None):
self.pth1 = pth1
self.num = num
linecache.clearcache()
self.total = int(linecache.getline(pth1, 1))
if num == None:
self.num = self.total
def __get_line_label(self, tmp, rand):
if rand:
line_label = random.sample(tmp, self.num)
else:
line_label = tmp[:self.num]
return line_label
def person_pair(self):
person = []
tmp = range(2, self.total + 2)
if self.num != self.total:
line_label = self.__get_line_label(tmp, False)
for i in line_label:
person.append(self.__extract_flnm(i))
else:
for i in tmp:
person.append(self.__extract_flnm(i))
return person
def person_mispair(self):
person = []
tmp = range(self.total + 2, self.total * 2 + 2)
if self.num != self.total:
line_label = random.sample(tmp, self.num)
for i in range(len(line_label)):
person.append(self.__extract_flnm(line_label[i]))
else:
for i in tmp:
person.append(self.__extract_flnm(i))
return person
def __extract_flnm(self, line_label):
tmp = linecache.getline(self.pth1, line_label)
tmp = tmp.split()
suffix = '.txt'
if len(tmp) == 3:
flag = 1
fl_nm1 = tmp[0] + '_' + '0'*(4 - len(tmp[1])) + tmp[1] + suffix
fl_nm2 = tmp[0] + '_' + '0'*(4 - len(tmp[2])) + tmp[2] + suffix
else:
flag = -1
fl_nm1 = tmp[0] + '_' + '0'*(4 - len(tmp[1])) + tmp[1] + suffix
fl_nm2 = tmp[2] + '_' + '0'*(4 - len(tmp[3])) + tmp[3] + suffix
pair_info = [fl_nm1, fl_nm2, flag]
return pair_info
import sys
import os
import numpy as np
from PIL import Image
import re
def read_images(path, sz=None):
c = 0
X, y = [], []
for dirname, dirnames, filenames in os.walk(path):
for subdirname in dirnames:
subject_path = os.path.join(dirname, subdirname)
for filename in os.listdir(subject_path):
try:
if not re.search(r"\.pgm$|\.jpg$", filename):
continue
if re.search(r"P00_Ambient\.pgm", filename):
continue
im = Image.open(os.path.join(subject_path, filename))
im = im.convert("L")
if sz is not None:
im = im.resize(sz, Image.ANTIALIAS)
X.append(np.asarray(im, dtype=np.uint8))
y.append(c)
except IOError, (errno, strerror):
print "I/O error({0}): {1}".format(errno, strerror)
except:
print "Unexpected error:", sys.exc_info()[0]
raise
c += 1
return [X, y]
import ns.applications
import ns.core
import ns.csma
import ns.internet
import ns.network
def main(argv):
cmd = ns.core.CommandLine()
cmd.Parse(argv)
ns.core.GlobalValue.Bind("SimulatorImplementationType", ns.core.StringValue("ns3::RealtimeSimulatorImpl"))
print "Create nodes."
n = ns.network.NodeContainer()
n.Create(4)
internet = ns.internet.InternetStackHelper()
internet.Install(n)
print ("Create channels.")
csma = ns.csma.CsmaHelper()
csma.SetChannelAttribute("DataRate", ns.network.DataRateValue(ns.network.DataRate(5000000)))
csma.SetChannelAttribute("Delay", ns.core.TimeValue(ns.core.MilliSeconds(2)));
csma.SetDeviceAttribute("Mtu", ns.core.UintegerValue(1400))
d = csma.Install(n)
print ("Assign IP Addresses.")
ipv4 = ns.internet.Ipv4AddressHelper()
ipv4.SetBase(ns.network.Ipv4Address("10.1.1.0"), ns.network.Ipv4Mask("255.255.255.0"))
i = ipv4.Assign(d)
print ("Create Applications.")
port = 9
server = ns.applications.UdpEchoServerHelper(port)
apps = server.Install(n.Get(1))
apps.Start(ns.core.Seconds(1.0))
apps.Stop(ns.core.Seconds(10.0))
packetSize = 1024
maxPacketCount = 500
interPacketInterval = ns.core.Seconds(0.01)
client = ns.applications.UdpEchoClientHelper(i.GetAddress (1), port)
client.SetAttribute("MaxPackets", ns.core.UintegerValue(maxPacketCount))
client.SetAttribute("Interval", ns.core.TimeValue(interPacketInterval))
client.SetAttribute("PacketSize", ns.core.UintegerValue(packetSize))
apps = client.Install(n.Get(0))
apps.Start(ns.core.Seconds(2.0))
apps.Stop(ns.core.Seconds(10.0))
ascii = ns.network.AsciiTraceHelper()
csma.EnableAsciiAll(ascii.CreateFileStream("realtime-udp-echo.tr"))
csma.EnablePcapAll("realtime-udp-echo", False)
print ("Run Simulation.")
ns.core.Simulator.Run()
ns.core.Simulator.Destroy()
print ("Done.")
if __name__ == '__main__':
import sys
main(sys.argv)
import csv, os, sys
try:
from PIL import Image
except ImportError:
import Image
import numpy as np
from facerec.feature import ChainOperator, Fisherfaces
from facerec.preprocessing import Resize
from facerec.dataset import NumericDataSet
from facerec.distance import EuclideanDistance
from facerec.classifier import NearestNeighbor
from facerec.model import PredictableModel
from facerec.validation import KFoldCrossValidation
from facerec.serialization import save_model, load_model
class PredictableModelWrapper(object):
def __init__(self, model):
self.model = model
self.numeric_dataset = NumericDataSet()
def compute(self):
X,y = self.numeric_dataset.get()
self.model.compute(X,y)
def set_data(self, numeric_dataset):
self.numeric_dataset = numeric_dataset
def predict(self, image):
prediction_result = self.model.predict(image)
num_label = prediction_result[0]
str_label = self.numeric_dataset.resolve_by_num(num_label)
return str_label
def update(self, name, image):
self.numeric_dataset.add(name, image)
class_label = self.numeric_dataset.resolve_by_str(name)
extracted_feature = self.feature.extract(image)
self.classifier.update(extracted_feature, class_label)
def __repr__(self):
return "PredictableModelWrapper (Inner Model=%s)" % (str(self.model))
def get_model(numeric_dataset, model_filename=None):
feature = ChainOperator(Resize((128,128)), Fisherfaces())
classifier = NearestNeighbor(dist_metric=EuclideanDistance(), k=1)
inner_model = PredictableModel(feature=feature, classifier=classifier)
model = PredictableModelWrapper(inner_model)
model.set_data(numeric_dataset)
model.compute()
if not model_filename is None:
save_model(model_filename, model)
return model
def read_images(path, identifier, numeric_dataset):
for filename in os.listdir(path):
try:
img = Image.open(os.path.join(path, filename))
img = img.convert("L")
img = np.asarray(img, dtype=np.uint8)
numeric_dataset.add(identifier, img)
except IOError, (errno, strerror):
print "I/O error({0}): {1}".format(errno, strerror)
except:
print "Unexpected error:", sys.exc_info()[0]
raise
def read_from_csv(filename):
numeric_dataset = NumericDataSet()
with open(filename, 'rb') as csvfile:
reader = csv.reader(csvfile, delimiter=';', quotechar='#')
for row in reader:
identifier = row[0]
path = row[1]
read_images(path, identifier, numeric_dataset)
return numeric_dataset
def get_model_from_csv(filename, out_model_filename):
numeric_dataset = read_from_csv(filename)
model = get_model(numeric_dataset, out_model_filename)
return model
def load_model_file(model_filename):
load_model(model_filename)
import math
class Solution(object):
def solve(self, cipher):
return self.sum_prime(self.get_configs(cipher))
def get_configs(self, N):
if N < 4:
return 1
F = [0 for _ in xrange(N + 1)]
for i in xrange(1, 4):
F[i] = 1
F[4] = 2
for i in xrange(5, N + 1):
F[i] = F[i - 4] + F[i - 1]
return F[N]
def prime(self, n):
is_prime = [1 for _ in xrange(n + 1)]
for i in xrange(2):
is_prime[i] = 0
n_max = int(math.sqrt(len(is_prime)))
for i in xrange(2, n_max + 1):
for j in xrange(2 * i, len(is_prime), i):
is_prime[j] = 0
return sum(is_prime)
def sum_prime(self, n):
import numpy as np
is_prime = np.ones((n + 1,), dtype=bool)
is_prime[:2] = 0
N_max = int(np.sqrt(len(is_prime)))
for j in xrange(2, N_max):
is_prime[2 * j::j] = False
return np.sum(is_prime)
if __name__ == "__main__":
import sys
f = open("1.in", "r")
solution = Solution()
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = int(f.readline().strip())
s = "%s\n" % (solution.solve(cipher))
print s,
class ListNode(object):
def __init__(self, val, next=None):
self.val = val
self.next = next
def __repr__(self):
return repr(self.val)
class Solution:
def rehashing(self, hashTable):
cap = len(hashTable)
cap *= 2
ht = [None for _ in xrange(cap)]
for node in hashTable:
while node:
self.__rehash(ht, ListNode(node.val))
node = node.next
return ht
def __rehash(self, ht, node):
code = self.__hashcode(node.val, len(ht))
if ht[code] is None:
ht[code] = node
else:
cur = ht[code]
while cur.next:
cur = cur.next
cur.next = node
def __hashcode(self, key, capacity):
return key%capacity
if __name__ == "__main__":
hashTable = [None for _ in xrange(3)]
n0 = ListNode(29)
n1 = ListNode(5)
n0.next = n1
hashTable[2] = n0
print Solution().rehashing(hashTable)
import ann_to_xml
import info_extraction
import os
import sys
def relation_evaluate(file_path):
global tp, fp, fn
set_original = ann_to_xml.get_relation_set(file_path+".ann")
extract_engine = info_extraction.InfoExtraction()
set_extracted = extract_engine.extract_file(file_path+"-tagged.xml", "relation")
tp += len(set_original.intersection(set_original, set_extracted))
fp += len(set_extracted - set_original)
fn += len(set_original - set_extracted)
if __name__ == '__main__':
if len(sys.argv)==1:
print "usage: python relation_evaluate.py [data_folder relative name]"
print "example: python relative_evaluate.py non-auto"
sys.exit(0)
else:
folder_name = sys.argv[1]
tp = fp = fn = 0
current_directory = os.path.dirname(os.path.realpath(__file__))
for i in range(1,33):
relation_evaluate(os.path.join(current_directory, folder_name, str(i)))
print "******summary*********"
print "tp: %d\nfp: %d\nfn: %d" % (tp, fp, fn)
print "f1: %f" % (float(2*tp)/(2*tp+fp+fn))
print "recall: %f" % (float(tp)/(tp+fn))
import os
from waflib import Build, ConfigSet, Task, Utils, Errors
from waflib.TaskGen import feature, before_method, after_method
EXTRA_LOCK = '.old_srcdir'
old1 = Build.BuildContext.store
def store(self):
old1(self)
db = os.path.join(self.variant_dir, EXTRA_LOCK)
env = ConfigSet.ConfigSet()
env.SRCDIR = self.srcnode.abspath()
env.store(db)
Build.BuildContext.store = store
old2 = Build.BuildContext.init_dirs
def init_dirs(self):
if not (os.path.isabs(self.top_dir) and os.path.isabs(self.out_dir)):
raise Errors.WafError('The project was not configured: run "waf configure" first!')
srcdir = None
db = os.path.join(self.variant_dir, EXTRA_LOCK)
env = ConfigSet.ConfigSet()
try:
env.load(db)
srcdir = env.SRCDIR
except:
pass
if srcdir:
d = self.root.find_node(srcdir)
if d and srcdir != self.top_dir and getattr(d, 'children', ''):
srcnode = self.root.make_node(self.top_dir)
print("relocating the source directory %r -> %r" % (srcdir, self.top_dir))
srcnode.children = {}
for (k, v) in d.children.items():
srcnode.children[k] = v
v.parent = srcnode
d.children = {}
old2(self)
Build.BuildContext.init_dirs = init_dirs
def uid(self):
try:
return self.uid_
except AttributeError:
m = Utils.md5()
up = m.update
up(self.__class__.__name__.encode())
for x in self.inputs + self.outputs:
up(x.path_from(x.ctx.srcnode).encode())
self.uid_ = m.digest()
return self.uid_
Task.Task.uid = uid
@feature('c', 'cxx', 'd', 'go', 'asm', 'fc', 'includes')
@after_method('propagate_uselib_vars', 'process_source')
def apply_incpaths(self):
lst = self.to_incnodes(self.to_list(getattr(self, 'includes', [])) + self.env['INCLUDES'])
self.includes_nodes = lst
bld = self.bld
self.env['INCPATHS'] = [x.is_child_of(bld.srcnode) and x.path_from(bld.srcnode) or x.abspath() for x in lst]
class TreeNode:
def __init__(self, val):
self.val = val
self.left, self.right = None, None
class Solution:
def removeNode(self, root, value):
return self.__removeNode(root, None, value)
def __removeNode(self, root, parent, value):
if not root:
return
if root.val > value:
self.__removeNode(root.left, root, value)
elif root.val < value:
self.__removeNode(root.right, root, value)
else:
if not root.left and not root.right:
if parent:
if parent.left == root:
parent.left = None
else:
parent.right = None
else:
root = None
elif root.left and not root.right or root.right and not root.left:
if root.left:
if parent:
if parent.left == root:
parent.left = root.left
else:
parent.right = root.left
else:
root = root.left
else:
if parent:
if parent.left == root:
parent.left = root.right
else:
parent.right = root.right
else:
root = root.right
else:
cur = root.left
while cur.right:
cur = cur.right
root.val = cur.val
self.__removeNode(root.left, root, cur.val)
return root
import re
import os
texts = []
directory = os.path.dirname(os.path.realpath(__file__))
for root, dirs, files in os.walk(directory):
for file in files:
if file.endswith(".srt"):
f=open(os.path.join(root,file), 'r')
texts.append((file,f.read()))
f.close()
p1 = re.compile(('^\d+$'))
p2 = re.compile(('\d\d:\d\d:\d\d'))
for videoName, videoTexts in texts:
transcripts = ''
lines = videoTexts.splitlines()
for line in lines:
if not (p1.search(line) or p2.search(line) or len(line) < 1):
transcripts += (line+'\n')
f = open(videoName[:len(videoName)-4]+'_cleaned.txt','w')
f.write(transcripts)
print(videoName + ' has been cleaned.')
f.close()
try:
from urllib.parse import urlencode
except ImportError:
from urllib import urlencode
from .filepost import encode_multipart_formdata
__all__ = ['RequestMethods']
class RequestMethods(object):
_encode_url_methods = set(['DELETE', 'GET', 'HEAD', 'OPTIONS'])
_encode_body_methods = set(['PATCH', 'POST', 'PUT', 'TRACE'])
def __init__(self, headers=None):
self.headers = headers or {}
def urlopen(self, method, url, body=None, headers=None,
encode_multipart=True, multipart_boundary=None,
**kw):
raise NotImplemented("Classes extending RequestMethods must implement "
"their own ``urlopen`` method.")
def request(self, method, url, fields=None, headers=None, **urlopen_kw):
method = method.upper()
if method in self._encode_url_methods:
return self.request_encode_url(method, url, fields=fields,
headers=headers,
**urlopen_kw)
else:
return self.request_encode_body(method, url, fields=fields,
headers=headers,
**urlopen_kw)
def request_encode_url(self, method, url, fields=None, **urlopen_kw):
if fields:
url += '?' + urlencode(fields)
return self.urlopen(method, url, **urlopen_kw)
def request_encode_body(self, method, url, fields=None, headers=None,
encode_multipart=True, multipart_boundary=None,
**urlopen_kw):
if encode_multipart:
body, content_type = encode_multipart_formdata(fields or {},
boundary=multipart_boundary)
else:
body, content_type = (urlencode(fields or {}),
'application/x-www-form-urlencoded')
if headers is None:
headers = self.headers
headers_ = {'Content-Type': content_type}
headers_.update(headers)
return self.urlopen(method, url, body=body, headers=headers_,
**urlopen_kw)
from __future__ import with_statement
import sys
import os
import re
import codecs
try:
import xml.etree.ElementTree as ET
except ImportError:
import cElementTree as ET
INSERTED_ELEMENT_TAG = "n2t-spc"
INPUT_ENCODING="UTF-8"
OUTPUT_ENCODING="UTF-8"
options = None
newline_wrap_element = set([
"CURRENT_TITLE",
"CURRENT_AUTHORLIST",
"ABSTRACT",
"P",
"TABLE",
"FIGURE",
"HEADER",
"REFERENCE",
"article-title",
"abstract",
"title",
"sec",
"p",
"contrib",
"aff",
"pub-date",
"copyright-statement",
"table",
"table-wrap",
"figure",
"fig",
"tr",
"kwd-group",
])
space_wrap_element = set([
"AUTHOR",
"SURNAME",
"CURRENT_AUTHOR",
"CURRENT_SURNAME",
"TITLE",
"JOURNAL",
"YEAR",
"surname",
"given-names",
"email",
"volume",
"issue",
"year",
"month",
"day",
"fpage",
"lpage",
"pub-id",
"copyright-year",
"journal-id",
"journal-title",
"issn",
"publisher-name",
"article-id",
"kwd",
"label",
"th",
"td",
])
strip_element = newline_wrap_element | space_wrap_element
class Standoff:
def __init__(self, element, start, end):
self.element = element
self.start   = start
self.end     = end
def txt(s):
return s if s is not None else ""
def text_and_standoffs(e):
strings, standoffs = [], []
_text_and_standoffs(e, 0, strings, standoffs)
text = "".join(strings)
return text, standoffs
def _text_and_standoffs(e, curroff, strings, standoffs):
startoff = curroff
so = Standoff(e, 0, 0)
standoffs.append(so)
if e.text is not None and e.text != "":
strings.append(e.text)
curroff += len(e.text)
curroff = _subelem_text_and_standoffs(e, curroff, strings, standoffs)
so.start = startoff
so.end   = curroff
return curroff
def _subelem_text_and_standoffs(e, curroff, strings, standoffs):
startoff = curroff
for s in e:
curroff = _text_and_standoffs(s, curroff, strings, standoffs)
if s.tail is not None and s.tail != "":
strings.append(s.tail)
curroff += len(s.tail)
return curroff
def preceding_space(pos, text, rewritten={}):
while pos > 0:
pos -= 1
if pos not in rewritten:
return text[pos].isspace()
elif rewritten[pos] is not None:
return rewritten[pos].isspace()
else:
pass
return True
def following_space(pos, text, rewritten={}):
while pos < len(text):
if pos not in rewritten:
return text[pos].isspace()
elif rewritten[pos] is not None:
return rewritten[pos].isspace()
else:
pass
pos += 1
return True
def preceding_linebreak(pos, text, rewritten={}):
if pos >= len(text):
return True
while pos > 0:
pos -= 1
c = rewritten.get(pos, text[pos])
if c == "\n":
return True
elif c is not None and not c.isspace():
return False
else:
pass
return True
def following_linebreak(pos, text, rewritten={}):
while pos < len(text):
c = rewritten.get(pos, text[pos])
if c == "\n":
return True
elif c is not None and not c.isspace():
return False
else:
pass
pos += 1
return True
def index_in_parent(e, p):
index = None
for i in range(len(p)):
if p[i] == e:
index = i
break
assert i is not None, "index_in_parent: error: not parent and child"
return i
def space_normalize(root, text=None, standoffs=None):
if text is None or standoffs is None:
text, standoffs = text_and_standoffs(root)
for so in standoffs:
e = so.element
if e.text is not None and e.text != "":
e.text = re.sub(r'\s+', ' ', e.text)
if e.tail is not None and e.tail != "":
e.tail = re.sub(r'\s+', ' ', e.tail)
def strip_elements(root, elements_to_strip=set(), text=None, standoffs=None):
if text is None or standoffs is None:
text, standoffs = text_and_standoffs(root)
rewritten = {}
for so in standoffs:
e = so.element
if e.tag == INSERTED_ELEMENT_TAG:
continue
if ((e.text is not None and e.text != "" and e.text[0].isspace()) and
(element_in_set(e, elements_to_strip) or
preceding_space(so.start, text, rewritten))):
l = 0
while l < len(e.text) and e.text[l].isspace():
l += 1
space, end = e.text[:l], e.text[l:]
for i in range(l):
assert so.start+i not in rewritten, "ERROR: dup remove at %d"  % (so.start+i)
rewritten[so.start+i] = None
e.text = end
if len(e) == 0:
if ((e.text is not None and e.text != "" and e.text[-1].isspace()) and
(element_in_set(e, elements_to_strip) or
following_space(so.end, text, rewritten))):
l = 0
while l < len(e.text) and e.text[-l-1].isspace():
l += 1
start, space = e.text[:-l], e.text[-l:]
for i in range(l):
o = so.end-i-1
assert o not in rewritten, "ERROR: dup remove"
rewritten[o] = None
e.text = start
else:
c = e[-1]
if ((c.tail is not None and c.tail != "" and c.tail[-1].isspace()) and
(element_in_set(e, elements_to_strip) or
following_space(so.end, text, rewritten))):
l = 0
while l < len(c.tail) and c.tail[-l-1].isspace():
l += 1
start, space = c.tail[:-l], c.tail[-l:]
for i in range(l):
o = so.end-i-1
assert o not in rewritten, "ERROR: dup remove"
rewritten[o] = None
c.tail = start
def trim_tails(root):
text, standoffs = text_and_standoffs(root)
for so in standoffs:
e = so.element
if (e.tail is not None and e.tail != "" and e.tail[0].isspace() and
preceding_space(so.end, text)):
l = 0
while l < len(e.tail) and e.tail[l].isspace():
l += 1
space, end = e.tail[:l], e.tail[l:]
e.tail = end
def reduce_space(root, elements_to_strip=set()):
text, standoffs = text_and_standoffs(root)
strip_elements(root, elements_to_strip, text, standoffs)
trim_tails(root)
space_normalize(root, text, standoffs)
def element_in_set(e, s):
if e.tag[0] == "{":
tag = re.sub(r'\{.*?\}', '', e.tag)
else:
tag = e.tag
return tag in s
def process(fn):
global strip_element
global options
if fn == "-":
fn = "/dev/stdin"
try:
tree = ET.parse(fn)
except:
print >> sys.stderr, "Error parsing %s" % fn
raise
root = tree.getroot()
reduce_space(root, strip_element)
text, standoffs = text_and_standoffs(root)
respace = {}
for so in standoffs:
e = so.element
if element_in_set(e, newline_wrap_element):
if not (so.start in respace and (respace[so.start][0] == "\n" and
respace[so.start][1] == False)):
respace[so.start] = ("\n", True)
respace[so.end] = ("\n", False)
elif element_in_set(e, space_wrap_element):
if not (so.start in respace and (respace[so.start][0] == "\n" or
respace[so.start][1] == False)):
respace[so.start] = (" ", True)
if not (so.end in respace and respace[so.end][0] == "\n"):
respace[so.end] = (" ", False)
rewritten = {}
filtered = {}
for pos in sorted(respace.keys()):
if respace[pos][0] == " ":
if not (preceding_space(pos, text, rewritten) or
following_space(pos, text, rewritten)):
filtered[pos] = respace[pos]
rewritten[pos-1] = " "
else:
assert respace[pos][0] == "\n", "INTERNAL ERROR"
if not (preceding_linebreak(pos, text, rewritten) or
following_linebreak(pos, text, rewritten)):
filtered[pos] = respace[pos]
rewritten[pos-1] = "\n"
respace = filtered
parent_map = {}
for parent in root.getiterator():
for child in parent:
parent_map[child] = parent
end_map = {}
for so in standoffs:
if so.end not in end_map:
end_map[so.end] = []
end_map[so.end].append(so)
for so in standoffs:
if so.start in respace and respace[so.start][1] == True:
e = so.element
assert e in parent_map, "INTERNAL ERROR: add space before root?"
p = parent_map[e]
i = index_in_parent(e, p)
rse = ET.Element(INSERTED_ELEMENT_TAG)
rse.text = respace[so.start][0]
p.insert(i, rse)
del respace[so.start]
if so.end in respace and respace[so.end][1] == False:
maxlen = max([s.end-s.start for s in end_map[so.end]])
if so.end-so.start != maxlen:
continue
longest = [s for s in end_map[so.end] if s.end-s.start == maxlen]
if so != longest[0]:
continue
e = so.element
assert e in parent_map, "INTERNAL ERROR: add space after root?"
p = parent_map[e]
i = index_in_parent(e, p)
rse = ET.Element(INSERTED_ELEMENT_TAG)
rse.text = respace[so.end][0]
p.insert(i+1, rse)
rse.tail = e.tail
e.tail = ""
del respace[so.end]
assert len(respace) == 0, "INTERNAL ERROR: failed to insert %s" % str(respace)
strip_elements(root)
trim_tails(root)
if options.stdout:
tree.write(sys.stdout, encoding=OUTPUT_ENCODING)
return True
if options is not None and options.directory is not None:
output_dir = options.directory
else:
output_dir = ""
output_fn = os.path.join(output_dir, os.path.basename(fn))
if output_fn == fn and not options.overwrite:
print >> sys.stderr, 'respace: skipping output for %s: file would overwrite input (consider -d and -o options)' % fn
else:
try:
with open(output_fn, 'w') as of:
tree.write(of, encoding=OUTPUT_ENCODING)
except IOError, ex:
print >> sys.stderr, 'respace: failed write: %s' % ex
return True
def argparser():
import argparse
ap=argparse.ArgumentParser(description='Revise whitespace content of a PMC NXML file for text extraction.')
ap.add_argument('-d', '--directory', default=None, metavar='DIR', help='output directory')
ap.add_argument('-o', '--overwrite', default=False, action='store_true', help='allow output to overwrite input files')
ap.add_argument('-s', '--stdout', default=False, action='store_true', help='output to stdout')
ap.add_argument('file', nargs='+', help='input PubMed Central NXML file')
return ap
def main(argv):
global options
options = argparser().parse_args(argv[1:])
for fn in options.file:
process(fn)
return 0
if __name__ == "__main__":
sys.exit(main(sys.argv))
import gzip
import logging
import zlib
from io import BytesIO
from .exceptions import DecodeError
from .packages.six import string_types as basestring
log = logging.getLogger(__name__)
def decode_gzip(data):
gzipper = gzip.GzipFile(fileobj=BytesIO(data))
return gzipper.read()
def decode_deflate(data):
try:
return zlib.decompress(data)
except zlib.error:
return zlib.decompress(data, -zlib.MAX_WBITS)
class HTTPResponse(object):
CONTENT_DECODERS = {
'gzip': decode_gzip,
'deflate': decode_deflate,
}
def __init__(self, body='', headers=None, status=0, version=0, reason=None,
strict=0, preload_content=True, decode_content=True,
original_response=None, pool=None, connection=None):
self.headers = headers or {}
self.status = status
self.version = version
self.reason = reason
self.strict = strict
self._decode_content = decode_content
self._body = body if body and isinstance(body, basestring) else None
self._fp = None
self._original_response = original_response
self._pool = pool
self._connection = connection
if hasattr(body, 'read'):
self._fp = body
if preload_content and not self._body:
self._body = self.read(decode_content=decode_content)
def get_redirect_location(self):
if self.status in [301, 302, 303, 307]:
return self.headers.get('location')
return False
def release_conn(self):
if not self._pool or not self._connection:
return
self._pool._put_conn(self._connection)
self._connection = None
@property
def data(self):
if self._body:
return self._body
if self._fp:
return self.read(cache_content=True)
def read(self, amt=None, decode_content=None, cache_content=False):
content_encoding = self.headers.get('content-encoding', '').lower()
decoder = self.CONTENT_DECODERS.get(content_encoding)
if decode_content is None:
decode_content = self._decode_content
if self._fp is None:
return
try:
if amt is None:
data = self._fp.read()
else:
return self._fp.read(amt)
try:
if decode_content and decoder:
data = decoder(data)
except (IOError, zlib.error):
raise DecodeError("Received response with content-encoding: %s, but "
"failed to decode it." % content_encoding)
if cache_content:
self._body = data
return data
finally:
if self._original_response and self._original_response.isclosed():
self.release_conn()
@classmethod
def from_httplib(ResponseCls, r, **response_kw):
headers = {}
for k, v in r.getheaders():
k = k.lower()
has_value = headers.get(k)
if has_value:
v = ', '.join([has_value, v])
headers[k] = v
strict = getattr(r, 'strict', 0)
return ResponseCls(body=r,
headers=headers,
status=r.status,
version=r.version,
reason=r.reason,
strict=strict,
original_response=r,
**response_kw)
def getheaders(self):
return self.headers
def getheader(self, name, default=None):
return self.headers.get(name, default)
class Solution(object):
def solve(self, cipher):
l, b = cipher
r = self.gcd(l, b)
return (l * b) / (r * r)
def gcd(self, a, b):
while b:
a, b = b, a % b
return a
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = map(int, f.readline().strip().split(' '))
s = "%s\n" % (Solution().solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
N, K = cipher
if K < N / 2:
return 2 * K + 1
else:
return 2 * (N - 1 - K)
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = map(int, f.readline().strip().split(' '))
s = "%s\n" % (Solution().solve(cipher))
print s,
class ListNode:
def __init__(self, x):
self.val = x
self.next = None
class Solution:
def rotateRight(self, head, k):
if not head:
return head
dummy = ListNode(0)
dummy.next = head
l = self.get_len(head)
k %= l
pre = dummy
i = 0
while pre and i < l-k:
pre = pre.next
i += 1
new_head = pre.next
if not new_head:
return dummy.next
cur = new_head
pre.next = None
while cur.next:
cur = cur.next
cur.next = dummy.next
dummy.next = new_head
return dummy.next
def get_len(self, head):
l = 0
cur = head
while cur:
l += 1
cur = cur.next
return l
class DirectedGraphNode:
def __init__(self, x):
self.label = x
self.neighbors = []
class Solution(object):
def hasRoute(self, graph, s, t):
visited = set()
return self.dfs(s, t, visited)
def dfs(self, s, t, visited):
if s == t:
return True
visited.add(s)
for nbr in s.neighbors:
if nbr not in visited:
if self.dfs(nbr, t, visited):
return True
return False
MOD = 1e9 + 7
class Solution(object):
def solve_TLE(self, cipher):
A = map(int, list(cipher))
f = A[0]
num = A[0]
sig = 1
for i in xrange(1, len(A)):
num = 10 * num + A[i]
sig *= 10
temp = num
temp_sig = sig
while temp_sig >= 1:
f += temp
f %= MOD
temp %= temp_sig
temp_sig /= 10
return int(f)
def solve(self, cipher):
pre = [0 for _ in cipher]
pre[0] = int(cipher[0])
for i in xrange(1, len(cipher)):
pre[i] = (pre[i - 1] * 10 + int(cipher[i]) * (i + 1)) % MOD
s = 0
for elt in pre:
s = (s + elt) % MOD
return int(s)
if __name__ == "__main__":
import sys
f = open("0.in", "r")
solution = Solution()
cipher = f.readline().strip()
s = "%s\n" % (solution.solve(cipher))
print s,
import numpy as np
import matplotlib.pyplot as plt
import ns.core
rng = ns.core.NormalVariable(100.0, 225.0)
x = [rng.GetValue() for t in range(10000)]
n, bins, patches = plt.hist(x, 50, normed=1, facecolor='g', alpha=0.75)
plt.title('ns-3 histogram')
plt.text(60, .025, r'$\mu=100,\ \sigma=15$')
plt.axis([40, 160, 0, 0.03])
plt.grid(True)
plt.show()
import ns.core
class MyModel(object):
def Start(self):
ns.core.Simulator.Schedule(ns.core.Seconds(10.0), self.HandleEvent, ns.core.Simulator.Now().GetSeconds())
def HandleEvent(self, value):
print "Member method received event at", ns.core.Simulator.Now().GetSeconds(), \
"s started at", value, "s"
def ExampleFunction(model):
print "ExampleFunction received event at", ns.core.Simulator.Now().GetSeconds(), "s"
model.Start()
def RandomFunction(model):
print "RandomFunction received event at", ns.core.Simulator.Now().GetSeconds(), "s"
def CancelledEvent():
print "I should never be called... "
def main(dummy_argv):
model = MyModel()
v = ns.core.UniformVariable(10,20)
ns.core.Simulator.Schedule(ns.core.Seconds(10.0), ExampleFunction, model)
ns.core.Simulator.Schedule(ns.core.Seconds(v.GetValue()), RandomFunction, model)
id = ns.core.Simulator.Schedule(ns.core.Seconds(30.0), CancelledEvent)
ns.core.Simulator.Cancel(id)
ns.core.Simulator.Run()
ns.core.Simulator.Destroy()
if __name__ == '__main__':
import sys
main(sys.argv)
class Solution(object):
def solve(self, cipher):
N, A = cipher
ret = 0
for i, val in enumerate(A):
if (i + 1) * (N - i) % 2 == 1:
ret ^= val
return ret
if __name__ == "__main__":
import sys
f = open("1.in", "r")
solution = Solution()
testcases = int(f.readline().strip())
for t in xrange(testcases):
N = int(f.readline().strip())
A = map(int, f.readline().strip().split(' '))
cipher = N, A
s = "%s\n" % (solution.solve(cipher))
print s,
import sys
from . import constants
from .charsetprober import CharSetProber
from .compat import wrap_ord
SAMPLE_SIZE = 64
SB_ENOUGH_REL_THRESHOLD = 1024
POSITIVE_SHORTCUT_THRESHOLD = 0.95
NEGATIVE_SHORTCUT_THRESHOLD = 0.05
SYMBOL_CAT_ORDER = 250
NUMBER_OF_SEQ_CAT = 4
POSITIVE_CAT = NUMBER_OF_SEQ_CAT - 1
class SingleByteCharSetProber(CharSetProber):
def __init__(self, model, reversed=False, nameProber=None):
CharSetProber.__init__(self)
self._mModel = model
self._mReversed = reversed
self._mNameProber = nameProber
self.reset()
def reset(self):
CharSetProber.reset(self)
self._mLastOrder = 255
self._mSeqCounters = [0] * NUMBER_OF_SEQ_CAT
self._mTotalSeqs = 0
self._mTotalChar = 0
self._mFreqChar = 0
def get_charset_name(self):
if self._mNameProber:
return self._mNameProber.get_charset_name()
else:
return self._mModel['charsetName']
def feed(self, aBuf):
if not self._mModel['keepEnglishLetter']:
aBuf = self.filter_without_english_letters(aBuf)
aLen = len(aBuf)
if not aLen:
return self.get_state()
for c in aBuf:
order = self._mModel['charToOrderMap'][wrap_ord(c)]
if order < SYMBOL_CAT_ORDER:
self._mTotalChar += 1
if order < SAMPLE_SIZE:
self._mFreqChar += 1
if self._mLastOrder < SAMPLE_SIZE:
self._mTotalSeqs += 1
if not self._mReversed:
i = (self._mLastOrder * SAMPLE_SIZE) + order
model = self._mModel['precedenceMatrix'][i]
else:
i = (order * SAMPLE_SIZE) + self._mLastOrder
model = self._mModel['precedenceMatrix'][i]
self._mSeqCounters[model] += 1
self._mLastOrder = order
if self.get_state() == constants.eDetecting:
if self._mTotalSeqs > SB_ENOUGH_REL_THRESHOLD:
cf = self.get_confidence()
if cf > POSITIVE_SHORTCUT_THRESHOLD:
if constants._debug:
sys.stderr.write('%s confidence = %s, we have a'
'winner\n' %
(self._mModel['charsetName'], cf))
self._mState = constants.eFoundIt
elif cf < NEGATIVE_SHORTCUT_THRESHOLD:
if constants._debug:
sys.stderr.write('%s confidence = %s, below negative'
'shortcut threshhold %s\n' %
(self._mModel['charsetName'], cf,
NEGATIVE_SHORTCUT_THRESHOLD))
self._mState = constants.eNotMe
return self.get_state()
def get_confidence(self):
r = 0.01
if self._mTotalSeqs > 0:
r = ((1.0 * self._mSeqCounters[POSITIVE_CAT]) / self._mTotalSeqs
/ self._mModel['mTypicalPositiveRatio'])
r = r * self._mFreqChar / self._mTotalChar
if r >= 1.0:
r = 0.99
return r
from .charsetgroupprober import CharSetGroupProber
from .sbcharsetprober import SingleByteCharSetProber
from .langcyrillicmodel import (Win1251CyrillicModel, Koi8rModel,
Latin5CyrillicModel, MacCyrillicModel,
Ibm866Model, Ibm855Model)
from .langgreekmodel import Latin7GreekModel, Win1253GreekModel
from .langbulgarianmodel import Latin5BulgarianModel, Win1251BulgarianModel
from .langhungarianmodel import Latin2HungarianModel, Win1250HungarianModel
from .langthaimodel import TIS620ThaiModel
from .langhebrewmodel import Win1255HebrewModel
from .hebrewprober import HebrewProber
class SBCSGroupProber(CharSetGroupProber):
def __init__(self):
CharSetGroupProber.__init__(self)
self._mProbers = [
SingleByteCharSetProber(Win1251CyrillicModel),
SingleByteCharSetProber(Koi8rModel),
SingleByteCharSetProber(Latin5CyrillicModel),
SingleByteCharSetProber(MacCyrillicModel),
SingleByteCharSetProber(Ibm866Model),
SingleByteCharSetProber(Ibm855Model),
SingleByteCharSetProber(Latin7GreekModel),
SingleByteCharSetProber(Win1253GreekModel),
SingleByteCharSetProber(Latin5BulgarianModel),
SingleByteCharSetProber(Win1251BulgarianModel),
SingleByteCharSetProber(Latin2HungarianModel),
SingleByteCharSetProber(Win1250HungarianModel),
SingleByteCharSetProber(TIS620ThaiModel),
]
hebrewProber = HebrewProber()
logicalHebrewProber = SingleByteCharSetProber(Win1255HebrewModel,
False, hebrewProber)
visualHebrewProber = SingleByteCharSetProber(Win1255HebrewModel, True,
hebrewProber)
hebrewProber.set_model_probers(logicalHebrewProber, visualHebrewProber)
self._mProbers.extend([hebrewProber, logicalHebrewProber,
visualHebrewProber])
self.reset()
from collections import defaultdict
class Val(object):
def __init__(self):
self.cnt = 0
self.start = 0
class TaskScheduleSolution(object):
def solve(self, A, intvl):
m = defaultdict(Val)
for e in A:
m[e].cnt += 1
t = 0
for _ in A:
maxa = None
for k, v in m.items():
if not maxa or m[maxa].cnt <= v.cnt:
if m[maxa].cnt == v.cnt and m[maxa].start > v.start:
maxa = k
elif m[maxa].cnt < v.cnt:
maxa = k
t = max(t, m[maxa].start)+1
m[maxa].cnt -= 1
if m[maxa] <= 0:
del m[maxa]
m[maxa].start = t+intvl
return t
if __name__ == "__main__":
assert TaskScheduleSolution().solve([1, 1, 2, 1], 2) == 7
assert TaskScheduleSolution().solve([1, 2, 3, 1, 2, 3], 3) == 7
class TreeNode:
def __init__(self, val):
self.val = val
self.left, self.right = None, None
class Solution(object):
def searchRange(self, root, k1, k2):
ret = []
self.dfs(root, k1, k2, ret)
return ret
def dfs(self, root, k1, k2, ret):
if not root:
return
if root.val < k1:
self.dfs(root.right, k1, k2, ret)
elif root.val > k2:
self.dfs(root.left, k1, k2, ret)
else:
self.dfs(root.left, k1, k2, ret)
ret.append(root.val)
self.dfs(root.right, k1, k2, ret)
class SegmentTreeNode:
def __init__(self, start, end):
self.start, self.end = start, end
self.left, self.right = None, None
class Solution:
def build(self, start, end):
if start > end:
return None
root = SegmentTreeNode(start, end)
if start == end:
return root
root.left = self.build(start, (start+end)/2)
root.right = self.build((start+end)/2+1, end)
return root
class SegmentTreeNode:
def __init__(self, start, end, max):
self.start, self.end, self.max = start, end, max
self.left, self.right = None, None
class Solution:
def modify(self, root, index, value):
if root is None:
return
if index < root.start or index > root.end:
return
if root.start == index and root.end == index:
root.max = value
return
self.modify(root.left, index, value)
self.modify(root.right, index, value)
m = value
if root.left:
m = max(m, root.left.max)
if root.right:
m = max(m, root.right.max)
root.max = m
DEFAULT = 0
f = lambda x, y: x+y
class Solution:
def query(self, root, s, e):
if not root:
return DEFAULT
if s <= root.start and e >= root.end:
return root.count
if s > root.end or e < root.start:
return DEFAULT
l = self.query(root.left, s, e)
r = self.query(root.right, s, e)
return f(l, r)
import sys
class SegmentTreeNode:
def __init__(self, start, end, max):
self.start, self.end, self.max = start, end, max
self.left, self.right = None, None
class Solution:
def query(self, root, start, end):
if start <= root.start and end >= root.end:
return root.max
if start > end:
return -sys.maxint-1
maxa = -sys.maxint-1
if root.left:
left = self.query(root.left, start, end)
maxa = max(maxa, left)
if root.right:
right = self.query(root.right, start, end)
maxa = max(maxa, right)
return maxa
class Node(object):
def __init__(self, lo, hi, cnt):
self.lo = lo
self.hi = hi
self.cnt = cnt
self.left = None
self.right = None
def __repr__(self):
return repr("[%d,%d)" % (self.lo, self.hi))
class SegmentTree(object):
def __init__(self):
self.root = None
def build(self, lo, hi):
if lo >= hi: return
if lo == hi-1: return Node(lo, hi, 1)
root = Node(lo, hi, hi-lo)
root.left = self.build(lo, (hi+lo)/2)
root.right = self.build((lo+hi)/2, hi)
return root
def find_delete(self, root, val):
root.cnt -= 1
if not root.left:
return root.lo
elif root.left.cnt >= val:
return self.find_delete(root.left, val)
else:
return self.find_delete(root.right,
val - root.left.cnt)
class Solution(object):
def reconstruct(self, A):
st = SegmentTree()
n = len(A)
st.root = st.build(0, n)
A = sorted(A, key=lambda x: x[0])
ret = [0]*n
for a in A:
idx = st.find_delete(st.root, a[1]+1)
ret[idx] = a[0]
return ret
if __name__ == "__main__":
A = [(5, 0), (2, 1), (3, 1), (4, 1,), (1, 4)]
assert Solution().reconstruct(A) == [5, 2, 3, 4, 1]
import sys
from os.path import join as path_join
from os.path import dirname
from sys import path as sys_path
sys_path.append(path_join(dirname(__file__), '../server/src'))
from ssplit import regex_sentence_boundary_gen
def _text_by_offsets_gen(text, offsets):
for start, end in offsets:
yield text[start:end]
def _normspace(s):
import re
return re.sub(r'\s', ' ', s)
def sentencebreaks_to_newlines(text):
line_offset = 1
if "\r\n" in text:
line_offset = 2
offsets = [o for o in regex_sentence_boundary_gen(text)]
sentences = [s for s in _text_by_offsets_gen(text, offsets)]
orig_parts = []
new_parts = []
sentnum = len(sentences)
for i in range(sentnum):
sent = sentences[i]
orig_parts.append(sent)
new_parts.append(sent)
if i < sentnum-1:
orig_parts.append(text[offsets[i][1]:offsets[i+1][0]])
if (offsets[i][1] < offsets[i+1][0] and
text[offsets[i][1]].isspace()):
new_parts.append('\n'+text[offsets[i][1]+line_offset:offsets[i+1][0]])
else:
new_parts.append(text[offsets[i][1]:offsets[i+1][0]])
if len(offsets) and offsets[-1][1] < len(text):
orig_parts.append(text[offsets[-1][1]:])
new_parts.append(text[offsets[-1][1]:])
assert text == ''.join(orig_parts), "INTERNAL ERROR:\n    '%s'\nvs\n    '%s'" % (text, ''.join(orig_parts))
splittext = ''.join(new_parts)
assert len(text) == len(splittext), "INTERNAL ERROR"
assert _normspace(text) == _normspace(splittext), "INTERNAL ERROR:\n    '%s'\nvs\n    '%s'" % (_normspace(text), _normspace(splittext))
return splittext
def main(argv):
while True:
text = sys.stdin.readline()
if len(text) == 0:
break
sys.stdout.write(sentencebreaks_to_newlines(text))
if __name__ == "__main__":
sys.exit(main(sys.argv))
import cPickle
def save_model(filename, model):
output = open(filename, 'wb')
cPickle.dump(model, output)
output.close()
def load_model(filename):
pkl_file = open(filename, 'rb')
res = cPickle.load(pkl_file)
pkl_file.close()
return res
import cStringIO
import base64
try:
from PIL import Image
except ImportError:
import Image
from flask import Flask, request, request_finished, json, abort, make_response, Response, jsonify
import sys
sys.path.append("../../..")
from facerec.model import PredictableModel
from facerec.lbp import ExtendedLBP
from facerec.feature import SpatialHistogram
from facerec.distance import ChiSquareDistance
from facerec.classifier import NearestNeighbor
import logging
from logging.handlers import RotatingFileHandler
import recognition
app = Flask(__name__)
IMAGE_DECODE_ERROR = 10
IMAGE_RESIZE_ERROR = 11
PREDICTION_ERROR = 12
SERVICE_TEMPORARY_UNAVAILABLE = 20
UNKNOWN_ERROR = 21
INVALID_FORMAT = 30
INVALID_API_KEY = 31
INVALID_API_TOKEN = 32
MISSING_ARGUMENTS = 40
errors = {
IMAGE_DECODE_ERROR : "IMAGE_DECODE_ERROR",
IMAGE_RESIZE_ERROR  : "IMAGE_RESIZE_ERROR",
SERVICE_TEMPORARY_UNAVAILABLE	: "SERVICE_TEMPORARILY_UNAVAILABLE",
PREDICTION_ERROR : "PREDICTION_ERROR",
UNKNOWN_ERROR : "UNKNOWN_ERROR",
INVALID_FORMAT : "INVALID_FORMAT",
INVALID_API_KEY : "INVALID_API_KEY",
INVALID_API_TOKEN : "INVALID_API_TOKEN",
MISSING_ARGUMENTS : "MISSING_ARGUMENTS"
}
LOG_FILENAME = 'serverlog.log'
LOG_BACKUP_COUNT = 5
LOG_FILE_SIZE_BYTES = 50 * 1024 * 1024
def init_logger(app):
handler = RotatingFileHandler(LOG_FILENAME, maxBytes=LOG_FILE_SIZE_BYTES, backupCount=LOG_BACKUP_COUNT)
handler.setLevel(logging.DEBUG)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
loggers = [app.logger, logging.getLogger('facerec')]
for logger in loggers:
logger.addHandler(handler)
def init_app(app):
init_logger(app)
init_app(app)
@app.before_request
def log_request():
app.logger.debug("Request: %s %s", request.method, request.url)
class WebAppException(Exception):
def __init__(self, error_code, exception, status_code=None):
Exception.__init__(self)
self.status_code = 400
self.exception = exception
self.error_code = error_code
try:
self.message = errors[self.error_code]
except:
self.error_code = UNKNOWN_ERROR
self.message = errors[self.error_code]
if status_code is not None:
self.status_code = status_code
def to_dict(self):
rv = dict()
rv['status'] = 'failed'
rv['code'] = self.error_code
rv['message'] = self.message
return rv
class ThrowsWebAppException(object):
def __init__(self, error_code, status_code=None):
self.error_code = error_code
self.status_code = status_code
def __call__(self, function):
def returnfunction(*args, **kwargs):
try:
return function(*args, **kwargs)
except Exception as e:
raise WebAppException(self.error_code, e)
return returnfunction
@app.errorhandler(WebAppException)
def handle_exception(error):
app.logger.exception(error.exception)
response = jsonify(error.to_dict())
response.status_code = error.status_code
return response
@ThrowsWebAppException(error_code = IMAGE_DECODE_ERROR)
def read_image(base64_image):
enc_data = base64.b64decode(base64_image)
file_like = cStringIO.StringIO(enc_data)
im = Image.open(file_like)
im = im.convert("L")
return im
def preprocess_image(image_data):
image = read_image(image_data)
return image
@ThrowsWebAppException(error_code = PREDICTION_ERROR)
def get_prediction(image_data):
image = preprocess_image(image_data)
prediction = model.predict(image)
return prediction
@app.route('/api/recognize', methods=['GET', 'POST'])
def identify():
if request.headers['Content-Type'] == 'application/json':
try:
image_data = request.json['image']
except:
raise WebAppException(error_code=MISSING_ARGUMENTS)
prediction = get_prediction(image_data)
response = jsonify(name = prediction)
return response
else:
raise WebAppException(error_code=INVALID_FORMAT)
if __name__ == '__main__':
long_description = ("server.py is a simple facerec webservice. It provides "
"you with a simple RESTful API to recognize faces from a "
"computed model. Please don't use this server in a production "
"environment, as it provides no security and there might be "
"ugly concurrency issues with the global state of the model." )
print "=== Description ==="
print long_description
from argparse import ArgumentParser
parser = ArgumentParser()
parser.add_argument("-t", "--train", action="store", dest="dataset", default=None,
help="Calculates a new model from a given CSV file. CSV format: <person>;</path/to/image/folder>.", required=False)
parser.add_argument("-a", "--address", action="store", dest="host", default="0.0.0.0",
help="Sets the endpoint for this server.", required=False)
parser.add_argument("-p", "--port", action="store", dest="port", default=5000,
help="Sets the port for this server.", required=False)
parser.add_argument('model_filename', nargs='?', help="Filename of the model to use or store")
print "=== Usage ==="
parser.print_help()
args = parser.parse_args()
global model
if args.dataset:
model = recognition.get_model_from_csv(filename=args.dataset,out_model_filename=args.model_filename)
else:
model = recognition.load_model_file(args.model_filename)
print "=== Server Log (also in %s) ===" % (LOG_FILENAME)
app.run(host=args.host, port=args.port, debug=True, use_reloader=False, threaded=False)
import os
from .compat import cookielib
from .cookies import cookiejar_from_dict
from .models import Request
from .hooks import dispatch_hook, default_hooks
from .utils import from_key_val_list, default_headers
from .exceptions import TooManyRedirects, InvalidSchema
from .compat import urlparse, urljoin
from .adapters import HTTPAdapter
from .utils import requote_uri, get_environ_proxies, get_netrc_auth
from .status_codes import codes
REDIRECT_STATI = (codes.moved, codes.found, codes.other, codes.temporary_moved)
DEFAULT_REDIRECT_LIMIT = 30
def merge_kwargs(local_kwarg, default_kwarg):
if default_kwarg is None:
return local_kwarg
if isinstance(local_kwarg, str):
return local_kwarg
if local_kwarg is None:
return default_kwarg
if not hasattr(default_kwarg, 'items'):
return local_kwarg
default_kwarg = from_key_val_list(default_kwarg)
local_kwarg = from_key_val_list(local_kwarg)
kwargs = default_kwarg.copy()
kwargs.update(local_kwarg)
for (k, v) in local_kwarg.items():
if v is None:
del kwargs[k]
return kwargs
class SessionRedirectMixin(object):
def resolve_redirects(self, resp, req, stream=False, timeout=None, verify=True, cert=None, proxies=None):
i = 0
while (('location' in resp.headers and resp.status_code in REDIRECT_STATI)):
resp.content
if i >= self.max_redirects:
raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects)
resp.close()
url = resp.headers['location']
method = req.method
if url.startswith('//'):
parsed_rurl = urlparse(resp.url)
url = '%s:%s' % (parsed_rurl.scheme, url)
if not urlparse(url).netloc:
url = urljoin(resp.url, requote_uri(url))
if resp.status_code is codes.see_other:
method = 'GET'
if resp.status_code in (codes.moved, codes.found) and req.method == 'POST':
method = 'GET'
if (resp.status_code == 303) and req.method != 'HEAD':
method = 'GET'
headers = req.headers
try:
del headers['Cookie']
except KeyError:
pass
resp = self.request(
url=url,
method=method,
headers=headers,
params=req.params,
auth=req.auth,
cookies=req.cookies,
allow_redirects=False,
stream=stream,
timeout=timeout,
verify=verify,
cert=cert,
proxies=proxies
)
i += 1
yield resp
class Session(SessionRedirectMixin):
def __init__(self):
self.headers = default_headers()
self.auth = None
self.proxies = {}
self.hooks = default_hooks()
self.params = {}
self.stream = False
self.verify = True
self.cert = None
self.max_redirects = DEFAULT_REDIRECT_LIMIT
self.trust_env = True
self.cookies = cookiejar_from_dict({})
self.adapters = {}
self.mount('http://', HTTPAdapter())
self.mount('https://', HTTPAdapter())
def __enter__(self):
return self
def __exit__(self, *args):
self.close()
def request(self, method, url,
params=None,
data=None,
headers=None,
cookies=None,
files=None,
auth=None,
timeout=None,
allow_redirects=True,
proxies=None,
hooks=None,
stream=None,
verify=None,
cert=None):
cookies = cookies or {}
proxies = proxies or {}
if not isinstance(cookies, cookielib.CookieJar):
cookies = cookiejar_from_dict(cookies)
for cookie in self.cookies:
cookies.set_cookie(cookie)
if self.trust_env:
env_proxies = get_environ_proxies(url) or {}
for (k, v) in env_proxies.items():
proxies.setdefault(k, v)
if not auth:
auth = get_netrc_auth(url)
if not verify and verify is not False:
verify = os.environ.get('REQUESTS_CA_BUNDLE')
if not verify and verify is not False:
verify = os.environ.get('CURL_CA_BUNDLE')
params = merge_kwargs(params, self.params)
headers = merge_kwargs(headers, self.headers)
auth = merge_kwargs(auth, self.auth)
proxies = merge_kwargs(proxies, self.proxies)
hooks = merge_kwargs(hooks, self.hooks)
stream = merge_kwargs(stream, self.stream)
verify = merge_kwargs(verify, self.verify)
cert = merge_kwargs(cert, self.cert)
req = Request()
req.method = method
req.url = url
req.headers = headers
req.files = files
req.data = data
req.params = params
req.auth = auth
req.cookies = cookies
req.hooks = hooks
prep = req.prepare()
resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
for cookie in resp.cookies:
self.cookies.set_cookie(cookie)
gen = self.resolve_redirects(resp, req, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)
history = [r for r in gen] if allow_redirects else []
if history:
history.insert(0, resp)
resp = history.pop()
resp.history = tuple(history)
self.response = dispatch_hook('response', hooks, resp)
return resp
def get(self, url, **kwargs):
kwargs.setdefault('allow_redirects', True)
return self.request('GET', url, **kwargs)
def options(self, url, **kwargs):
kwargs.setdefault('allow_redirects', True)
return self.request('OPTIONS', url, **kwargs)
def head(self, url, **kwargs):
kwargs.setdefault('allow_redirects', False)
return self.request('HEAD', url, **kwargs)
def post(self, url, data=None, **kwargs):
return self.request('POST', url, data=data, **kwargs)
def put(self, url, data=None, **kwargs):
return self.request('PUT', url, data=data, **kwargs)
def patch(self, url, data=None, **kwargs):
return self.request('PATCH', url,  data=data, **kwargs)
def delete(self, url, **kwargs):
return self.request('DELETE', url, **kwargs)
def send(self, request, **kwargs):
adapter = self.get_adapter(url=request.url)
r = adapter.send(request, **kwargs)
return r
def get_adapter(self, url):
for (prefix, adapter) in self.adapters.items():
if url.startswith(prefix):
return adapter
raise InvalidSchema("No connection adapters were found for '%s'" % url)
def close(self):
for _, v in self.adapters.items():
v.close()
def mount(self, prefix, adapter):
self.adapters[prefix] = adapter
def __getstate__(self):
return dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)
def __setstate__(self, state):
for attr, value in state.items():
setattr(self, attr, value)
def session():
return Session()
import os
import dj_database_url
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SECRET_KEY = 'zepnf(4ontqc)o2=owlr5354698rgdw_l8!8%rl056$d(td)!u'
DEBUG = False
ALLOWED_HOSTS = ["*"]
INSTALLED_APPS = (
'django.contrib.admin',
'django.contrib.auth',
'django.contrib.contenttypes',
'django.contrib.sessions',
'django.contrib.messages',
'django.contrib.staticfiles',
'rake_app',
)
MIDDLEWARE_CLASSES = (
'django.contrib.sessions.middleware.SessionMiddleware',
'django.middleware.common.CommonMiddleware',
'django.middleware.csrf.CsrfViewMiddleware',
'django.contrib.auth.middleware.AuthenticationMiddleware',
'django.contrib.auth.middleware.SessionAuthenticationMiddleware',
'django.contrib.messages.middleware.MessageMiddleware',
'django.middleware.clickjacking.XFrameOptionsMiddleware',
'django.middleware.security.SecurityMiddleware',
)
ROOT_URLCONF = 'tagr.urls'
TEMPLATES = [
{
'BACKEND': 'django.template.backends.django.DjangoTemplates',
'DIRS': [
os.path.join(BASE_DIR, 'templates').replace('\\', '/'),
],
'APP_DIRS': True,
'OPTIONS': {
'context_processors': [
'django.template.context_processors.debug',
'django.template.context_processors.request',
'django.contrib.auth.context_processors.auth',
'django.contrib.messages.context_processors.messages',
],
},
},
]
WSGI_APPLICATION = 'tagr.wsgi.application'
DATABASES = {
'default': {
'ENGINE': 'django.db.backends.sqlite3',
'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),
}
}
LANGUAGE_CODE = 'en-us'
TIME_ZONE = 'UTC'
USE_I18N = True
USE_L10N = True
USE_TZ = True
SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')
STATIC_ROOT = 'staticfiles'
STATIC_URL = '/static/'
STATICFILES_DIRS = (
os.path.join(BASE_DIR, 'static'),
)
STATICFILES_STORAGE = 'whitenoise.django.GzipManifestStaticFilesStorage'
MEDIA_URL = 'media/'
MEDIA_DIRS = (
os.path.join(BASE_DIR, 'media'),
)
from distutils.core import setup
import os
setup(
name         = 'snippyt',
version      = '0.0.1',
author       = 'Daniel D. Zhang',
author_email = 'dzhang.idf@gmail.com',
license      = 'BSD-3',
description  = 'A command line snippet management for modern developers.',
url          = 'https://github.com/idf/snippyt',
packages     = [
'snippyt',
'snippyt.templates',
],
package_data = {
'snippyt.templates': [f for f in os.listdir('snippyt/templates') if '.' not in f]
},
scripts          = ['snip'],
install_requires = [
'docopt >= 0.6.2',
'Jinja2 >= 2.9.5',
'MarkupSafe >= 1.0',
]
)
import shlex
import subprocess
import sys
import re
import os
env_var_rx = re.compile(r"^([a-zA-Z0-9_]+)=(\S+)$")
def debug(message):
print >> sys.stderr, message
if sys.platform == 'win32':
dev_null = open("NUL:", "w")
else:
dev_null = open("/dev/null", "w")
fcntl = fd = fl = None
try:
import fcntl
except ImportError:
pass
else:
fd = dev_null.fileno()
fl = fcntl.fcntl(fd, fcntl.F_GETFD)
fcntl.fcntl(fd, fcntl.F_SETFD, fl | fcntl.FD_CLOEXEC)
del fcntl, fd, fl
def _open_out_file(filename):
if filename in ['NUL:', '/dev/null']:
return dev_null
else:
return open(filename, 'wb')
class Node(object):
pass
class Op(Node):
pass
class Pipe(Op):
pass
class And(Op):
pass
class Or(Op):
pass
class Command(Node):
class PIPE(object):
pass
class STDOUT(object):
pass
def __init__(self, name):
super(Command, self).__init__()
self.name = name
self.argv = [name]
self.stdin = None
self.stdout = None
self.stderr = None
self.env_vars = None
def __repr__(self):
return "Command(%r, argv=%r, stdin=%r, stdout=%r, stderr=%r)" \
% (self.name, self.argv, self.stdin, self.stdout, self.stderr)
class Chdir(Node):
def __init__(self):
super(Chdir, self).__init__()
self.dir = None
def __repr__(self):
return "Chdir(%r)" \
% (self.dir)
class Pipeline(object):
def __init__(self):
self.current_command = None
self.pipeline = []
def _commit_command(self):
assert self.current_command is not None
self.pipeline.append(self.current_command)
self.current_command = None
def get_abbreviated_command(self):
l = []
for node in self.pipeline:
if isinstance(node, Command):
l.append(node.name)
if isinstance(node, Chdir):
l.append('cd %s' % node.dir)
elif isinstance(node, Pipe):
l.append('|')
elif isinstance(node, And):
l.append('&&')
elif isinstance(node, And):
l.append('||')
return ' '.join(l)
def parse(self, command):
self.current_command = None
self.pipeline = []
if isinstance(command, list):
tokens = list(command)
else:
tokens = shlex.split(command)
debug("command: shlex: %r" % (tokens,))
BEGIN, COMMAND, CHDIR, STDERR, STDOUT, STDIN = range(6)
state = BEGIN
self.current_command = None
env_vars = dict()
while tokens:
token = tokens.pop(0)
if state == BEGIN:
env_var_match = env_var_rx.match(token)
if env_var_match is not None:
env_vars[env_var_match.group(1)] = env_var_match.group(2)
else:
assert self.current_command is None
if token == 'cd':
self.current_command = Chdir()
assert not env_vars
state = CHDIR
else:
self.current_command = Command(token)
if env_vars:
self.current_command.env_vars = env_vars
env_vars = dict()
state = COMMAND
elif state == COMMAND:
if token == '>':
state = STDOUT
elif token == '2>':
state = STDERR
elif token == '2>&1':
assert self.current_command.stderr is None
self.current_command.stderr = Command.STDOUT
elif token == '<':
state = STDIN
elif token == '|':
assert self.current_command.stdout is None
self.current_command.stdout = Command.PIPE
self._commit_command()
self.pipeline.append(Pipe())
state = BEGIN
elif token == '&&':
self._commit_command()
self.pipeline.append(And())
state = BEGIN
elif token == '||':
self._commit_command()
self.pipeline.append(Or())
state = BEGIN
else:
self.current_command.argv.append(token)
elif state == CHDIR:
if token == '&&':
self._commit_command()
self.pipeline.append(And())
state = BEGIN
else:
assert self.current_command.dir is None
self.current_command.dir = token
elif state == STDOUT:
assert self.current_command.stdout is None
self.current_command.stdout = token
state = COMMAND
elif state == STDERR:
assert self.current_command.stderr is None
self.current_command.stderr = token
state = COMMAND
elif state == STDIN:
assert self.current_command.stdin is None
self.current_command.stdin = token
state = COMMAND
self._commit_command()
return self.pipeline
def _exec_piped_commands(self, commands):
retvals = []
for cmd in commands:
retvals.append(cmd.wait())
retval = 0
for r in retvals:
if r:
retval = retvals[-1]
break
return retval
def run(self, verbose=False):
pipeline = list(self.pipeline)
files_to_close = []
piped_commands = []
piped_commands_display = []
BEGIN, PIPE = range(2)
state = BEGIN
cwd = '.'
while pipeline:
node = pipeline.pop(0)
if isinstance(node, Chdir):
next_op = pipeline.pop(0)
assert isinstance(next_op, And)
cwd = os.path.join(cwd, node.dir)
if verbose:
piped_commands_display.append("cd %s &&" % node.dir)
continue
assert isinstance(node, (Command, Chdir))
cmd = node
if verbose:
if cmd.env_vars:
env_vars_str = ' '.join(['%s=%s' % (key, val) for key, val in cmd.env_vars.iteritems()])
piped_commands_display.append("%s %s" % (env_vars_str, ' '.join(cmd.argv)))
else:
piped_commands_display.append(' '.join(cmd.argv))
if state == PIPE:
stdin = piped_commands[-1].stdout
elif cmd.stdin is not None:
stdin = open(cmd.stdin, "r")
if verbose:
piped_commands_display.append('< %s' % cmd.stdin)
files_to_close.append(stdin)
else:
stdin = None
if cmd.stdout is None:
stdout = None
elif cmd.stdout is Command.PIPE:
stdout = subprocess.PIPE
else:
stdout = _open_out_file(cmd.stdout)
files_to_close.append(stdout)
if verbose:
piped_commands_display.append('> %s' % cmd.stdout)
if cmd.stderr is None:
stderr = None
elif cmd.stderr is Command.PIPE:
stderr = subprocess.PIPE
elif cmd.stderr is Command.STDOUT:
stderr = subprocess.STDOUT
if verbose:
piped_commands_display.append('2>&1')
else:
stderr = _open_out_file(cmd.stderr)
files_to_close.append(stderr)
if verbose:
piped_commands_display.append('2> %s' % cmd.stderr)
if cmd.env_vars:
env = dict(os.environ)
env.update(cmd.env_vars)
else:
env = None
if cwd == '.':
proc_cwd = None
else:
proc_cwd = cwd
debug("command: subprocess.Popen(argv=%r, stdin=%r, stdout=%r, stderr=%r, env_vars=%r, cwd=%r)"
% (cmd.argv, stdin, stdout, stderr, cmd.env_vars, proc_cwd))
proc = subprocess.Popen(cmd.argv, stdin=stdin, stdout=stdout, stderr=stderr, env=env, cwd=proc_cwd)
del stdin, stdout, stderr
piped_commands.append(proc)
try:
next_node = pipeline.pop(0)
except IndexError:
try:
retval = self._exec_piped_commands(piped_commands)
if verbose:
print "%s: exit code %i" % (' '.join(piped_commands_display), retval)
finally:
for f in files_to_close:
if f is not dev_null:
f.close()
files_to_close = []
return retval
else:
if isinstance(next_node, Pipe):
state = PIPE
piped_commands_display.append('|')
elif isinstance(next_node, Or):
try:
this_retval = self._exec_piped_commands(piped_commands)
finally:
for f in files_to_close:
if f is not dev_null:
f.close()
files_to_close = []
if this_retval == 0:
if verbose:
print "%s: exit code %i (|| is short-circuited)" % (' '.join(piped_commands_display), retval)
return this_retval
if verbose:
print "%s: exit code %i (|| proceeds)" % (' '.join(piped_commands_display), retval)
state = BEGIN
piped_commands = []
piped_commands_display = []
elif isinstance(next_node, And):
try:
this_retval = self._exec_piped_commands(piped_commands)
finally:
for f in files_to_close:
if f is not dev_null:
f.close()
files_to_close = []
if this_retval != 0:
if verbose:
print "%s: exit code %i (&& is short-circuited)" % (' '.join(piped_commands_display), retval)
return this_retval
if verbose:
print "%s: exit code %i (&& proceeds)" % (' '.join(piped_commands_display), retval)
state = BEGIN
piped_commands = []
piped_commands_display = []
def _main():
pipeline = Pipeline()
pipeline.parse('./foo.py 2>&1 < xxx | cat && ls')
print pipeline.run()
if __name__ == '__main__':
_main()
import collections
class Solution(object):
def solve(self, cipher):
d = collections.defaultdict(int)
lst = list(cipher)
n = len(lst)
for i in xrange(n):
for l in xrange(1, n - i + 1):
sub = lst[i: i + l]
sub.sort()
d["".join(sub)] += 1
s = 0
for v in d.values():
s += v * (v - 1) / 2
return s
if __name__ == "__main__":
import sys
f = open("0.in", "r")
solution = Solution()
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = f.readline().strip()
s = "%s\n" % (solution.solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
N, A = cipher
f = [0 for _ in xrange(N + 1)]
for i in xrange(1, N + 1):
f[i] = f[i - 1] + A[i - 1]
for i in xrange(N):
if f[i] == f[N] - f[i + 1]:
return "YES"
return "NO"
if __name__ == "__main__":
import sys
f = open("1.in", "r")
solution = Solution()
testcases = int(f.readline().strip())
for t in xrange(testcases):
N = int(f.readline().strip())
A = map(int, f.readline().strip().split(' '))
cipher = N, A
s = "%s\n" % (solution.solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
B = cipher
N = len(B)
dp = [[0, 0] for _ in xrange(N + 1)]
LOW = 0
HIGH = 1
for i in xrange(2, N + 1):
dp[i][LOW] = max(dp[i - 1][LOW], dp[i - 1][HIGH] + abs(1 - B[i - 2]))
dp[i][HIGH] = max(dp[i - 1][HIGH], dp[i - 1][LOW] + abs(B[i - 1] - 1))
return str(max(dp[-1][LOW], dp[-1][HIGH]))
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
N = int(f.readline().strip())
cipher = map(int, f.readline().strip().split(' '))
s = "%s\n" % (Solution().solve(cipher))
print s,
import math
class Solution(object):
def solve(self, cipher):
N = cipher
if N % 2 == 1:
return 0
cnt = 0
i = 1
sq = math.sqrt(N)
while i <= sq:
if N % i == 0:
if i % 2 == 0:
cnt += 1
other = N / i
if other != i and other % 2 == 0:
cnt += 1
i += 1
return cnt
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = int(f.readline().strip())
s = "%s\n" % (Solution().solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
N, lst = cipher
for i in xrange(N):
for j in xrange(i + 1, N):
if self.gcd(lst[i], lst[j]) == 1:
return "YES"
return "NO"
def gcd(self, a, b):
while b:
a, b = b, a % b
return a
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
N = int(f.readline().strip())
lst = map(int, f.readline().strip().split(' '))
cipher = (N, lst)
s = "%s\n" % (Solution().solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
A, P, Q = cipher
A.sort()
gmax = -1 << 32
M = -1
if P <= A[0] and gmax < A[0] - P:
gmax = A[0] - P
M = P
if Q >= A[-1] and gmax < Q - A[-1]:
gmax = Q - A[-1]
M = Q
for i in xrange(1, len(A)):
max_cnd = (A[i] - A[i - 1]) / 2
if gmax < max_cnd:
M_cnd = (A[i] + A[i - 1]) / 2
if P <= M_cnd <= Q:
gmax = max_cnd
M = M_cnd
else:
if M_cnd > Q and A[i - 1] <= Q <= A[i]:
max_cnd = min(abs(A[i] - Q), abs(A[i - 1] - Q))
if gmax < max_cnd:
gmax = max_cnd
M = Q
if M_cnd < P and A[i - 1] <= P <= A[i]:
max_cnd = min(abs(A[i] - P), abs(A[i - 1] - P))
if gmax < max_cnd:
gmax = max_cnd
M = P
return M
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
lst = map(int, f.readline().strip().split(" "))
P, Q = map(int, f.readline().strip().split(" "))
cipher = lst, P, Q
s = "%s\n" % (Solution().solve(cipher))
print s,
import math
class Solution(object):
def solve(self, cipher):
L, S1, S2, qs = cipher
v = abs(S1 - S2) / math.sqrt(2)
rets = []
for q in qs:
t = (L - math.sqrt(q)) / v
rets.append(t)
return "\n".join(map(lambda x: "%f" % x, rets))
if __name__ == "__main__":
import sys
f = open("1.in", "r")
solution = Solution()
L, S1, S2 = map(int, f.readline().strip().split(' '))
q = int(f.readline().strip())
qs = []
for t in xrange(q):
qs.append(int(f.readline().strip()))
cipher = L, S1, S2, qs
s = "%s\n" % (solution.solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
hm = {}
cnt = 0
for ind, val in enumerate(cipher):
if val in hm:
cnt += 2 * len(hm[val])
hm[val].append(ind)
else:
hm[val] = [ind]
return cnt
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
N = f.readline().strip()
cipher = map(int, f.readline().strip().split(' '))
s = "%s\n" % (Solution().solve(cipher))
print s,
MOD = 10 ** 9 + 7
import math
class Solution(object):
def solve(self, cipher):
N, M = cipher
return math.factorial(N + M - 1) / math.factorial(N) / math.factorial(M - 1) % MOD
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = map(int, f.readline().strip().split(' '))
s = "%s\n" % (Solution().solve(cipher))
print s,
class Solution(object):
def solve(self, N):
for i in xrange(N / 3 * 3, -1, -3):
if (N - i) % 5 == 0:
return "5" * i + "3" * (N - i)
return "-1"
if __name__ == "__main__":
import sys
f = open("1.in", "r")
solution = Solution()
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = int(f.readline().strip())
s = "%s\n" % (solution.solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
N, K, Q, A, q = cipher
result = []
for i in q:
result.append(A[(i - K) % N])
return "\n".join(map(str, result))
if __name__ == "__main__":
import sys
f = open("1.in", "r")
N, K, Q = map(int, f.readline().strip().split(' '))
A = map(int, f.readline().strip().split(' '))
q = []
for i in xrange(Q):
q.append(int(f.readline().strip()))
cipher = N, K, Q, A, q
s = "%s\n" % (Solution().solve(cipher))
print s,
import gobject
import gtk
import ns.core
import ns.network
import ns.visualizer
from visualizer.base import InformationWindow
from visualizer.higcontainer import HIGContainer
from kiwi.ui.objectlist import ObjectList, Column
class ShowLastPackets(InformationWindow):
class PacketList(gtk.ScrolledWindow):
(
COLUMN_TIME,
COLUMN_INTERFACE,
COLUMN_SIZE,
COLUMN_CONTENTS,
) = range(4)
def __init__(self):
super(ShowLastPackets.PacketList, self).__init__()
self.set_properties(hscrollbar_policy=gtk.POLICY_AUTOMATIC,
vscrollbar_policy=gtk.POLICY_AUTOMATIC)
self.table_model = gtk.ListStore(*([str]*4))
treeview = gtk.TreeView(self.table_model)
treeview.show()
self.add(treeview)
def add_column(descr, colid):
column = gtk.TreeViewColumn(descr, gtk.CellRendererText(), text=colid)
treeview.append_column(column)
add_column("Time", self.COLUMN_TIME)
add_column("Interface", self.COLUMN_INTERFACE)
add_column("Size", self.COLUMN_SIZE)
add_column("Contents", self.COLUMN_CONTENTS)
def update(self, node, packet_list):
self.table_model.clear()
for sample in packet_list:
tree_iter = self.table_model.append()
if sample.device is None:
interface_name = "(unknown)"
else:
interface_name = ns.core.Names.FindName(sample.device)
if not interface_name:
interface_name = "(interface %i)" % sample.device.GetIfIndex()
self.table_model.set(tree_iter,
self.COLUMN_TIME, str(sample.time.GetSeconds()),
self.COLUMN_INTERFACE, interface_name,
self.COLUMN_SIZE, str(sample.packet.GetSize ()),
self.COLUMN_CONTENTS, str(sample.packet)
)
def __init__(self, visualizer, node_index):
InformationWindow.__init__(self)
self.win = gtk.Dialog(parent=visualizer.window,
flags=gtk.DIALOG_DESTROY_WITH_PARENT|gtk.DIALOG_NO_SEPARATOR,
buttons=(gtk.STOCK_CLOSE, gtk.RESPONSE_CLOSE))
self.win.connect("response", self._response_cb)
self.win.set_title("Last packets for node %i" % node_index)
self.visualizer = visualizer
self.viz_node = visualizer.get_node(node_index)
self.node = ns.network.NodeList.GetNode(node_index)
def smart_expand(expander, vbox):
if expander.get_expanded():
vbox.set_child_packing(expander, expand=True, fill=True, padding=0, pack_type=gtk.PACK_START)
else:
vbox.set_child_packing(expander, expand=False, fill=False, padding=0, pack_type=gtk.PACK_START)
main_hbox = gtk.HBox(False, 4)
main_hbox.show()
main_vbox = gtk.VBox(False, 4)
main_vbox.show()
self.win.vbox.add(main_hbox)
main_hbox.add(main_vbox)
self.tx_list = self.PacketList()
self.tx_list.show()
group = gtk.Expander("Last transmitted packets")
group.show()
group.add(self.tx_list)
main_vbox.pack_start(group, expand=False, fill=False)
group.connect_after("activate", smart_expand, main_vbox)
self.rx_list = self.PacketList()
self.rx_list.show()
group = gtk.Expander("Last received packets")
group.show()
group.add(self.rx_list)
main_vbox.pack_start(group, expand=False, fill=False)
group.connect_after("activate", smart_expand, main_vbox)
self.drop_list = self.PacketList()
self.drop_list.show()
group = gtk.Expander("Last dropped packets")
group.show()
group.add(self.drop_list)
main_vbox.pack_start(group, expand=False, fill=False)
group.connect_after("activate", smart_expand, main_vbox)
self.packet_capture_options = ns.visualizer.PyViz.PacketCaptureOptions()
self.packet_capture_options.numLastPackets = 100
packet_filter_vbox = gtk.VBox(False, 4)
packet_filter_vbox.show()
main_hbox.add(packet_filter_vbox)
sel_buttons_box = gtk.HButtonBox()
sel_buttons_box.show()
packet_filter_vbox.pack_start(sel_buttons_box, False, False, 4)
select_all_button = gobject.new(gtk.Button, label="Sel. All", visible=True)
select_none_button = gobject.new(gtk.Button, label="Sel. None", visible=True)
sel_buttons_box.add(select_all_button)
sel_buttons_box.add(select_none_button)
self.packet_filter_widget = ObjectList([
Column('selected', title="Sel.", data_type=bool, editable=True),
Column('name', title="Header"),
], sortable=True)
self.packet_filter_widget.show()
packet_filter_vbox.pack_start(self.packet_filter_widget, True, True, 4)
class TypeIdConfig(object):
__slots__ = ['name', 'selected', 'typeid']
self.packet_filter_list = []
Header = ns.core.TypeId.LookupByName("ns3::Header")
Trailer = ns.core.TypeId.LookupByName("ns3::Trailer")
for typeid_i in range(ns.core.TypeId.GetRegisteredN()):
typeid = ns.core.TypeId.GetRegistered(typeid_i)
typeid_tmp = typeid
type_is_good = False
while 1:
if typeid_tmp == Header or typeid_tmp == Trailer:
type_is_good = True
break
if typeid_tmp.HasParent():
typeid_tmp = typeid_tmp.GetParent()
else:
break
if not type_is_good:
