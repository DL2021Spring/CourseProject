continue
if typeid in [Header, Trailer]:
continue
c = TypeIdConfig()
c.selected = True
c.name = typeid.GetName()
c.typeid = typeid
self.packet_filter_list.append(c)
self.packet_filter_widget.add_list(self.packet_filter_list)
def update_capture_options():
if self.op_AND_button.props.active:
self.packet_capture_options.mode = ns.visualizer.PyViz.PACKET_CAPTURE_FILTER_HEADERS_AND
else:
self.packet_capture_options.mode = ns.visualizer.PyViz.PACKET_CAPTURE_FILTER_HEADERS_OR
self.packet_capture_options.numLastPackets = 100
self.packet_capture_options.headers = [c.typeid for c in self.packet_filter_list if c.selected]
self.visualizer.simulation.lock.acquire()
try:
self.visualizer.simulation.sim_helper.SetPacketCaptureOptions(
self.node.GetId(), self.packet_capture_options)
finally:
self.visualizer.simulation.lock.release()
def sel_all_cb(bt):
for c in self.packet_filter_list:
c.selected = True
self.packet_filter_widget.refresh()
update_capture_options()
def sel_none_cb(bt):
for c in self.packet_filter_list:
c.selected = False
self.packet_filter_widget.refresh()
update_capture_options()
select_all_button.connect("clicked", sel_all_cb)
select_none_button.connect("clicked", sel_none_cb)
op_buttons_box = gtk.HButtonBox()
op_buttons_box.show()
packet_filter_vbox.pack_start(op_buttons_box, False, False, 4)
self.op_AND_button = gobject.new(gtk.RadioButton, label="AND", visible=True)
self.op_OR_button = gobject.new(gtk.RadioButton, label="OR", visible=True, group=self.op_AND_button)
op_buttons_box.add(self.op_AND_button)
op_buttons_box.add(self.op_OR_button)
self.op_OR_button.props.active = True
self.op_AND_button.connect("toggled", lambda b: update_capture_options())
def cell_edited(l, obj, attribute):
update_capture_options()
self.packet_filter_widget.connect("cell-edited", cell_edited)
update_capture_options()
self.visualizer.add_information_window(self)
self.win.set_default_size(600, 300)
self.win.show()
def _response_cb(self, win, response):
self.win.destroy()
self.visualizer.remove_information_window(self)
def update(self):
last_packets = self.visualizer.simulation.sim_helper.GetLastPackets(self.node.GetId())
self.tx_list.update(self.node, last_packets.lastTransmittedPackets)
self.rx_list.update(self.node, last_packets.lastReceivedPackets)
self.drop_list.update(self.node, last_packets.lastDroppedPackets)
def populate_node_menu(viz, node, menu):
menu_item = gtk.MenuItem("Show Last Packets")
menu_item.show()
def _show_it(dummy_menu_item):
ShowLastPackets(viz, node.node_index)
menu_item.connect("activate", _show_it)
menu.add(menu_item)
def register(viz):
viz.connect("populate-node-menu", populate_node_menu)
import ns.applications
import ns.core
import ns.csma
import ns.internet
import ns.network
def main(argv):
cmd = ns.core.CommandLine();
cmd.Parse(argv);
print "Create nodes"
n0 = ns.network.Node();
r = ns.network.Node();
n1 = ns.network.Node();
net1 = ns.network.NodeContainer();
net1.Add(n0);
net1.Add(r);
net2 = ns.network.NodeContainer();
net2.Add(r);
net2.Add(n1);
all = ns.network.NodeContainer();
all.Add(n0);
all.Add(r);
all.Add(n1);
internetv6 = ns.internet.InternetStackHelper();
internetv6.Install(all);
csma = ns.csma.CsmaHelper();
csma.SetChannelAttribute("DataRate", ns.network.DataRateValue(ns.network.DataRate(5000000)));
csma.SetChannelAttribute("Delay", ns.core.TimeValue(ns.core.MilliSeconds(2)));
d1 = csma.Install(net1);
d2 = csma.Install(net2);
print "Addressing"
ipv6 = ns.internet.Ipv6AddressHelper();
ipv6.NewNetwork(ns.network.Ipv6Address("2001:1::"), ns.network.Ipv6Prefix(64));
i1 = ipv6.Assign(d1);
i1.SetRouter(1, True);
ipv6.NewNetwork(ns.network.Ipv6Address("2001:2::"), ns.network.Ipv6Prefix(64));
i2 = ipv6.Assign(d2);
i2.SetRouter(0, True);
print "Application"
packetSize = 1024;
maxPacketCount = 5;
interPacketInterval = ns.core.Seconds(1.);
ping6 = ns.applications.Ping6Helper();
ping6.SetLocal(i1.GetAddress(0, 1));
ping6.SetRemote(i2.GetAddress(1, 1));
ping6.SetAttribute("MaxPackets", ns.core.UintegerValue(maxPacketCount));
ping6.SetAttribute("Interval", ns.core.TimeValue(interPacketInterval));
ping6.SetAttribute("PacketSize", ns.core.UintegerValue(packetSize));
apps = ping6.Install(ns.network.NodeContainer(net1.Get(0)));
apps.Start(ns.core.Seconds(2.0));
apps.Stop(ns.core.Seconds(20.0));
print "Tracing"
ascii = ns.network.AsciiTraceHelper()
csma.EnableAsciiAll(ascii.CreateFileStream("simple-routing-ping6.tr"))
csma.EnablePcapAll("simple-routing-ping6", True)
ns.core.Simulator.Run()
ns.core.Simulator.Destroy()
if __name__ == '__main__':
import sys
main(sys.argv)
import sys, os
sys.path.append("../..")
from facerec.feature import Fisherfaces, SpatialHistogram, Identity
from facerec.distance import EuclideanDistance, ChiSquareDistance
from facerec.classifier import NearestNeighbor
from facerec.model import PredictableModel
from facerec.validation import KFoldCrossValidation
from facerec.visual import subplot
from facerec.util import minmax_normalize
from facerec.serialization import save_model, load_model
import numpy as np
try:
from PIL import Image
except ImportError:
import Image
import matplotlib.cm as cm
import logging
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from facerec.lbp import LPQ, ExtendedLBP
def read_images(path, sz=None):
c = 0
X,y = [], []
for dirname, dirnames, filenames in os.walk(path):
for subdirname in dirnames:
subject_path = os.path.join(dirname, subdirname)
for filename in os.listdir(subject_path):
try:
im = Image.open(os.path.join(subject_path, filename))
im = im.convert("L")
if (sz is not None):
im = im.resize(self.sz, Image.ANTIALIAS)
X.append(np.asarray(im, dtype=np.uint8))
y.append(c)
except IOError, (errno, strerror):
print "I/O error({0}): {1}".format(errno, strerror)
except:
print "Unexpected error:", sys.exc_info()[0]
raise
c = c+1
return [X,y]
if __name__ == "__main__":
out_dir = None
if len(sys.argv) < 2:
print "USAGE: facerec_demo.py </path/to/images>"
sys.exit()
[X,y] = read_images(sys.argv[1])
handler = logging.StreamHandler(sys.stdout)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger = logging.getLogger("facerec")
logger.addHandler(handler)
logger.setLevel(logging.DEBUG)
feature = Fisherfaces()
classifier = NearestNeighbor(dist_metric=EuclideanDistance(), k=1)
my_model = PredictableModel(feature=feature, classifier=classifier)
my_model.compute(X, y)
save_model('model.pkl', my_model)
model = load_model('model.pkl')
E = []
for i in xrange(min(model.feature.eigenvectors.shape[1], 16)):
e = model.feature.eigenvectors[:,i].reshape(X[0].shape)
E.append(minmax_normalize(e,0,255, dtype=np.uint8))
subplot(title="Fisherfaces", images=E, rows=4, cols=4, sptitle="Fisherface", colormap=cm.jet, filename="fisherfaces.png")
cv = KFoldCrossValidation(model, k=10)
cv.validate(X, y)
cv.print_results()
import logging
import cv2
from helper.common import *
from helper.video import *
import sys
sys.path.append("../..")
from facerec.model import PredictableModel
from facerec.feature import Fisherfaces
from facerec.distance import EuclideanDistance
from facerec.classifier import NearestNeighbor
from facerec.validation import KFoldCrossValidation
from facerec.serialization import save_model, load_model
from facedet.detector import CascadedDetector
class ExtendedPredictableModel(PredictableModel):
def __init__(self, feature, classifier, image_size, subject_names):
PredictableModel.__init__(self, feature=feature, classifier=classifier)
self.image_size = image_size
self.subject_names = subject_names
def get_model(image_size, subject_names):
feature = Fisherfaces()
classifier = NearestNeighbor(dist_metric=EuclideanDistance(), k=1)
return ExtendedPredictableModel(feature=feature, classifier=classifier, image_size=image_size, subject_names=subject_names)
def read_subject_names(path):
folder_names = []
for dirname, dirnames, filenames in os.walk(path):
for subdirname in dirnames:
folder_names.append(subdirname)
return folder_names
def read_images(path, image_size=None):
c = 0
X = []
y = []
folder_names = []
for dirname, dirnames, filenames in os.walk(path):
for subdirname in dirnames:
folder_names.append(subdirname)
subject_path = os.path.join(dirname, subdirname)
for filename in os.listdir(subject_path):
try:
im = cv2.imread(os.path.join(subject_path, filename), cv2.IMREAD_GRAYSCALE)
if (image_size is not None):
im = cv2.resize(im, image_size)
X.append(np.asarray(im, dtype=np.uint8))
y.append(c)
except IOError, (errno, strerror):
print "I/O error({0}): {1}".format(errno, strerror)
except:
print "Unexpected error:", sys.exc_info()[0]
raise
c = c+1
return [X,y,folder_names]
class App(object):
def __init__(self, model, camera_id, cascade_filename):
self.model = model
self.detector = CascadedDetector(cascade_fn=cascade_filename, minNeighbors=5, scaleFactor=1.1)
self.cam = create_capture(camera_id)
def run(self):
while True:
ret, frame = self.cam.read()
img = cv2.resize(frame, (frame.shape[1]/2, frame.shape[0]/2), interpolation = cv2.INTER_CUBIC)
imgout = img.copy()
for i,r in enumerate(self.detector.detect(img)):
x0,y0,x1,y1 = r
face = img[y0:y1, x0:x1]
face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)
face = cv2.resize(face, self.model.image_size, interpolation = cv2.INTER_CUBIC)
prediction = self.model.predict(face)[0]
cv2.rectangle(imgout, (x0,y0),(x1,y1),(0,255,0),2)
draw_str(imgout, (x0-20,y0-20), self.model.subject_names[prediction])
cv2.imshow('videofacerec', imgout)
ch = cv2.waitKey(10)
if ch == 27:
break
if __name__ == '__main__':
from optparse import OptionParser
usage = "usage: %prog [options] model_filename"
parser = OptionParser(usage=usage)
parser.add_option("-r", "--resize", action="store", type="string", dest="size", default="100x100",
help="Resizes the given dataset to a given size in format [width]x[height] (default: 100x100).")
parser.add_option("-v", "--validate", action="store", dest="numfolds", type="int", default=None,
help="Performs a k-fold cross validation on the dataset, if given (default: None).")
parser.add_option("-t", "--train", action="store", dest="dataset", type="string", default=None,
help="Trains the model on the given dataset.")
parser.add_option("-i", "--id", action="store", dest="camera_id", type="int", default=0,
help="Sets the Camera Id to be used (default: 0).")
parser.add_option("-c", "--cascade", action="store", dest="cascade_filename", default="haarcascade_frontalface_alt2.xml",
help="Sets the path to the Haar Cascade used for the face detection part (default: haarcascade_frontalface_alt2.xml).")
parser.print_help()
print "Press [ESC] to exit the program!"
print "Script output:"
(options, args) = parser.parse_args()
if len(args) == 0:
print "[Error] No prediction model was given."
sys.exit()
model_filename = args[0]
if (options.dataset is None) and (not os.path.exists(model_filename)):
print "[Error] No prediction model found at '%s'." % model_filename
sys.exit()
if not os.path.exists(options.cascade_filename):
print "[Error] No Cascade File found at '%s'." % options.cascade_filename
sys.exit()
try:
image_size = (int(options.size.split("x")[0]), int(options.size.split("x")[1]))
except:
print "[Error] Unable to parse the given image size '%s'. Please pass it in the format [width]x[height]!" % options.size
sys.exit()
if options.dataset:
if not os.path.exists(options.dataset):
print "[Error] No dataset found at '%s'." % dataset_path
sys.exit()
print "Loading dataset..."
[images, labels, subject_names] = read_images(options.dataset, image_size)
list_of_labels = list(xrange(max(labels)+1))
subject_dictionary = dict(zip(list_of_labels, subject_names))
model = get_model(image_size=image_size, subject_names=subject_dictionary)
if options.numfolds:
print "Validating model with %s folds..." % options.numfolds
handler = logging.StreamHandler(sys.stdout)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger = logging.getLogger("facerec")
logger.addHandler(handler)
logger.setLevel(logging.DEBUG)
crossval = KFoldCrossValidation(model, k=options.numfolds)
crossval.validate(images, labels)
crossval.print_results()
print "Computing the model..."
model.compute(images, labels)
print "Saving the model..."
save_model(model_filename, model)
else:
print "Loading the model..."
model = load_model(model_filename)
if not isinstance(model, ExtendedPredictableModel):
print "[Error] The given model is not of type '%s'." % "ExtendedPredictableModel"
sys.exit()
print "Starting application..."
App(model=model,
camera_id=options.camera_id,
cascade_filename=options.cascade_filename).run()
class Solution:
def singleNumberIII(self, A):
bits = 0
for a in A:
bits ^= a
rightmost_set_bit = bits&-bits
bits1 = 0
bits2 = 0
for a in A:
if a&rightmost_set_bit:
bits1 ^= a
else:
bits2 ^= a
return bits1, bits2
import threading
class SingletonMixin(object):
__singleton_lock = threading.Lock()
__singleton_instance = None
@classmethod
def instance(cls):
if not cls.__singleton_instance:
with cls.__singleton_lock:
if not cls.__singleton_instance:
cls.__singleton_instance = cls()
return cls.__singleton_instance
import operator
import sys
import types
__version__ = "1.2.0"
PY3 = sys.version_info[0] == 3
if PY3:
string_types = str,
integer_types = int,
class_types = type,
text_type = str
binary_type = bytes
MAXSIZE = sys.maxsize
else:
string_types = basestring,
integer_types = (int, long)
class_types = (type, types.ClassType)
text_type = unicode
binary_type = str
if sys.platform.startswith("java"):
MAXSIZE = int((1 << 31) - 1)
else:
class X(object):
def __len__(self):
return 1 << 31
try:
len(X())
except OverflowError:
MAXSIZE = int((1 << 31) - 1)
else:
MAXSIZE = int((1 << 63) - 1)
del X
def _add_doc(func, doc):
func.__doc__ = doc
def _import_module(name):
__import__(name)
return sys.modules[name]
class _LazyDescr(object):
def __init__(self, name):
self.name = name
def __get__(self, obj, tp):
result = self._resolve()
setattr(obj, self.name, result)
delattr(tp, self.name)
return result
class MovedModule(_LazyDescr):
def __init__(self, name, old, new=None):
super(MovedModule, self).__init__(name)
if PY3:
if new is None:
new = name
self.mod = new
else:
self.mod = old
def _resolve(self):
return _import_module(self.mod)
class MovedAttribute(_LazyDescr):
def __init__(self, name, old_mod, new_mod, old_attr=None, new_attr=None):
super(MovedAttribute, self).__init__(name)
if PY3:
if new_mod is None:
new_mod = name
self.mod = new_mod
if new_attr is None:
if old_attr is None:
new_attr = name
else:
new_attr = old_attr
self.attr = new_attr
else:
self.mod = old_mod
if old_attr is None:
old_attr = name
self.attr = old_attr
def _resolve(self):
module = _import_module(self.mod)
return getattr(module, self.attr)
class _MovedItems(types.ModuleType):
_moved_attributes = [
MovedAttribute("cStringIO", "cStringIO", "io", "StringIO"),
MovedAttribute("filter", "itertools", "builtins", "ifilter", "filter"),
MovedAttribute("input", "__builtin__", "builtins", "raw_input", "input"),
MovedAttribute("map", "itertools", "builtins", "imap", "map"),
MovedAttribute("reload_module", "__builtin__", "imp", "reload"),
MovedAttribute("reduce", "__builtin__", "functools"),
MovedAttribute("StringIO", "StringIO", "io"),
MovedAttribute("xrange", "__builtin__", "builtins", "xrange", "range"),
MovedAttribute("zip", "itertools", "builtins", "izip", "zip"),
MovedModule("builtins", "__builtin__"),
MovedModule("configparser", "ConfigParser"),
MovedModule("copyreg", "copy_reg"),
MovedModule("http_cookiejar", "cookielib", "http.cookiejar"),
MovedModule("http_cookies", "Cookie", "http.cookies"),
MovedModule("html_entities", "htmlentitydefs", "html.entities"),
MovedModule("html_parser", "HTMLParser", "html.parser"),
MovedModule("http_client", "httplib", "http.client"),
MovedModule("BaseHTTPServer", "BaseHTTPServer", "http.server"),
MovedModule("CGIHTTPServer", "CGIHTTPServer", "http.server"),
MovedModule("SimpleHTTPServer", "SimpleHTTPServer", "http.server"),
MovedModule("cPickle", "cPickle", "pickle"),
MovedModule("queue", "Queue"),
MovedModule("reprlib", "repr"),
MovedModule("socketserver", "SocketServer"),
MovedModule("tkinter", "Tkinter"),
MovedModule("tkinter_dialog", "Dialog", "tkinter.dialog"),
MovedModule("tkinter_filedialog", "FileDialog", "tkinter.filedialog"),
MovedModule("tkinter_scrolledtext", "ScrolledText", "tkinter.scrolledtext"),
MovedModule("tkinter_simpledialog", "SimpleDialog", "tkinter.simpledialog"),
MovedModule("tkinter_tix", "Tix", "tkinter.tix"),
MovedModule("tkinter_constants", "Tkconstants", "tkinter.constants"),
MovedModule("tkinter_dnd", "Tkdnd", "tkinter.dnd"),
MovedModule("tkinter_colorchooser", "tkColorChooser",
"tkinter.colorchooser"),
MovedModule("tkinter_commondialog", "tkCommonDialog",
"tkinter.commondialog"),
MovedModule("tkinter_tkfiledialog", "tkFileDialog", "tkinter.filedialog"),
MovedModule("tkinter_font", "tkFont", "tkinter.font"),
MovedModule("tkinter_messagebox", "tkMessageBox", "tkinter.messagebox"),
MovedModule("tkinter_tksimpledialog", "tkSimpleDialog",
"tkinter.simpledialog"),
MovedModule("urllib_robotparser", "robotparser", "urllib.robotparser"),
MovedModule("winreg", "_winreg"),
]
for attr in _moved_attributes:
setattr(_MovedItems, attr.name, attr)
del attr
moves = sys.modules[__name__ + ".moves"] = _MovedItems("moves")
def add_move(move):
setattr(_MovedItems, move.name, move)
def remove_move(name):
try:
delattr(_MovedItems, name)
except AttributeError:
try:
del moves.__dict__[name]
except KeyError:
raise AttributeError("no such move, %r" % (name,))
if PY3:
_meth_func = "__func__"
_meth_self = "__self__"
_func_code = "__code__"
_func_defaults = "__defaults__"
_iterkeys = "keys"
_itervalues = "values"
_iteritems = "items"
else:
_meth_func = "im_func"
_meth_self = "im_self"
_func_code = "func_code"
_func_defaults = "func_defaults"
_iterkeys = "iterkeys"
_itervalues = "itervalues"
_iteritems = "iteritems"
try:
advance_iterator = next
except NameError:
def advance_iterator(it):
return it.next()
next = advance_iterator
if PY3:
def get_unbound_function(unbound):
return unbound
Iterator = object
def callable(obj):
return any("__call__" in klass.__dict__ for klass in type(obj).__mro__)
else:
def get_unbound_function(unbound):
return unbound.im_func
class Iterator(object):
def next(self):
return type(self).__next__(self)
callable = callable
_add_doc(get_unbound_function,
)
get_method_function = operator.attrgetter(_meth_func)
get_method_self = operator.attrgetter(_meth_self)
get_function_code = operator.attrgetter(_func_code)
get_function_defaults = operator.attrgetter(_func_defaults)
def iterkeys(d):
return iter(getattr(d, _iterkeys)())
def itervalues(d):
return iter(getattr(d, _itervalues)())
def iteritems(d):
return iter(getattr(d, _iteritems)())
if PY3:
def b(s):
return s.encode("latin-1")
def u(s):
return s
if sys.version_info[1] <= 1:
def int2byte(i):
return bytes((i,))
else:
int2byte = operator.methodcaller("to_bytes", 1, "big")
import io
StringIO = io.StringIO
BytesIO = io.BytesIO
else:
def b(s):
return s
def u(s):
return unicode(s, "unicode_escape")
int2byte = chr
import StringIO
StringIO = BytesIO = StringIO.StringIO
_add_doc(b, )
_add_doc(u, )
if PY3:
import builtins
exec_ = getattr(builtins, "exec")
def reraise(tp, value, tb=None):
if value.__traceback__ is not tb:
raise value.with_traceback(tb)
raise value
print_ = getattr(builtins, "print")
del builtins
else:
def exec_(code, globs=None, locs=None):
if globs is None:
frame = sys._getframe(1)
globs = frame.f_globals
if locs is None:
locs = frame.f_locals
del frame
elif locs is None:
locs = globs
exec()
exec_()
def print_(*args, **kwargs):
fp = kwargs.pop("file", sys.stdout)
if fp is None:
return
def write(data):
if not isinstance(data, basestring):
data = str(data)
fp.write(data)
want_unicode = False
sep = kwargs.pop("sep", None)
if sep is not None:
if isinstance(sep, unicode):
want_unicode = True
elif not isinstance(sep, str):
raise TypeError("sep must be None or a string")
end = kwargs.pop("end", None)
if end is not None:
if isinstance(end, unicode):
want_unicode = True
elif not isinstance(end, str):
raise TypeError("end must be None or a string")
if kwargs:
raise TypeError("invalid keyword arguments to print()")
if not want_unicode:
for arg in args:
if isinstance(arg, unicode):
want_unicode = True
break
if want_unicode:
newline = unicode("\n")
space = unicode(" ")
else:
newline = "\n"
space = " "
if sep is None:
sep = space
if end is None:
end = newline
for i, arg in enumerate(args):
if i:
write(sep)
write(arg)
write(end)
_add_doc(reraise, )
def with_metaclass(meta, base=object):
return meta("NewBase", (base,), {})
import sys
from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import SJISDistributionAnalysis
from .jpcntx import SJISContextAnalysis
from .mbcssm import SJISSMModel
from . import constants
class SJISProber(MultiByteCharSetProber):
def __init__(self):
MultiByteCharSetProber.__init__(self)
self._mCodingSM = CodingStateMachine(SJISSMModel)
self._mDistributionAnalyzer = SJISDistributionAnalysis()
self._mContextAnalyzer = SJISContextAnalysis()
self.reset()
def reset(self):
MultiByteCharSetProber.reset(self)
self._mContextAnalyzer.reset()
def get_charset_name(self):
return "SHIFT_JIS"
def feed(self, aBuf):
aLen = len(aBuf)
for i in range(0, aLen):
codingState = self._mCodingSM.next_state(aBuf[i])
if codingState == constants.eError:
if constants._debug:
sys.stderr.write(self.get_charset_name()
+ ' prober hit error at byte ' + str(i)
+ '\n')
self._mState = constants.eNotMe
break
elif codingState == constants.eItsMe:
self._mState = constants.eFoundIt
break
elif codingState == constants.eStart:
charLen = self._mCodingSM.get_current_charlen()
if i == 0:
self._mLastChar[1] = aBuf[0]
self._mContextAnalyzer.feed(self._mLastChar[2 - charLen:],
charLen)
self._mDistributionAnalyzer.feed(self._mLastChar, charLen)
else:
self._mContextAnalyzer.feed(aBuf[i + 1 - charLen:i + 3
- charLen], charLen)
self._mDistributionAnalyzer.feed(aBuf[i - 1:i + 1],
charLen)
self._mLastChar[0] = aBuf[aLen - 1]
if self.get_state() == constants.eDetecting:
if (self._mContextAnalyzer.got_enough_data() and
(self.get_confidence() > constants.SHORTCUT_THRESHOLD)):
self._mState = constants.eFoundIt
return self.get_state()
def get_confidence(self):
contxtCf = self._mContextAnalyzer.get_confidence()
distribCf = self._mDistributionAnalyzer.get_confidence()
return max(contxtCf, distribCf)
class Solution:
def maxSlidingWindow(self, nums, k):
if not nums or k == 0:
return []
q = []
ret = []
for i in xrange(k):
while q and nums[i] >= nums[q[-1]]:
q.pop()
q.append(i)
ret.append(nums[q[0]])
for i in xrange(k, len(nums)):
while q and nums[i] >= nums[q[-1]]:
q.pop()
while q and q[0] < i-k+1:
q.pop(0)
q.append(i)
ret.append(nums[q[0]])
return ret
if __name__ == "__main__":
print Solution().maxSlidingWindow([1, 2, 7, 7, 8], 3)
from collections import defaultdict
class Heap(object):
def __init__(self, A):
self._A = A
self._h = []
self._pos = defaultdict(set)
def _pos2pos_set(self, ind):
return self._pos[self._A[self._h[ind]]]
def _swap_heap_node(self, i, j):
if self._cmp_by_pos(i, j) == 0:
return
self._pos2pos_set(i).remove(i)
self._pos2pos_set(j).remove(j)
self._pos2pos_set(i).add(j)
self._pos2pos_set(j).add(i)
self._h[i], self._h[j] = self._h[j], self._h[i]
def _pi(self, pos):
if pos%2 == 0:
return max(0, pos/2-1)
else:
return pos/2
def push(self, i):
pos = len(self._h)
self._h.append(i)
self._pos[self._A[i]].add(pos)
pi = self._pi(pos)
while pi != pos and self._cmp_by_pos(pos, pi) < 0:
self._swap_heap_node(pi, pos)
pos = pi
pi = self._pi(pos)
def _val2pos(self, val):
return next(iter(self._pos[val]))
def _pos2val(self, pos):
return self._A[self._h[pos]]
def _cmp_by_pos(self, i, j):
return self._pos2val(i) - self._pos2val(j)
def remove(self, i):
try:
pos = self._val2pos(self._A[i])
self.pop(pos)
except StopIteration:
pass
def _heappush(self, pos):
n = len(self._h)
if pos >= n:
return
l = 2*pos+1
r = 2*pos+2
mini = pos
if l < n and self._cmp_by_pos(l, mini) < 0:
mini = l
if r < n and self._cmp_by_pos(r, mini) < 0:
mini = r
if pos != mini:
self._swap_heap_node(pos, mini)
self._heappush(mini)
def peek(self):
return self._h[0]
def pop(self, pos=0):
last_pos = len(self._h)-1
self._swap_heap_node(pos, last_pos)
self._pos2pos_set(last_pos).remove(last_pos)
head = self._h.pop()
self._heappush(pos)
return head
def __len__(self):
return len(self._h)
def __repr__(self):
return repr(map(lambda x: self._A[x], self._h))
class DualHeap(object):
def __init__(self, A):
self._A = A
self.min_h = Heap(A)
self.max_h = Heap(map(lambda x: -x, A))
def _rebalance(self):
r = len(self.min_h)
l = len(self.max_h)
if abs(l-r) <= 1:
return
if r > l:
self.max_h.push(self.min_h.pop())
else:
self.min_h.push(self.max_h.pop())
self._rebalance()
def add(self, i):
if len(self.min_h) > 0 and self._A[i] > self._A[self.min_h.peek()]:
self.min_h.push(i)
else:
self.max_h.push(i)
self._rebalance()
def remove(self, i):
if len(self.min_h) > 0 and self._A[i] >= self._A[self.min_h.peek()]:
self.min_h.remove(i)
else:
self.max_h.remove(i)
self._rebalance()
def median(self):
r = len(self.min_h)
l = len(self.max_h)
if r > l:
return self._A[self.min_h.peek()]
else:
return self._A[self.max_h.peek()]
def __repr__(self):
return repr(self.max_h)+repr(self.min_h)
class Solution:
def medianSlidingWindow(self, nums, k):
if len(nums) < 1:
return []
ret = []
dh = DualHeap(nums)
for i in xrange(k):
dh.add(i)
ret.append(dh.median())
for i in xrange(k, len(nums)):
dh.remove(i-k)
dh.add(i)
ret.append(dh.median())
return ret
if __name__ == "__main__":
assert Solution().medianSlidingWindow([1, 1, 1, 1], 3) == [1, 1]
assert Solution().medianSlidingWindow([1, 2, 7, 8, 5], 3) == [2, 7, 7]
class PriorityQueue(object):
def __init__(self):
self.lst = []
def bisect(self, t):
l = 0
h = len(self.lst)
while l < h:
m = (l+h)/2
if self.lst[m] < t:
l = m+1
else:
h = m
return l
def insert(self, t):
pos = self.bisect(t)
self.lst.insert(pos, t)
def remove(self, t):
pos = self.bisect(t)
if self.lst[pos] != t:
raise ValueError("%s not found in the queue"%str(t))
del self.lst[pos]
def __getitem__(self, item):
return self.lst[item]
import heapq
from collections import defaultdict
class Heap(object):
def __init__(self):
self.h = []
self.existing = defaultdict(int)
self.len = 0
def push(self, t):
heapq.heappush(self.h, t)
self.existing[t] += 1
self.len += 1
def pop(self):
while True:
a = heapq.heappop(self.h)
if self.existing[a] == 0:
continue
else:
self.remove(a)
return a
def remove(self, t):
if self.existing[t] < 1:
raise ValueError("%s does not exist in the heap"%str(t))
self.existing[t] -= 1
self.len -= 1
def __len__(self):
return self.len
def peek(self):
a = self.h[0]
if self.existing[a] > 0:
return a
a = self.pop()
self.push(a)
return a
def __repr__(self):
return repr(self.existing)
class DualHeap(object):
def __init__(self):
self.min_h = Heap()
self.max_h = Heap()
def _rebalance(self):
r = len(self.min_h)
l = len(self.max_h)
if abs(l-r) <= 1:
return
if r > l:
self.max_h.push(-self.min_h.pop())
else:
self.min_h.push(-self.max_h.pop())
self._rebalance()
def add(self, t):
if len(self.min_h) > 0 and t > self.min_h.peek():
self.min_h.push(t)
else:
self.max_h.push(-t)
self._rebalance()
def remove(self, t):
if len(self.min_h) > 0 and t >= self.min_h.peek():
self.min_h.remove(t)
else:
self.max_h.remove(-t)
self._rebalance()
def median(self):
r = len(self.min_h)
l = len(self.max_h)
if r > l:
return self.min_h.peek()
else:
return -self.max_h.peek()
def __repr__(self):
return repr(self.max_h)+repr(self.min_h)
class Solution:
def medianSlidingWindow(self, nums, k):
if len(nums) < 1:
return []
ret = []
dh = DualHeap()
for i in xrange(k):
dh.add(nums[i])
ret.append(dh.median())
for i in xrange(k, len(nums)):
dh.remove(nums[i-k])
dh.add(nums[i])
ret.append(dh.median())
return ret
def medianSlidingWindow_TLE(self, nums, k):
if len(nums) < 1:
return []
pq = PriorityQueue()
for i in xrange(k):
pq.insert(nums[i])
ret = []
mid = k/2
if k%2 == 0:
mid -= 1
ret.append(pq[mid])
for i in xrange(k, len(nums)):
pq.remove(nums[i-k])
pq.insert(nums[i])
ret.append(pq[mid])
return ret
if __name__ == "__main__":
assert Solution().medianSlidingWindow([1, 2, 7, 8, 5], 3) == [2, 7, 7]
import heapq
from collections import defaultdict
class Value(object):
def __init__(self, val):
self.val = val
self.deleted = False
def __neg__(self):
self.val = -self.val
return self
def __cmp__(self, other):
assert isinstance(other, Value)
return self.val - other.val
def __repr__(self):
return repr(self.val)
class Heap(object):
def __init__(self):
self.h = []
self.len = 0
def push(self, t):
heapq.heappush(self.h, t)
self.len += 1
def pop(self):
self._clean_top()
self.len -= 1
return heapq.heappop(self.h)
def remove(self, t):
t.deleted = True
self.len -= 1
def __len__(self):
return self.len
def _clean_top(self):
while self.h and self.h[0].deleted:
heapq.heappop(self.h)
def peek(self):
self._clean_top()
return self.h[0]
def __repr__(self):
return repr(self.h)
class DualHeap(object):
def __init__(self):
self.min_h = Heap()
self.max_h = Heap()
def _rebalance(self):
r = len(self.min_h)
l = len(self.max_h)
if abs(l-r) <= 1:
return
if r > l:
self.max_h.push(-self.min_h.pop())
else:
self.min_h.push(-self.max_h.pop())
self._rebalance()
def add(self, t):
if len(self.min_h) > 0 and t > self.min_h.peek():
self.min_h.push(t)
else:
self.max_h.push(-t)
self._rebalance()
def remove(self, t):
if len(self.min_h) > 0 and t >= self.min_h.peek():
self.min_h.remove(t)
else:
self.max_h.remove(t)
self._rebalance()
def median(self):
r = len(self.min_h)
l = len(self.max_h)
if r > l:
return self.min_h.peek().val
else:
return -self.max_h.peek().val
def __repr__(self):
return repr(self.max_h)+repr(self.min_h)
class Solution:
def medianSlidingWindow(self, nums, k):
nums = map(lambda x: Value(x), nums)
if len(nums) < 1:
return []
ret = []
dh = DualHeap()
for i in xrange(k):
dh.add(nums[i])
ret.append(dh.median())
for i in xrange(k, len(nums)):
dh.remove(nums[i-k])
dh.add(nums[i])
ret.append(dh.median())
return ret
if __name__ == "__main__":
assert Solution().medianSlidingWindow([1, 2, 7, 7, 2], 3) == [2, 7, 7]
assert Solution().medianSlidingWindow([1, 2, 7, 8, 5], 3) == [2, 7, 7]
class Solution:
def sortLetters(self, chars):
closed = -1
for ind, val in enumerate(chars):
if ord(val) < ord('a'):
continue
else:
closed += 1
chars[ind], chars[closed] = chars[closed], chars[ind]
if __name__ == "__main__":
chars = list("abAcD")
Solution().sortLetters(chars)
assert "".join(chars) == "abcAD
import random
class PartialQuickSort(object):
def partial_qsort(self, A, i, j, m):
if i >= j: return
p = self.pivot(A, i, j)
self.partial_qsort(A, i, p, m)
if p+1 >= m: return
self.partial_qsort(A, p+1, j, m)
def pivot(self, A, i, j):
p = i
closed = p
for ptr in xrange(i, j):
if A[ptr] < A[p]:
closed += 1
A[ptr], A[closed] = A[closed], A[ptr]
A[closed], A[p] = A[p], A[closed]
return closed
@staticmethod
def test():
A = [4, 5, 3, 2, 1, 6, 7]
sorter = PartialQuickSort()
m = 3
sorter.partial_qsort(A, 0, len(A), m)
try:
assert A[:m] == range(1, m+1)
except AssertionError as e:
print A[:m]
raise e
class MergeSort(object):
def merge_sort(self, A):
n = len(A)
l = 1
while l <= n:
for i in range(0, n, l*2):
lo, hi = i, min(n, i+2*l)
mid = i + l
p, q = lo, mid
while p < mid and q < hi:
if A[p] < A[q]:
p += 1
else:
tmp = A[q]
A[p+1: q+1] = A[p:q]
A[p] = tmp
p, mid, q = p+1, mid+1, q+1
l *= 2
return A
@staticmethod
def test():
sorter = MergeSort()
assert sorter.merge_sort([4, 3, 2, 1]) == [1, 2, 3, 4]
assert sorter.merge_sort([4, 2, 3, 1]) == [1, 2, 3, 4]
assert sorter.merge_sort([4, 5, 3, 2, 1]) == [1, 2, 3, 4, 5]
for _ in range(100):
tmp = range(100)
random.shuffle(tmp)
assert sorter.merge_sort(tmp) == range(100)
return 'test pass!'
class MergeSorter2(object):
def merge_sort(self, A):
if len(A) <= 1:
return
mid = len(A)/2
L, R = A[:mid], A[mid:]
self.merge_sort(L)
self.merge_sort(R)
i, j, k = 0, 0, 0
while i < len(L) and j < len(R):
if L[i] < R[j]:
A[k] = L[i]
i += 1
else:
A[k] = R[j]
j += 1
k += 1
if i < len(L):
A[k:] = L[i:]
if j < len(R):
A[k:] = R[j:]
@staticmethod
def test():
sorter = MergeSorter2()
A = [4, 3, 2, 1]
sorter.merge_sort(A)
assert A == [1, 2, 3, 4]
for _ in range(100):
tmp = range(100)
random.shuffle(tmp)
sorter.merge_sort(tmp)
assert tmp == range(100)
return 'test pass!'
if __name__ == "__main__":
PartialQuickSort.test()
MergeSort.test()
MergeSorter2.test()
class Solution:
def replaceBlank(self, string, length):
i = 0
while i < length:
if string[i] == " ":
string.append("")
string.append("")
length += 2
for j in xrange(length-1, i, -1):
string[j] = string[j-2]
string[i:i+3] = list("%20")
i += 2
i += 1
return length
if __name__ == "__main__":
assert Solution().replaceBlank(list("Mr John Smith"), 13) == 17
class Solution(object):
def solve(self, cipher):
N = cipher
x = 1
while True:
binary = bin(x)[2:]
nine_ary = str(binary).replace("1", "9")
dec = int(nine_ary)
if dec % N == 0:
return dec
x += 1
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = int(f.readline().strip())
s = "%s\n" % (Solution().solve(cipher))
print s,
class AllNerestSmallerValues(object):
def allNearestSmaller(self, A):
P = [-1 for _ in A]
stk = []
for i, v in enumerate(A):
while stk and A[stk[-1]] >= v: stk.pop()
if stk:
P[i] = stk[-1]
else:
P[i] = -1
stk.append(i)
return P
@staticmethod
def test():
A = [0, 8, 4, 12, 2, 10, 6, 14, 1, 9, 5, 13, 3, 11, 7, 15]
solution = AllNerestSmallerValues()
P = solution.allNearestSmaller(A)
expected = [None, 0, 0, 4, 0, 2, 2, 6, 0, 1, 1, 5, 1, 3, 3, 7]
for i, v in enumerate(P):
if P[i] == -1:
assert expected[i] is None
else:
assert expected[i] == A[P[i]]
if __name__ == "__main__":
AllNerestSmallerValues.test()
import sys
import os
from posixpath import normpath
from urllib import unquote
from cgi import FieldStorage
from BaseHTTPServer import HTTPServer
from SimpleHTTPServer import SimpleHTTPRequestHandler
from SocketServer import ForkingMixIn
import socket
sys.path.append(os.path.join(os.path.dirname(__file__), 'server/src'))
from server import serve
import annlog
import annotation
import annotator
import auth
import common
import delete
import dispatch
import docimport
import document
import download
import filelock
import gtbtokenize
import jsonwrap
import message
import normdb
import norm
import predict
import projectconfig
import realmessage
import sdistance
import search
import server
import session
import simstringdb
import sosmessage
import ssplit
import sspostproc
import stats
import svg
import tag
import tokenise
import undo
import verify_annotations
_VERBOSE_HANDLER = False
_DEFAULT_SERVER_ADDR = ''
_DEFAULT_SERVER_PORT = 8001
_PERMISSIONS =
class PermissionParseError(Exception):
def __init__(self, linenum, line, message=None):
self.linenum = linenum
self.line = line
self.message = ' (%s)' % message if message is not None else ''
def __str__(self):
return 'line %d%s: %s' % (self.linenum, self.message, self.line)
class PathPattern(object):
def __init__(self, path):
self.path = path
self.plen = len(path)
def match(self, s):
return s[:self.plen] == self.path and (self.path[-1] == '/' or
s[self.plen:] == '' or
s[self.plen] == '/')
class ExtensionPattern(object):
def __init__(self, ext):
self.ext = ext
def match(self, s):
return os.path.splitext(s)[1] == self.ext
class PathPermissions(object):
def __init__(self, default_allow=False):
self._entries = []
self.default_allow = default_allow
def allow(self, path):
for pattern, allow in self._entries:
if pattern.match(path):
return allow
return self.default_allow
def parse(self, lines):
for ln, l in enumerate(lines):
i = l.find('#')
if i != -1:
l = l[:i]
l = l.strip()
if not l:
continue
i = l.find(':')
if i == -1:
raise PermissionParseError(ln, lines[ln], 'missing colon')
directive = l[:i].strip().lower()
pattern = l[i+1:].strip()
if directive == 'allow':
allow = True
elif directive == 'disallow':
allow = False
else:
raise PermissionParseError(ln, lines[ln], 'unrecognized directive')
if pattern.startswith('/'):
patt = PathPattern(pattern)
elif pattern.startswith('*.'):
patt = ExtensionPattern(pattern[1:])
else:
raise PermissionParseError(ln, lines[ln], 'unrecognized pattern')
self._entries.append((patt, allow))
return self
class BratHTTPRequestHandler(SimpleHTTPRequestHandler):
permissions = PathPermissions().parse(_PERMISSIONS.split('\n'))
def log_request(self, code='-', size='-'):
if _VERBOSE_HANDLER:
SimpleHTTPRequestHandler.log_request(self, code, size)
else:
pass
def is_brat(self):
path = self.path
path = path.split('?', 1)[0]
path = path.split('#', 1)[0]
if path == '/ajax.cgi':
return True
else:
return False
def run_brat_direct(self):
remote_addr = self.client_address[0]
remote_host = self.address_string()
cookie_data = ', '.join(filter(None, self.headers.getheaders('cookie')))
query_string = ''
i = self.path.find('?')
if i != -1:
query_string = self.path[i+1:]
saved = sys.stdin, sys.stdout, sys.stderr
sys.stdin, sys.stdout = self.rfile, self.wfile
env = {}
env['REQUEST_METHOD'] = self.command
content_length = self.headers.getheader('content-length')
if content_length:
env['CONTENT_LENGTH'] = content_length
if query_string:
env['QUERY_STRING'] = query_string
os.environ.update(env)
params = FieldStorage()
cookie_hdrs, response_data = serve(params, remote_addr, remote_host,
cookie_data)
sys.stdin, sys.stdout, sys.stderr = saved
if cookie_hdrs is not None:
response_hdrs = [hdr for hdr in cookie_hdrs]
else:
response_hdrs = []
response_hdrs.extend(response_data[0])
self.send_response(200)
self.wfile.write('\n'.join('%s: %s' % (k, v) for k, v in response_hdrs))
self.wfile.write('\n')
self.wfile.write('\n')
if isinstance(response_data[1], unicode):
self.wfile.write(response_data[1].encode('utf-8'))
else:
self.wfile.write(response_data[1])
return 0
def allow_path(self):
path = self.path
path = path.split('?', 1)[0]
path = path.split('#', 1)[0]
path = unquote(path)
path = normpath(path)
parts = path.split('/')
parts = filter(None, parts)
if '..' in parts:
return False
path = '/'+'/'.join(parts)
return self.permissions.allow(path)
def list_directory(self, path):
self.send_error(403)
def do_POST(self):
if self.is_brat():
self.run_brat_direct()
else:
self.send_error(501, "Can only POST to brat")
def do_GET(self):
if not self.allow_path():
self.send_error(403)
elif self.is_brat():
self.run_brat_direct()
else:
SimpleHTTPRequestHandler.do_GET(self)
def do_HEAD(self):
if not self.allow_path():
self.send_error(403)
else:
SimpleHTTPRequestHandler.do_HEAD(self)
class BratServer(ForkingMixIn, HTTPServer):
def __init__(self, server_address):
HTTPServer.__init__(self, server_address, BratHTTPRequestHandler)
def main(argv):
try:
if os.getuid() == 0:
print >> sys.stderr,
except AttributeError:
print >> sys.stderr,
if len(argv) > 1:
try:
port = int(argv[1])
except ValueError:
print >> sys.stderr, "Failed to parse", argv[1], "as port number."
return 1
else:
port = _DEFAULT_SERVER_PORT
try:
server = BratServer((_DEFAULT_SERVER_ADDR, port))
print >> sys.stderr, "Serving brat at http://%s:%d" % server.server_address
server.serve_forever()
except KeyboardInterrupt:
pass
except socket.error, why:
print >> sys.stderr, "Error binding to port", port, ":", why[1]
except Exception, e:
print >> sys.stderr, "Server error", e
raise
return 0
if __name__ == "__main__":
sys.exit(main(sys.argv))
from .structures import LookupDict
_codes = {
100: ('continue',),
101: ('switching_protocols',),
102: ('processing',),
103: ('checkpoint',),
122: ('uri_too_long', 'request_uri_too_long'),
200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', '\\o/', '閴'),
201: ('created',),
202: ('accepted',),
203: ('non_authoritative_info', 'non_authoritative_information'),
204: ('no_content',),
205: ('reset_content', 'reset'),
206: ('partial_content', 'partial'),
207: ('multi_status', 'multiple_status', 'multi_stati', 'multiple_stati'),
208: ('im_used',),
300: ('multiple_choices',),
301: ('moved_permanently', 'moved', '\\o-'),
302: ('found',),
303: ('see_other', 'other'),
304: ('not_modified',),
305: ('use_proxy',),
306: ('switch_proxy',),
307: ('temporary_redirect', 'temporary_moved', 'temporary'),
308: ('resume_incomplete', 'resume'),
400: ('bad_request', 'bad'),
401: ('unauthorized',),
402: ('payment_required', 'payment'),
403: ('forbidden',),
404: ('not_found', '-o-'),
405: ('method_not_allowed', 'not_allowed'),
406: ('not_acceptable',),
407: ('proxy_authentication_required', 'proxy_auth', 'proxy_authentication'),
408: ('request_timeout', 'timeout'),
409: ('conflict',),
410: ('gone',),
411: ('length_required',),
412: ('precondition_failed', 'precondition'),
413: ('request_entity_too_large',),
414: ('request_uri_too_large',),
415: ('unsupported_media_type', 'unsupported_media', 'media_type'),
416: ('requested_range_not_satisfiable', 'requested_range', 'range_not_satisfiable'),
417: ('expectation_failed',),
418: ('im_a_teapot', 'teapot', 'i_am_a_teapot'),
422: ('unprocessable_entity', 'unprocessable'),
423: ('locked',),
424: ('failed_dependency', 'dependency'),
425: ('unordered_collection', 'unordered'),
426: ('upgrade_required', 'upgrade'),
428: ('precondition_required', 'precondition'),
429: ('too_many_requests', 'too_many'),
431: ('header_fields_too_large', 'fields_too_large'),
444: ('no_response', 'none'),
449: ('retry_with', 'retry'),
450: ('blocked_by_windows_parental_controls', 'parental_controls'),
499: ('client_closed_request',),
500: ('internal_server_error', 'server_error', '/o\\', '閴'),
501: ('not_implemented',),
502: ('bad_gateway',),
503: ('service_unavailable', 'unavailable'),
504: ('gateway_timeout',),
505: ('http_version_not_supported', 'http_version'),
506: ('variant_also_negotiates',),
507: ('insufficient_storage',),
509: ('bandwidth_limit_exceeded', 'bandwidth'),
510: ('not_extended',),
}
codes = LookupDict(name='status_codes')
for (code, titles) in list(_codes.items()):
for title in titles:
setattr(codes, title, code)
if not title.startswith('\\'):
setattr(codes, title.upper(), code)
class Solution(object):
def solve(self, cipher):
N, A = cipher
f = [0 for _ in A]
f[N - 1] = A[N - 1]
for i in xrange(N - 2, -1, -1):
f[i] = max(A[i], f[i + 1])
profit = 0
for i in xrange(N - 1):
profit += max(0, f[i + 1] - A[i])
return profit
if __name__ == "__main__":
import sys
f = open("0.in", "r")
solution = Solution()
testcases = int(f.readline().strip())
for t in xrange(testcases):
N = int(f.readline().strip())
A = map(int, f.readline().strip().split(' '))
cipher = N, A
s = "%s\n" % (solution.solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
r, c = cipher
r, c = r - 1, c - 1
return r / 2 * 10 + r % 2 + c * 2
if __name__ == "__main__":
import sys
f = open("0.in", "r")
solution = Solution()
cipher = map(int, f.readline().strip().split(' '))
s = "%s\n" % (solution.solve(cipher))
print s,
def longest(word_set, cache, word):
if word not in cache:
ret = 1
for i in xrange(len(word)):
w = word[:i] + word[i+1:]
if w and w in word_set:
cnt = longest(word_set, cache, w)
ret = max(ret, 1 + cnt)
cache[word] = ret
return cache[word]
def longestChain(words):
cache = {}
word_set = set(words)
gmax = 0
for word in words:
gmax = max(gmax, longest(word_set, cache, word))
return gmax
if __name__ == "__main__":
words = ["a", "b", "ba", "bca", "bda", "bdca"]
assert longestChain(words) == 4
class CaseInsensitiveDict(dict):
@property
def lower_keys(self):
if not hasattr(self, '_lower_keys') or not self._lower_keys:
self._lower_keys = dict((k.lower(), k) for k in list(self.keys()))
return self._lower_keys
def _clear_lower_keys(self):
if hasattr(self, '_lower_keys'):
self._lower_keys.clear()
def __setitem__(self, key, value):
dict.__setitem__(self, key, value)
self._clear_lower_keys()
def __delitem__(self, key):
dict.__delitem__(self, self.lower_keys.get(key.lower(), key))
self._lower_keys.clear()
def __contains__(self, key):
return key.lower() in self.lower_keys
def __getitem__(self, key):
if key in self:
return dict.__getitem__(self, self.lower_keys[key.lower()])
def get(self, key, default=None):
if key in self:
return self[key]
else:
return default
class LookupDict(dict):
def __init__(self, name=None):
self.name = name
super(LookupDict, self).__init__()
def __repr__(self):
return '<lookup \'%s\'>' % (self.name)
def __getitem__(self, key):
return self.__dict__.get(key, None)
def get(self, key, default=None):
return self.__dict__.get(key, default)
from bisect import bisect_left, bisect_right
class Solution:
def subarraySumII(self, A, start, end):
n = len(A)
cnt = 0
f = [0 for _ in xrange(n+1)]
for i in xrange(1, n+1):
f[i] = f[i-1]+A[i-1]
f.sort()
for i in xrange(n+1):
lo = bisect_left(f, f[i]-end, 0, i)
hi = bisect_right(f, f[i]-start, 0, i)
cnt += hi-lo
return cnt
def subarraySumII_TLE(self, A, start, end):
n = len(A)
cnt = 0
f = [0 for _ in xrange(n+1)]
for i in xrange(1, n+1):
f[i] = f[i-1]+A[i-1]
for i in xrange(0, n+1):
for j in xrange(i+1, n+1):
s = f[j]-f[i]
if start <= s <= end:
cnt += 1
return cnt
if __name__ == "__main__":
assert Solution().subarraySumII([1, 2, 3, 4], 1, 3) == 4
from collections import defaultdict
class Solution:
def subarraySum(self, nums):
n = len(nums)
f = [0 for _ in xrange(n+1)]
for i in xrange(1, n+1):
f[i] = f[i-1]+nums[i-1]
d = defaultdict(list)
for i in xrange(1, n+1):
d[f[i]].append(i)
for k, v in d.items():
if k == 0:
return [0, v[0]-1]
if len(v) > 1:
return [v[0], v[1]-1]
return [-1, -1]
if __name__ == "__main__":
print Solution().subarraySum([-5, 10, 5, -3, 1, 1, 1, -2, 3, -4])
class Solution:
def submatrixSum(self, matrix):
m = len(matrix)
n = len(matrix[0])
to_top = [[0 for _ in xrange(n+1)] for _ in xrange(m+1)]
for i in xrange(1, m+1):
for j in xrange(1, n+1):
to_top[i][j] = to_top[i-1][j] + matrix[i-1][j-1]
for up in xrange(m):
for down in xrange(up, m):
h = {}
s = 0
h[s] = -1
for j in xrange(n):
s += to_top[down+1][j+1] - to_top[up][j+1]
if s in h:
return [[up, h[s]+1], [down, j]]
h[s] = j
return [[-1, -1], [-1, -1]]
if __name__ == "__main__":
assert Solution().submatrixSum([
[1, 5, 7],
[3, 7, -8],
[4, -8, 9],
]) == [[1, 1], [2, 2]]
class Solution(object):
def solve(self, cipher):
S, p, q = cipher
n = len(p)
S = int(S)
global_max = 0
for i in xrange(n):
global_max = max(global_max, self.get_longest(S, p, q, i, 0), self.get_longest(S, p, q, 0, i))
return global_max
def get_longest(self, S, p, q, i, j):
start_i = i
start_j = j
local_max = 0
n = len(p)
cur_diff = 0
while i < n and j < n:
if p[i] != q[j]:
cur_diff += 1
if cur_diff > S:
while p[start_i] == q[start_j]:
start_i += 1
start_j += 1
start_i += 1
start_j += 1
cur_diff -= 1
local_max = max(local_max, i - start_i + 1)
i += 1
j += 1
return local_max
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = f.readline().strip().split(' ')
s = "%s\n" % (Solution().solve(cipher))
print s,
import gobject
import rsvg
import goocanvas
import os.path
class SvgItem(goocanvas.ItemSimple):
__gproperties__ = {
'x': (float,
'X',
'The x coordinate of a SVG image',
-10e6,
10e6,
0,
gobject.PARAM_READWRITE),
'y': (float,
'Y',
'The y coordinate of a SVG image',
-10e6,
10e6,
0,
gobject.PARAM_READWRITE),
'width': (float,
'Width',
'The width of the SVG Image',
0,
10e6,
0,
gobject.PARAM_READWRITE),
'height': (float,
'Height',
'The width of the SVG Image',
0,
10e6,
0,
gobject.PARAM_READWRITE),
}
def __init__(self, x, y, rsvg_handle, **kwargs):
super(SvgItem, self).__init__(**kwargs)
assert isinstance(rsvg_handle, rsvg.Handle)
self.x = x
self.y = y
self.sx = 1.0
self.sy = 1.0
self.handle = rsvg_handle
self.width = self.handle.props.width
self.height = self.handle.props.height
self.custom_width = None
self.custom_height = None
def do_set_property(self, pspec, value):
if pspec.name == 'x':
self.x = value
self.changed(True)
elif pspec.name == 'y':
self.y = value
self.changed(True)
elif pspec.name == 'width':
self.custom_width = value
self._size_changed()
self.changed(True)
elif pspec.name == 'height':
self.custom_height = value
self._size_changed()
self.changed(True)
else:
raise AttributeError, 'unknown property %s' % pspec.name
def _size_changed(self):
if self.custom_width is None and self.custom_height is None:
self.width = self.handle.props.width
self.height = self.handle.props.height
self.sx = 1.0
self.sy = 1.0
elif self.custom_width is not None and self.custom_height is None:
self.width = self.custom_width
self.sx = self.custom_width / self.handle.props.width
self.sy = self.sx
self.height = self.handle.props.height*self.sy
elif self.custom_width is None and self.custom_height is not None:
self.height = self.custom_height
self.sy = self.custom_height / self.handle.props.height
self.sx  = self.sy
self.width = self.handle.props.width*self.sx
else:
self.width = self.custom_width
self.height = self.custom_height
self.sx = self.custom_width / self.handle.props.width
self.sy = self.custom_height / self.handle.props.height
def do_get_property(self, pspec):
if pspec.name == 'x':
return self.x
elif pspec.name == 'y':
return self.y
elif pspec.name == 'width':
self.width = self.handle.props.width
self.height = self.handle.props.height
return self.width
elif pspec.name == 'height':
return self.height
else:
raise AttributeError, 'unknown property %s' % pspec.name
def do_simple_paint(self, cr, bounds):
cr.translate(self.x, self.y)
cr.scale(self.sx, self.sy)
self.handle.render_cairo(cr)
def do_simple_update(self, cr):
self.bounds_x1 = float(self.x)
self.bounds_y1 = float(self.y)
self.bounds_x2 = float(self.x + self.width)
self.bounds_y2 = float(self.y + self.height)
def do_simple_is_item_at(self, x, y, cr, is_pointer_event):
if ((x < self.x) or (x > self.x + self.width)) or ((y < self.y) or (y > self.y + self.height)):
return False
else:
return True
_rsvg_cache = dict()
def rsvg_handle_factory(base_file_name):
try:
return _rsvg_cache[base_file_name]
except KeyError:
full_path = os.path.join(os.path.dirname(__file__), 'resource', base_file_name)
rsvg_handle = rsvg.Handle(full_path)
_rsvg_cache[base_file_name] = rsvg_handle
return rsvg_handle
from facerec_py.facerec.classifier import SVM
from facerec_py.facerec.validation import KFoldCrossValidation
from facerec_py.facerec.model import PredictableModel
from svmutil import *
from itertools import product
import numpy as np
import logging
def range_f(begin, end, step):
seq = []
while True:
if step == 0: break
if step > 0 and begin > end: break
if step < 0 and begin < end: break
seq.append(begin)
begin = begin + step
return seq
def grid(grid_parameters):
grid = []
for parameter in grid_parameters:
begin, end, step = parameter
grid.append(range_f(begin, end, step))
return product(*grid)
def grid_search(model, X, y, C_range=(-5,  15, 2), gamma_range=(3, -15, -2), k=5, num_cores=1):
if not isinstance(model, PredictableModel):
raise TypeError("GridSearch expects a PredictableModel. If you want to perform optimization on raw data use facerec.feature.Identity to pass unpreprocessed data!")
if not isinstance(model.classifier, SVM):
raise TypeError("GridSearch expects a SVM as classifier. Please use a facerec.classifier.SVM!")
logger = logging.getLogger("facerec.svm.gridsearch")
logger.info("Performing a Grid Search.")
best_parameter = svm_parameter("-q")
best_parameter.kernel_type = model.classifier.param.kernel_type
best_parameter.nu = model.classifier.param.nu
best_parameter.coef0 = model.classifier.param.coef0
if (gamma_range is None) or (model.classifier.param.kernel_type == LINEAR):
gamma_range = (0, 0, 1)
best_accuracy = np.finfo('float').min
g = grid([C_range, gamma_range])
results = []
for p in g:
C, gamma = p
C, gamma = 2**C, 2**gamma
model.classifier.param.C, model.classifier.param.gamma = C, gamma
cv = KFoldCrossValidation(model=model,k=k)
cv.validate(X,y)
results.append([C, gamma, cv.accuracy])
if cv.accuracy > best_accuracy:
logger.info("best_accuracy=%s" % (cv.accuracy))
best_accuracy = cv.accuracy
best_parameter.C, best_parameter.gamma = C, gamma
logger.info("%d-CV Result = %.2f." % (k, cv.accuracy))
return best_parameter, results
from django import template
import markdown2
register = template.Library()
@register.simple_tag(takes_context=True)
def some_tags(context):
pass
@register.filter
def markdownify(text):
return markdown2.markdown(text, extras=["fenced-code-blocks"], safe_mode=None)
import sys
import ns.core
import ns.csma
import ns.internet
import ns.network
import ns.tap_bridge
def main(argv):
ns.core.GlobalValue.Bind("SimulatorImplementationType", ns.core.StringValue("ns3::RealtimeSimulatorImpl"))
ns.core.GlobalValue.Bind("ChecksumEnabled", ns.core.BooleanValue("true"))
nodes = ns.network.NodeContainer()
nodes.Create (2)
csma = ns.csma.CsmaHelper()
devices = csma.Install(nodes)
tapBridge = ns.tap_bridge.TapBridgeHelper()
tapBridge.SetAttribute ("Mode", ns.core.StringValue ("UseLocal"))
tapBridge.SetAttribute ("DeviceName", ns.core.StringValue ("tap-left"))
tapBridge.Install (nodes.Get (0), devices.Get (0))
tapBridge.SetAttribute ("DeviceName", ns.core.StringValue ("tap-right"))
tapBridge.Install (nodes.Get (1), devices.Get (1))
ns.core.Simulator.Stop (ns.core.Seconds (600))
ns.core.Simulator.Run(signal_check_frequency = -1)
ns.core.Simulator.Destroy()
return 0
if __name__ == '__main__':
sys.exit(main(sys.argv))
import sys
import ns.core
import ns.internet
import ns.mobility
import ns.network
import ns.tap_bridge
import ns.wifi
def main(argv):
ns.core.GlobalValue.Bind("SimulatorImplementationType", ns.core.StringValue("ns3::RealtimeSimulatorImpl"))
ns.core.GlobalValue.Bind("ChecksumEnabled", ns.core.BooleanValue("true"))
nodes = ns.network.NodeContainer()
nodes.Create (2);
wifi = ns.wifi.WifiHelper.Default()
wifi.SetStandard (ns.wifi.WIFI_PHY_STANDARD_80211a);
wifi.SetRemoteStationManager ("ns3::ConstantRateWifiManager", "DataMode", ns.core.StringValue ("OfdmRate54Mbps"));
wifiMac = ns.wifi.NqosWifiMacHelper.Default()
wifiMac.SetType ("ns3::AdhocWifiMac");
wifiChannel = ns.wifi.YansWifiChannelHelper.Default()
wifiPhy = ns.wifi.YansWifiPhyHelper.Default()
wifiPhy.SetChannel(wifiChannel.Create())
devices = wifi.Install(wifiPhy, wifiMac, nodes)
mobility = ns.mobility.MobilityHelper()
positionAlloc = ns.mobility.ListPositionAllocator()
positionAlloc.Add(ns.core.Vector(0.0, 0.0, 0.0))
positionAlloc.Add(ns.core.Vector(5.0, 0.0, 0.0))
mobility.SetPositionAllocator(positionAlloc)
mobility.SetMobilityModel ("ns3::ConstantPositionMobilityModel")
mobility.Install(nodes)
tapBridge = ns.tap_bridge.TapBridgeHelper()
tapBridge.SetAttribute ("Mode", ns.core.StringValue ("UseLocal"));
tapBridge.SetAttribute ("DeviceName", ns.core.StringValue ("tap-left"));
tapBridge.Install (nodes.Get (0), devices.Get (0));
tapBridge.SetAttribute ("DeviceName", ns.core.StringValue ("tap-right"));
tapBridge.Install (nodes.Get (1), devices.Get (1));
ns.core.Simulator.Stop (ns.core.Seconds (600));
ns.core.Simulator.Run(signal_check_frequency = -1)
ns.core.Simulator.Destroy()
return 0
if __name__ == '__main__':
sys.exit(main(sys.argv))
class Solution(object):
def solve(self, cipher):
tasks = cipher
tasks.sort(key=lambda t: t[0])
overshot = -1
timer = 0
for task in tasks:
timer += task[1]
overshot = max(overshot, timer - task[0])
return overshot
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
cipher = []
for t in xrange(testcases):
cipher.append(map(lambda x: int(x), f.readline().strip().split(' ')))
s = "%s\n" % (Solution().solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
if __name__ == "__main__":
import sys
f = open("0.in", "r")
solution = Solution()
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = map(int, f.readline().strip().split(' '))
s = "%s\n" % (solution.solve(cipher))
print s,
import os
import sys
import time
import optparse
import subprocess
import threading
import Queue
import signal
import xml.dom.minidom
import shutil
import re
from utils import get_list_from_file
interesting_config_items = [
"NS3_ENABLED_MODULES",
"NS3_MODULE_PATH",
"NSC_ENABLED",
"ENABLE_REAL_TIME",
"ENABLE_THREADING",
"ENABLE_EXAMPLES",
"ENABLE_TESTS",
"EXAMPLE_DIRECTORIES",
"ENABLE_PYTHON_BINDINGS",
"ENABLE_CLICK",
"ENABLE_OPENFLOW",
]
NSC_ENABLED = False
ENABLE_REAL_TIME = False
ENABLE_THREADING = False
ENABLE_EXAMPLES = True
ENABLE_TESTS = True
ENABLE_CLICK = False
ENABLE_OPENFLOW = False
EXAMPLE_DIRECTORIES = []
core_kinds = ["bvt", "core", "system", "unit"]
core_valgrind_skip_tests = [
"ns3-tcp-cwnd",
"nsc-tcp-loss",
"ns3-tcp-interoperability",
"routing-click",
]
core_nsc_missing_skip_tests = [
"ns3-tcp-cwnd",
"nsc-tcp-loss",
"ns3-tcp-interoperability",
]
def parse_examples_to_run_file(
examples_to_run_path,
cpp_executable_dir,
python_script_dir,
example_tests,
python_tests):
if os.path.exists(examples_to_run_path):
cpp_examples = get_list_from_file(examples_to_run_path, "cpp_examples")
for example_name, do_run, do_valgrind_run in cpp_examples:
example_path = os.path.join(cpp_executable_dir, example_name)
if os.path.exists(example_path):
example_tests.append((example_path, do_run, do_valgrind_run))
python_examples = get_list_from_file(examples_to_run_path, "python_examples")
for example_name, do_run in python_examples:
example_path = os.path.join(python_script_dir, example_name)
if os.path.exists(example_path):
python_tests.append((example_path, do_run))
TMP_OUTPUT_DIR = "testpy-output"
def read_test(test):
result = test.find('Result').text
name = test.find('Name').text
if not test.find('Time') is None:
time_real = test.find('Time').get('real')
else:
time_real = ''
return (result, name, time_real)
def node_to_text (test, f):
(result, name, time_real) = read_test(test)
output = "%s: Test Suite \"%s\" (%s)\n" % (result, name, time_real)
f.write(output)
for details in test.findall('FailureDetails'):
f.write("    Details:\n")
f.write("      Message:   %s\n" % details.find('Message').text)
f.write("      Condition: %s\n" % details.find('Condition').text)
f.write("      Actual:    %s\n" % details.find('Actual').text)
f.write("      Limit:     %s\n" % details.find('Limit').text)
f.write("      File:      %s\n" % details.find('File').text)
f.write("      Line:      %s\n" % details.find('Line').text)
for child in test.findall('Test'):
node_to_text(child, f)
def translate_to_text(results_file, text_file):
f = open(text_file, 'w')
import xml.etree.ElementTree as ET
et = ET.parse (results_file)
for test in et.findall('Test'):
node_to_text (test, f)
for example in et.findall('Example'):
result = example.find('Result').text
name = example.find('Name').text
if not example.find('Time') is None:
time_real = example.find('Time').get('real')
else:
time_real = ''
output = "%s: Example \"%s\" (%s)\n" % (result, name, time_real)
f.write(output)
f.close()
def translate_to_html(results_file, html_file):
f = open(html_file, 'w')
f.write("<html>\n")
f.write("<body>\n")
f.write("<center><h1>ns-3 Test Results</h1></center>\n")
import xml.etree.ElementTree as ET
et = ET.parse(results_file)
f.write("<h2>Test Suites</h2>\n")
for suite in et.findall('Test'):
(result, name, time) = read_test (suite)
if result == "PASS":
f.write("<h3 style=\"color:green\">%s: %s (%s)</h3>\n" % (result, name, time))
elif result == "SKIP":
f.write("<h3 style=\"color:
else:
f.write("<h3 style=\"color:red\">%s: %s (%s)</h3>\n" % (result, name, time))
f.write("<table border=\"1\">\n")
f.write("<th> Result </th>\n")
if result in ["CRASH", "SKIP", "VALGR"]:
f.write("<tr>\n")
if result == "SKIP":
f.write("<td style=\"color:
else:
f.write("<td style=\"color:red\">%s</td>\n" % result)
f.write("</tr>\n")
f.write("</table>\n")
continue
f.write("<th>Test Case Name</th>\n")
f.write("<th> Time </th>\n")
if result == "FAIL":
f.write("<th>Failure Details</th>\n")
for case in suite.findall('Test'):
(result, name, time) = read_test(case)
if result == "FAIL":
first_row = True
for details in case.findall('FailureDetails'):
f.write("<tr>\n")
if first_row:
first_row = False
f.write("<td style=\"color:red\">%s</td>\n" % result)
f.write("<td>%s</td>\n" % name)
f.write("<td>%s</td>\n" % time)
else:
f.write("<td></td>\n")
f.write("<td></td>\n")
f.write("<td></td>\n")
f.write("<td>")
f.write("<b>Message: </b>%s, " % details.find('Message').text)
f.write("<b>Condition: </b>%s, " % details.find('Condition').text)
f.write("<b>Actual: </b>%s, " % details.find('Actual').text)
f.write("<b>Limit: </b>%s, " % details.find('Limit').text)
f.write("<b>File: </b>%s, " % details.find('File').text)
f.write("<b>Line: </b>%s" % details.find('Line').text)
f.write("</td>\n")
f.write("</td>\n")
else:
f.write("<tr>\n")
f.write("<td style=\"color:green\">%s</td>\n" % result)
f.write("<td>%s</td>\n" % name)
f.write("<td>%s</td>\n" % time)
f.write("<td></td>\n")
f.write("</tr>\n")
f.write("</table>\n")
f.write("<h2>Examples</h2>\n")
f.write("<table border=\"1\">\n")
f.write("<th> Result </th>\n")
f.write("<th>Example Name</th>\n")
f.write("<th>Elapsed Time</th>\n")
for example in et.findall("Example"):
f.write("<tr>\n")
(result, name, time) = read_test(example)
if result == "PASS":
f.write("<td style=\"color:green\">%s</td>\n" % result)
elif result == "SKIP":
f.write("<td style=\"color:
else:
f.write("<td style=\"color:red\">%s</td>\n" % result)
f.write("<td>%s</td>\n" % name)
f.write("<td>%s</td>\n" % time)
f.write("</tr>\n")
f.write("</table>\n")
f.write("</body>\n")
f.write("</html>\n")
f.close()
thread_exit = False
def sigint_hook(signal, frame):
global thread_exit
thread_exit = True
return 0
def read_waf_config():
for line in open(".lock-wafbuild", "rt"):
if line.startswith("out_dir ="):
key, val = line.split('=')
out_dir = eval(val.strip())
global NS3_BUILDDIR
NS3_BUILDDIR = out_dir
for line in open("%s/c4che/_cache.py" % out_dir).readlines():
for item in interesting_config_items:
if line.startswith(item):
exec(line, globals())
if options.verbose:
for item in interesting_config_items:
print "%s ==" % item, eval(item)
def make_paths():
have_DYLD_LIBRARY_PATH = False
have_LD_LIBRARY_PATH = False
have_PATH = False
have_PYTHONPATH = False
keys = os.environ.keys()
for key in keys:
if key == "DYLD_LIBRARY_PATH":
have_DYLD_LIBRARY_PATH = True
if key == "LD_LIBRARY_PATH":
have_LD_LIBRARY_PATH = True
if key == "PATH":
have_PATH = True
if key == "PYTHONPATH":
have_PYTHONPATH = True
pypath = os.environ["PYTHONPATH"] = os.path.join (NS3_BUILDDIR, "bindings", "python")
if not have_PYTHONPATH:
os.environ["PYTHONPATH"] = pypath
else:
os.environ["PYTHONPATH"] += ":" + pypath
if options.verbose:
print "os.environ[\"PYTHONPATH\"] == %s" % os.environ["PYTHONPATH"]
if sys.platform == "darwin":
if not have_DYLD_LIBRARY_PATH:
os.environ["DYLD_LIBRARY_PATH"] = ""
for path in NS3_MODULE_PATH:
os.environ["DYLD_LIBRARY_PATH"] += ":" + path
if options.verbose:
print "os.environ[\"DYLD_LIBRARY_PATH\"] == %s" % os.environ["DYLD_LIBRARY_PATH"]
elif sys.platform == "win32":
if not have_PATH:
os.environ["PATH"] = ""
for path in NS3_MODULE_PATH:
os.environ["PATH"] += ';' + path
if options.verbose:
print "os.environ[\"PATH\"] == %s" % os.environ["PATH"]
elif sys.platform == "cygwin":
if not have_PATH:
os.environ["PATH"] = ""
for path in NS3_MODULE_PATH:
os.environ["PATH"] += ":" + path
if options.verbose:
print "os.environ[\"PATH\"] == %s" % os.environ["PATH"]
else:
if not have_LD_LIBRARY_PATH:
os.environ["LD_LIBRARY_PATH"] = ""
for path in NS3_MODULE_PATH:
os.environ["LD_LIBRARY_PATH"] += ":" + path
if options.verbose:
print "os.environ[\"LD_LIBRARY_PATH\"] == %s" % os.environ["LD_LIBRARY_PATH"]
VALGRIND_SUPPRESSIONS_FILE = "testpy.supp"
def run_job_synchronously(shell_command, directory, valgrind, is_python, build_path=""):
(base, build) = os.path.split (NS3_BUILDDIR)
suppressions_path = os.path.join (base, VALGRIND_SUPPRESSIONS_FILE)
if is_python:
path_cmd = "python " + os.path.join (base, shell_command)
else:
if len(build_path):
path_cmd = os.path.join (build_path, shell_command)
else:
path_cmd = os.path.join (NS3_BUILDDIR, shell_command)
if valgrind:
cmd = "valgrind --suppressions=%s --leak-check=full --show-reachable=yes --error-exitcode=2 %s" % (suppressions_path,
path_cmd)
else:
cmd = path_cmd
if options.verbose:
print "Synchronously execute %s" % cmd
start_time = time.time()
proc = subprocess.Popen(cmd, shell = True, cwd = directory, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
stdout_results, stderr_results = proc.communicate()
elapsed_time = time.time() - start_time
retval = proc.returncode
if valgrind and retval == 0 and "== LEAK SUMMARY:" in stderr_results:
retval = 2
if options.verbose:
print "Return code = ", retval
print "stderr = ", stderr_results
return (retval, stdout_results, stderr_results, elapsed_time)
class Job:
def __init__(self):
self.is_break = False
self.is_skip = False
self.is_example = False
self.is_pyexample = False
self.shell_command = ""
self.display_name = ""
self.basedir = ""
self.tempdir = ""
self.cwd = ""
self.tmp_file_name = ""
self.returncode = False
self.elapsed_time = 0
self.build_path = ""
def set_is_break(self, is_break):
self.is_break = is_break
def set_is_skip(self, is_skip):
self.is_skip = is_skip
def set_is_example(self, is_example):
self.is_example = is_example
def set_is_pyexample(self, is_pyexample):
self.is_pyexample = is_pyexample
def set_shell_command(self, shell_command):
self.shell_command = shell_command
def set_build_path(self, build_path):
self.build_path = build_path
def set_display_name(self, display_name):
self.display_name = display_name
def set_basedir(self, basedir):
self.basedir = basedir
def set_tempdir(self, tempdir):
self.tempdir = tempdir
def set_cwd(self, cwd):
self.cwd = cwd
def set_tmp_file_name(self, tmp_file_name):
self.tmp_file_name = tmp_file_name
def set_returncode(self, returncode):
self.returncode = returncode
def set_elapsed_time(self, elapsed_time):
self.elapsed_time = elapsed_time
class worker_thread(threading.Thread):
def __init__(self, input_queue, output_queue):
threading.Thread.__init__(self)
self.input_queue = input_queue
self.output_queue = output_queue
def run(self):
while True:
job = self.input_queue.get()
if job.is_break:
return
if thread_exit == True:
job.set_is_break(True)
self.output_queue.put(job)
continue
if job.is_skip:
if options.verbose:
print "Skip %s" % job.shell_command
self.output_queue.put(job)
continue
else:
if options.verbose:
print "Launch %s" % job.shell_command
if job.is_example or job.is_pyexample:
(job.returncode, standard_out, standard_err, et) = run_job_synchronously(job.shell_command,
job.cwd, options.valgrind, job.is_pyexample, job.build_path)
else:
if options.update_data:
update_data = '--update-data'
else:
update_data = ''
(job.returncode, standard_out, standard_err, et) = run_job_synchronously(job.shell_command +
" --xml --tempdir=%s --out=%s %s" % (job.tempdir, job.tmp_file_name, update_data),
job.cwd, options.valgrind, False)
job.set_elapsed_time(et)
if options.verbose:
print "returncode = %d" % job.returncode
print "---------- begin standard out ----------"
print standard_out
print "---------- begin standard err ----------"
print standard_err
print "---------- end standard err ----------"
self.output_queue.put(job)
def run_tests():
if not options.nowaf:
if options.kinds or options.list or (len(options.constrain) and options.constrain in core_kinds):
if sys.platform == "win32":
waf_cmd = "waf --target=test-runner"
else:
waf_cmd = "./waf --target=test-runner"
elif len(options.example):
if sys.platform == "win32":
waf_cmd = "waf --target=%s" % os.path.basename(options.example)
else:
waf_cmd = "./waf --target=%s" % os.path.basename(options.example)
else:
if sys.platform == "win32":
waf_cmd = "waf"
else:
waf_cmd = "./waf"
if options.verbose:
print "Building: %s" % waf_cmd
proc = subprocess.Popen(waf_cmd, shell = True)
proc.communicate()
if proc.returncode:
print >> sys.stderr, "Waf died. Not running tests"
return proc.returncode
read_waf_config()
make_paths()
build_status_file = os.path.join (NS3_BUILDDIR, 'build-status.py')
if os.path.exists(build_status_file):
ns3_runnable_programs = get_list_from_file(build_status_file, "ns3_runnable_programs")
ns3_runnable_scripts = get_list_from_file(build_status_file, "ns3_runnable_scripts")
else:
print >> sys.stderr, 'The build status file was not found.  You must do waf build before running test.py.'
sys.exit(2)
example_tests = []
python_tests = []
for directory in EXAMPLE_DIRECTORIES:
example_directory   = os.path.join("examples", directory)
examples_to_run_path = os.path.join(example_directory, "examples-to-run.py")
cpp_executable_dir   = os.path.join(NS3_BUILDDIR, example_directory)
python_script_dir    = os.path.join(example_directory)
parse_examples_to_run_file(
examples_to_run_path,
cpp_executable_dir,
python_script_dir,
example_tests,
python_tests)
for module in NS3_ENABLED_MODULES:
module = module[len("ns3-"):]
module_directory     = os.path.join("src", module)
example_directory    = os.path.join(module_directory, "examples")
examples_to_run_path = os.path.join(module_directory, "test", "examples-to-run.py")
cpp_executable_dir   = os.path.join(NS3_BUILDDIR, example_directory)
python_script_dir    = os.path.join(example_directory)
parse_examples_to_run_file(
examples_to_run_path,
cpp_executable_dir,
python_script_dir,
example_tests,
python_tests)
os.environ["NS_LOG"] = ""
if options.kinds:
path_cmd = os.path.join("utils", "test-runner --print-test-type-list")
(rc, standard_out, standard_err, et) = run_job_synchronously(path_cmd, os.getcwd(), False, False)
print standard_out
if options.list:
path_cmd = os.path.join("utils", "test-runner --print-test-name-list")
(rc, standard_out, standard_err, et) = run_job_synchronously(path_cmd, os.getcwd(), False, False)
print standard_out
if options.kinds or options.list:
return
date_and_time = time.strftime("%Y-%m-%d-%H-%M-%S-CUT", time.gmtime())
if not os.path.exists(TMP_OUTPUT_DIR):
os.makedirs(TMP_OUTPUT_DIR)
testpy_output_dir = os.path.join(TMP_OUTPUT_DIR, date_and_time);
if not os.path.exists(testpy_output_dir):
os.makedirs(testpy_output_dir)
xml_results_file = os.path.join(testpy_output_dir, "results.xml")
f = open(xml_results_file, 'w')
f.write('<?xml version="1.0"?>\n')
f.write('<Results>\n')
f.close()
if len(options.suite):
path_cmd = os.path.join("utils", "test-runner --print-test-name-list")
(rc, suites, standard_err, et) = run_job_synchronously(path_cmd, os.getcwd(), False, False)
if options.suite in suites:
suites = options.suite + "\n"
else:
print >> sys.stderr, 'The test suite was not run because an unknown test suite name was requested.'
sys.exit(2)
elif len(options.example) == 0 and len(options.pyexample) == 0:
if len(options.constrain):
path_cmd = os.path.join("utils", "test-runner --print-test-name-list --test-type=%s" % options.constrain)
(rc, suites, standard_err, et) = run_job_synchronously(path_cmd, os.getcwd(), False, False)
else:
path_cmd = os.path.join("utils", "test-runner --print-test-name-list")
(rc, suites, standard_err, et) = run_job_synchronously(path_cmd, os.getcwd(), False, False)
else:
suites = ""
suite_list = suites.split('\n')
input_queue = Queue.Queue(0)
output_queue = Queue.Queue(0)
jobs = 0
threads=[]
processors = 1
if sys.platform != "win32":
if 'SC_NPROCESSORS_ONLN'in os.sysconf_names:
processors = os.sysconf('SC_NPROCESSORS_ONLN')
else:
proc = subprocess.Popen("sysctl -n hw.ncpu", shell = True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
stdout_results, stderr_results = proc.communicate()
if len(stderr_results) == 0:
processors = int(stdout_results)
for i in range(processors):
thread = worker_thread(input_queue, output_queue)
threads.append(thread)
thread.start()
total_tests = 0
skipped_tests = 0
for test in suite_list:
test = test.strip()
if len(test):
job = Job()
job.set_is_example(False)
job.set_is_pyexample(False)
job.set_display_name(test)
job.set_tmp_file_name(os.path.join(testpy_output_dir, "%s.xml" % test))
job.set_cwd(os.getcwd())
job.set_basedir(os.getcwd())
job.set_tempdir(testpy_output_dir)
if (options.multiple):
multiple = ""
else:
multiple = " --stop-on-failure"
path_cmd = os.path.join("utils", "test-runner --test-name=%s%s" % (test, multiple))
job.set_shell_command(path_cmd)
if options.valgrind and test in core_valgrind_skip_tests:
job.set_is_skip(True)
if not NSC_ENABLED and test in core_nsc_missing_skip_tests:
job.set_is_skip(True)
if options.verbose:
print "Queue %s" % test
input_queue.put(job)
jobs = jobs + 1
total_tests = total_tests + 1
if len(options.suite) == 0 and len(options.example) == 0 and len(options.pyexample) == 0:
if len(options.constrain) == 0 or options.constrain == "example":
if ENABLE_EXAMPLES:
for test, do_run, do_valgrind_run in example_tests:
if os.path.basename(test) in ns3_runnable_programs:
if eval(do_run):
job = Job()
job.set_is_example(True)
job.set_is_pyexample(False)
job.set_display_name(test)
job.set_tmp_file_name("")
job.set_cwd(testpy_output_dir)
job.set_basedir(os.getcwd())
job.set_tempdir(testpy_output_dir)
job.set_shell_command(test)
job.set_build_path("")
if options.valgrind and not eval(do_valgrind_run):
job.set_is_skip (True)
if options.verbose:
print "Queue %s" % test
input_queue.put(job)
jobs = jobs + 1
total_tests = total_tests + 1
elif len(options.example):
example_name = os.path.basename(options.example)
if example_name not in ns3_runnable_programs:
print "Example %s is not runnable." % example_name
else:
job = Job()
job.set_is_example(True)
job.set_is_pyexample(False)
job.set_display_name(options.example)
job.set_tmp_file_name("")
job.set_cwd(testpy_output_dir)
job.set_basedir(os.getcwd())
job.set_tempdir(testpy_output_dir)
job.set_shell_command(options.example)
job.set_build_path(options.buildpath)
if options.verbose:
print "Queue %s" % options.example
input_queue.put(job)
jobs = jobs + 1
total_tests = total_tests + 1
if len(options.suite) == 0 and len(options.example) == 0 and len(options.pyexample) == 0:
if len(options.constrain) == 0 or options.constrain == "pyexample":
if ENABLE_EXAMPLES:
for test, do_run in python_tests:
if os.path.basename(test) in ns3_runnable_scripts:
if eval(do_run):
job = Job()
job.set_is_example(False)
job.set_is_pyexample(True)
job.set_display_name(test)
job.set_tmp_file_name("")
job.set_cwd(testpy_output_dir)
job.set_basedir(os.getcwd())
job.set_tempdir(testpy_output_dir)
job.set_shell_command(test)
job.set_build_path("")
if options.valgrind:
job.set_is_skip (True)
if not ENABLE_PYTHON_BINDINGS:
job.set_is_skip (True)
if options.verbose:
print "Queue %s" % test
input_queue.put(job)
jobs = jobs + 1
total_tests = total_tests + 1
elif len(options.pyexample):
example_name = os.path.basename(options.pyexample)
if example_name not in ns3_runnable_scripts:
print "Example %s is not runnable." % example_name
else:
job = Job()
job.set_is_pyexample(True)
job.set_display_name(options.pyexample)
job.set_tmp_file_name("")
job.set_cwd(testpy_output_dir)
job.set_basedir(os.getcwd())
job.set_tempdir(testpy_output_dir)
job.set_shell_command(options.pyexample)
job.set_build_path("")
if options.verbose:
print "Queue %s" % options.pyexample
input_queue.put(job)
jobs = jobs + 1
total_tests = total_tests + 1
for i in range(processors):
job = Job()
job.set_is_break(True)
input_queue.put(job)
passed_tests = 0
failed_tests = 0
crashed_tests = 0
valgrind_errors = 0
for i in range(jobs):
job = output_queue.get()
if job.is_break:
continue
if job.is_example or job.is_pyexample:
kind = "Example"
else:
kind = "TestSuite"
if job.is_skip:
status = "SKIP"
skipped_tests = skipped_tests + 1
else:
if job.returncode == 0:
status = "PASS"
passed_tests = passed_tests + 1
elif job.returncode == 1:
failed_tests = failed_tests + 1
status = "FAIL"
elif job.returncode == 2:
valgrind_errors = valgrind_errors + 1
status = "VALGR"
else:
crashed_tests = crashed_tests + 1
status = "CRASH"
print "%s: %s %s" % (status, kind, job.display_name)
if job.is_example or job.is_pyexample:
f = open(xml_results_file, 'a')
f.write('<Example>\n')
example_name = "  <Name>%s</Name>\n" % job.display_name
f.write(example_name)
if status == "PASS":
f.write('  <Result>PASS</Result>\n')
elif status == "FAIL":
f.write('  <Result>FAIL</Result>\n')
elif status == "VALGR":
f.write('  <Result>VALGR</Result>\n')
elif status == "SKIP":
f.write('  <Result>SKIP</Result>\n')
else:
f.write('  <Result>CRASH</Result>\n')
f.write('  <Time real="%.3f"/>\n' % job.elapsed_time)
f.write('</Example>\n')
f.close()
else:
if job.is_skip:
f = open(xml_results_file, 'a')
f.write("<Test>\n")
f.write("  <Name>%s</Name>\n" % job.display_name)
f.write('  <Result>SKIP</Result>\n')
f.write("</Test>\n")
f.close()
else:
if job.returncode == 0 or job.returncode == 1 or job.returncode == 2:
f_to = open(xml_results_file, 'a')
f_from = open(job.tmp_file_name)
f_to.write(f_from.read())
f_to.close()
f_from.close()
else:
f = open(xml_results_file, 'a')
f.write("<Test>\n")
f.write("  <Name>%s</Name>\n" % job.display_name)
f.write('  <Result>CRASH</Suite>\n')
f.write("</Test>\n")
f.close()
if job.returncode == 2:
f = open(xml_results_file, 'a')
f.write("<Test>\n")
f.write("  <Name>%s</Name>\n" % job.display_name)
f.write('  <Result>VALGR</Result>\n')
f.write("</Test>\n")
f.close()
for thread in threads:
thread.join()
f = open(xml_results_file, 'a')
f.write('</Results>\n')
f.close()
print "%d of %d tests passed (%d passed, %d skipped, %d failed, %d crashed, %d valgrind errors)" % (passed_tests,
total_tests, passed_tests, skipped_tests, failed_tests, crashed_tests, valgrind_errors)
if len(options.html):
translate_to_html(xml_results_file, options.html)
if len(options.text):
translate_to_text(xml_results_file, options.text)
if len(options.xml):
shutil.copyfile(xml_results_file, options.xml)
if not ENABLE_TESTS or not ENABLE_EXAMPLES:
print
if not ENABLE_TESTS:
print '***  Note: ns-3 tests are currently disabled. Enable them by adding'
print '***  "--enable-tests" to ./waf configure or modifying your .ns3rc file.'
print
if not ENABLE_EXAMPLES:
print '***  Note: ns-3 examples are currently disabled. Enable them by adding'
print '***  "--enable-examples" to ./waf configure or modifying your .ns3rc file.'
print
if not options.retain:
shutil.rmtree(testpy_output_dir)
if passed_tests + skipped_tests == total_tests:
return 0
else:
return 1
def main(argv):
parser = optparse.OptionParser()
parser.add_option("-b", "--buildpath", action="store", type="string", dest="buildpath", default="",
metavar="BUILDPATH",
help="specify the path where ns-3 was built (defaults to the build directory for the current variant)")
parser.add_option("-c", "--constrain", action="store", type="string", dest="constrain", default="",
metavar="KIND",
help="constrain the test-runner by kind of test")
parser.add_option("-e", "--example", action="store", type="string", dest="example", default="",
metavar="EXAMPLE",
help="specify a single example to run (with relative path)")
parser.add_option("-u", "--update-data", action="store_true", dest="update_data", default=False,
help="If examples use reference data files, get them to re-generate them")
parser.add_option("-g", "--grind", action="store_true", dest="valgrind", default=False,
help="run the test suites and examples using valgrind")
parser.add_option("-k", "--kinds", action="store_true", dest="kinds", default=False,
help="print the kinds of tests available")
parser.add_option("-l", "--list", action="store_true", dest="list", default=False,
help="print the list of known tests")
parser.add_option("-m", "--multiple", action="store_true", dest="multiple", default=False,
help="report multiple failures from test suites and test cases")
parser.add_option("-n", "--nowaf", action="store_true", dest="nowaf", default=False,
help="do not run waf before starting testing")
parser.add_option("-p", "--pyexample", action="store", type="string", dest="pyexample", default="",
metavar="PYEXAMPLE",
help="specify a single python example to run (with relative path)")
parser.add_option("-r", "--retain", action="store_true", dest="retain", default=False,
help="retain all temporary files (which are normally deleted)")
parser.add_option("-s", "--suite", action="store", type="string", dest="suite", default="",
metavar="TEST-SUITE",
help="specify a single test suite to run")
parser.add_option("-t", "--text", action="store", type="string", dest="text", default="",
metavar="TEXT-FILE",
help="write detailed test results into TEXT-FILE.txt")
parser.add_option("-v", "--verbose", action="store_true", dest="verbose", default=False,
help="print progress and informational messages")
parser.add_option("-w", "--web", "--html", action="store", type="string", dest="html", default="",
metavar="HTML-FILE",
help="write detailed test results into HTML-FILE.html")
parser.add_option("-x", "--xml", action="store", type="string", dest="xml", default="",
metavar="XML-FILE",
help="write detailed test results into XML-FILE.xml")
global options
options = parser.parse_args()[0]
signal.signal(signal.SIGINT, sigint_hook)
return run_tests()
if __name__ == '__main__':
sys.exit(main(sys.argv))
def _add_tests(generator):
def class_decorator(cls):
for f, args in generator():
test = lambda self, args=args, f=f: f(self, *args)
test.__name__ = "test_%s_%s" % (f.__name__, args[0])
setattr(cls, test.__name__, test)
return cls
return class_decorator
import copy
import functools
import unittest
from unittest import TestCase
from bs4 import BeautifulSoup
from bs4.element import (
CharsetMetaAttributeValue,
Comment,
ContentMetaAttributeValue,
Doctype,
SoupStrainer,
)
from bs4.builder import HTMLParserTreeBuilder
default_builder = HTMLParserTreeBuilder
class SoupTest(unittest.TestCase):
@property
def default_builder(self):
return default_builder()
def soup(self, markup, **kwargs):
builder = kwargs.pop('builder', self.default_builder)
return BeautifulSoup(markup, builder=builder, **kwargs)
def document_for(self, markup):
return self.default_builder.test_fragment_to_document(markup)
def assertSoupEquals(self, to_parse, compare_parsed_to=None):
builder = self.default_builder
obj = BeautifulSoup(to_parse, builder=builder)
if compare_parsed_to is None:
compare_parsed_to = to_parse
self.assertEqual(obj.decode(), self.document_for(compare_parsed_to))
class HTMLTreeBuilderSmokeTest(object):
def assertDoctypeHandled(self, doctype_fragment):
doctype_str, soup = self._document_with_doctype(doctype_fragment)
doctype = soup.contents[0]
self.assertEqual(doctype.__class__, Doctype)
self.assertEqual(doctype, doctype_fragment)
self.assertEqual(str(soup)[:len(doctype_str)], doctype_str)
self.assertEqual(soup.p.contents[0], 'foo')
def _document_with_doctype(self, doctype_fragment):
doctype = '<!DOCTYPE %s>' % doctype_fragment
markup = doctype + '\n<p>foo</p>'
soup = self.soup(markup)
return doctype, soup
def test_normal_doctypes(self):
self.assertDoctypeHandled("html")
self.assertDoctypeHandled(
'html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"')
def test_public_doctype_with_url(self):
doctype = 'html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"'
self.assertDoctypeHandled(doctype)
def test_system_doctype(self):
self.assertDoctypeHandled('foo SYSTEM "http://www.example.com/"')
def test_namespaced_system_doctype(self):
self.assertDoctypeHandled('xsl:stylesheet SYSTEM "htmlent.dtd"')
def test_namespaced_public_doctype(self):
self.assertDoctypeHandled('xsl:stylesheet PUBLIC "htmlent.dtd"')
def test_real_xhtml_document(self):
markup = b
soup = self.soup(markup)
self.assertEqual(
soup.encode("utf-8").replace(b"\n", b""),
markup.replace(b"\n", b""))
def test_deepcopy(self):
copy.deepcopy(self.default_builder)
def test_p_tag_is_never_empty_element(self):
soup = self.soup("<p/>")
self.assertFalse(soup.p.is_empty_element)
self.assertEqual(str(soup.p), "<p></p>")
def test_unclosed_tags_get_closed(self):
self.assertSoupEquals("<p>", "<p></p>")
self.assertSoupEquals("<b>", "<b></b>")
self.assertSoupEquals("<br>", "<br/>")
def test_br_is_always_empty_element_tag(self):
soup = self.soup("<br></br>")
self.assertTrue(soup.br.is_empty_element)
self.assertEqual(str(soup.br), "<br/>")
def test_nested_formatting_elements(self):
self.assertSoupEquals("<em><em></em></em>")
def test_comment(self):
markup = "<p>foo<!--foobar-->baz</p>"
self.assertSoupEquals(markup)
soup = self.soup(markup)
comment = soup.find(text="foobar")
self.assertEqual(comment.__class__, Comment)
def test_preserved_whitespace_in_pre_and_textarea(self):
self.assertSoupEquals("<pre>   </pre>")
self.assertSoupEquals("<textarea> woo  </textarea>")
def test_nested_inline_elements(self):
b_tag = "<b>Inside a B tag</b>"
self.assertSoupEquals(b_tag)
nested_b_tag = "<p>A <i>nested <b>tag</b></i></p>"
self.assertSoupEquals(nested_b_tag)
double_nested_b_tag = "<p>A <a>doubly <i>nested <b>tag</b></i></a></p>"
self.assertSoupEquals(nested_b_tag)
def test_nested_block_level_elements(self):
soup = self.soup('<blockquote><p><b>Foo</b></p></blockquote>')
blockquote = soup.blockquote
self.assertEqual(blockquote.p.b.string, 'Foo')
self.assertEqual(blockquote.b.string, 'Foo')
def test_correctly_nested_tables(self):
markup = ('<table id="1">'
'<tr>'
"<td>Here's another table:"
'<table id="2">'
'<tr><td>foo</td></tr>'
'</table></td>')
self.assertSoupEquals(
markup,
'<table id="1"><tr><td>Here\'s another table:'
'<table id="2"><tr><td>foo</td></tr></table>'
'</td></tr></table>')
self.assertSoupEquals(
"<table><thead><tr><td>Foo</td></tr></thead>"
"<tbody><tr><td>Bar</td></tr></tbody>"
"<tfoot><tr><td>Baz</td></tr></tfoot></table>")
def test_deeply_nested_multivalued_attribute(self):
markup = '<table><div><div class="css"></div></div></table>'
soup = self.soup(markup)
self.assertEqual(["css"], soup.div.div['class'])
def test_angle_brackets_in_attribute_values_are_escaped(self):
self.assertSoupEquals('<a b="<a>"></a>', '<a b="&lt;a&gt;"></a>')
def test_entities_in_attributes_converted_to_unicode(self):
expect = u'<p id="pi\N{LATIN SMALL LETTER N WITH TILDE}ata"></p>'
self.assertSoupEquals('<p id="pi&
self.assertSoupEquals('<p id="pi&
self.assertSoupEquals('<p id="pi&ntilde;ata"></p>', expect)
def test_entities_in_text_converted_to_unicode(self):
expect = u'<p>pi\N{LATIN SMALL LETTER N WITH TILDE}ata</p>'
self.assertSoupEquals("<p>pi&
self.assertSoupEquals("<p>pi&
self.assertSoupEquals("<p>pi&ntilde;ata</p>", expect)
def test_quot_entity_converted_to_quotation_mark(self):
self.assertSoupEquals("<p>I said &quot;good day!&quot;</p>",
'<p>I said "good day!"</p>')
def test_out_of_range_entity(self):
expect = u"\N{REPLACEMENT CHARACTER}"
self.assertSoupEquals("&
self.assertSoupEquals("&
self.assertSoupEquals("&
def test_basic_namespaces(self):
markup = b'<html xmlns="http://www.w3.org/1999/xhtml" xmlns:mathml="http://www.w3.org/1998/Math/MathML" xmlns:svg="http://www.w3.org/2000/svg"><head></head><body><mathml:msqrt>4</mathml:msqrt><b svg:fill="red"></b></body></html>'
soup = self.soup(markup)
self.assertEqual(markup, soup.encode())
html = soup.html
self.assertEqual('http://www.w3.org/1999/xhtml', soup.html['xmlns'])
self.assertEqual(
'http://www.w3.org/1998/Math/MathML', soup.html['xmlns:mathml'])
self.assertEqual(
'http://www.w3.org/2000/svg', soup.html['xmlns:svg'])
def test_multivalued_attribute_value_becomes_list(self):
markup = b'<a class="foo bar">'
soup = self.soup(markup)
self.assertEqual(['foo', 'bar'], soup.a['class'])
def test_soupstrainer(self):
strainer = SoupStrainer("b")
soup = self.soup("A <b>bold</b> <meta/> <i>statement</i>",
parse_only=strainer)
self.assertEqual(soup.decode(), "<b>bold</b>")
def test_single_quote_attribute_values_become_double_quotes(self):
self.assertSoupEquals("<foo attr='bar'></foo>",
'<foo attr="bar"></foo>')
def test_attribute_values_with_nested_quotes_are_left_alone(self):
text =
self.assertSoupEquals(text)
def test_attribute_values_with_double_nested_quotes_get_quoted(self):
text =
soup = self.soup(text)
soup.foo['attr'] = 'Brawls happen at "Bob\'s Bar"'
self.assertSoupEquals(
soup.foo.decode(),
)
def test_ampersand_in_attribute_value_gets_escaped(self):
self.assertSoupEquals('<this is="really messed up & stuff"></this>',
'<this is="really messed up &amp; stuff"></this>')
self.assertSoupEquals(
'<a href="http://example.org?a=1&b=2;3">foo</a>',
'<a href="http://example.org?a=1&amp;b=2;3">foo</a>')
def test_escaped_ampersand_in_attribute_value_is_left_alone(self):
self.assertSoupEquals('<a href="http://example.org?a=1&amp;b=2;3"></a>')
def test_entities_in_strings_converted_during_parsing(self):
text = "<p>&lt;&lt;sacr&eacute;&
expected = u"<p>&lt;&lt;sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</p>"
self.assertSoupEquals(text, expected)
def test_smart_quotes_converted_on_the_way_in(self):
quote = b"<p>\x91Foo\x92</p>"
soup = self.soup(quote)
self.assertEqual(
soup.p.string,
u"\N{LEFT SINGLE QUOTATION MARK}Foo\N{RIGHT SINGLE QUOTATION MARK}")
def test_non_breaking_spaces_converted_on_the_way_in(self):
soup = self.soup("<a>&nbsp;&nbsp;</a>")
self.assertEqual(soup.a.string, u"\N{NO-BREAK SPACE}" * 2)
def test_entities_converted_on_the_way_out(self):
text = "<p>&lt;&lt;sacr&eacute;&
expected = u"<p>&lt;&lt;sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</p>".encode("utf-8")
soup = self.soup(text)
self.assertEqual(soup.p.encode("utf-8"), expected)
def test_real_iso_latin_document(self):
unicode_html = u'<html><head><meta content="text/html; charset=ISO-Latin-1" http-equiv="Content-type"/></head><body><p>Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!</p></body></html>'
iso_latin_html = unicode_html.encode("iso-8859-1")
soup = self.soup(iso_latin_html)
result = soup.encode("utf-8")
expected = unicode_html.replace("ISO-Latin-1", "utf-8")
expected = expected.encode("utf-8")
self.assertEqual(result, expected)
def test_real_shift_jis_document(self):
shift_jis_html = (
b'<html><head></head><body><pre>'
b'\x82\xb1\x82\xea\x82\xcdShift-JIS\x82\xc5\x83R\x81[\x83f'
b'\x83B\x83\x93\x83O\x82\xb3\x82\xea\x82\xbd\x93\xfa\x96{\x8c'
b'\xea\x82\xcc\x83t\x83@\x83C\x83\x8b\x82\xc5\x82\xb7\x81B'
b'</pre></body></html>')
unicode_html = shift_jis_html.decode("shift-jis")
soup = self.soup(unicode_html)
self.assertEqual(soup.encode("utf-8"), unicode_html.encode("utf-8"))
self.assertEqual(soup.encode("euc_jp"), unicode_html.encode("euc_jp"))
def test_real_hebrew_document(self):
hebrew_document = b'<html><head><title>Hebrew (ISO 8859-8) in Visual Directionality</title></head><body><h1>Hebrew (ISO 8859-8) in Visual Directionality</h1>\xed\xe5\xec\xf9</body></html>'
soup = self.soup(
hebrew_document, from_encoding="iso8859-8")
self.assertEqual(soup.original_encoding, 'iso8859-8')
self.assertEqual(
soup.encode('utf-8'),
hebrew_document.decode("iso8859-8").encode("utf-8"))
def test_meta_tag_reflects_current_encoding(self):
meta_tag = ('<meta content="text/html; charset=x-sjis" '
'http-equiv="Content-type"/>')
shift_jis_html = (
'<html><head>\n%s\n'
'<meta http-equiv="Content-language" content="ja"/>'
'</head><body>Shift-JIS markup goes here.') % meta_tag
soup = self.soup(shift_jis_html)
parsed_meta = soup.find('meta', {'http-equiv': 'Content-type'})
content = parsed_meta['content']
self.assertEqual('text/html; charset=x-sjis', content)
self.assertTrue(isinstance(content, ContentMetaAttributeValue))
self.assertEqual('text/html; charset=utf8', content.encode("utf8"))
def test_html5_style_meta_tag_reflects_current_encoding(self):
meta_tag = ('<meta id="encoding" charset="x-sjis" />')
shift_jis_html = (
'<html><head>\n%s\n'
'<meta http-equiv="Content-language" content="ja"/>'
'</head><body>Shift-JIS markup goes here.') % meta_tag
soup = self.soup(shift_jis_html)
parsed_meta = soup.find('meta', id="encoding")
charset = parsed_meta['charset']
self.assertEqual('x-sjis', charset)
self.assertTrue(isinstance(charset, CharsetMetaAttributeValue))
self.assertEqual('utf8', charset.encode("utf8"))
def test_tag_with_no_attributes_can_have_attributes_added(self):
data = self.soup("<a>text</a>")
data.a['foo'] = 'bar'
self.assertEqual('<a foo="bar">text</a>', data.a.decode())
class XMLTreeBuilderSmokeTest(object):
def test_docstring_generated(self):
soup = self.soup("<root/>")
self.assertEqual(
soup.encode(), b'<?xml version="1.0" encoding="utf-8"?>\n<root/>')
def test_real_xhtml_document(self):
markup = b
soup = self.soup(markup)
self.assertEqual(
soup.encode("utf-8"), markup)
def test_popping_namespaced_tag(self):
markup = '<rss xmlns:dc="foo"><dc:creator>b</dc:creator><dc:date>2012-07-02T20:33:42Z</dc:date><dc:rights>c</dc:rights><image>d</image></rss>'
soup = self.soup(markup)
self.assertEqual(
unicode(soup.rss), markup)
def test_docstring_includes_correct_encoding(self):
soup = self.soup("<root/>")
self.assertEqual(
soup.encode("latin1"),
b'<?xml version="1.0" encoding="latin1"?>\n<root/>')
def test_large_xml_document(self):
markup = (b'<?xml version="1.0" encoding="utf-8"?>\n<root>'
+ b'0' * (2**12)
+ b'</root>')
soup = self.soup(markup)
self.assertEqual(soup.encode("utf-8"), markup)
def test_tags_are_empty_element_if_and_only_if_they_are_empty(self):
self.assertSoupEquals("<p>", "<p/>")
self.assertSoupEquals("<p>foo</p>")
def test_namespaces_are_preserved(self):
markup = '<root xmlns:a="http://example.com/" xmlns:b="http://example.net/"><a:foo>This tag is in the a namespace</a:foo><b:foo>This tag is in the b namespace</b:foo></root>'
soup = self.soup(markup)
root = soup.root
self.assertEqual("http://example.com/", root['xmlns:a'])
self.assertEqual("http://example.net/", root['xmlns:b'])
def test_closing_namespaced_tag(self):
markup = '<p xmlns:dc="http://purl.org/dc/elements/1.1/"><dc:date>20010504</dc:date></p>'
soup = self.soup(markup)
self.assertEqual(unicode(soup.p), markup)
def test_namespaced_attributes(self):
markup = '<foo xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><bar xsi:schemaLocation="http://www.example.com"/></foo>'
soup = self.soup(markup)
self.assertEqual(unicode(soup.foo), markup)
class HTML5TreeBuilderSmokeTest(HTMLTreeBuilderSmokeTest):
def test_real_xhtml_document(self):
pass
def test_html_tags_have_namespace(self):
markup = "<a>"
soup = self.soup(markup)
self.assertEqual("http://www.w3.org/1999/xhtml", soup.a.namespace)
def test_svg_tags_have_namespace(self):
markup = '<svg><circle/></svg>'
soup = self.soup(markup)
namespace = "http://www.w3.org/2000/svg"
self.assertEqual(namespace, soup.svg.namespace)
self.assertEqual(namespace, soup.circle.namespace)
def test_mathml_tags_have_namespace(self):
markup = '<math><msqrt>5</msqrt></math>'
soup = self.soup(markup)
namespace = 'http://www.w3.org/1998/Math/MathML'
self.assertEqual(namespace, soup.math.namespace)
self.assertEqual(namespace, soup.msqrt.namespace)
def skipIf(condition, reason):
def nothing(test, *args, **kwargs):
return None
def decorator(test_item):
if condition:
return nothing
else:
return test_item
return decorator
from django.test import TestCase
from BaseHTTPServer import HTTPServer, test as simple_http_server_test
from CGIHTTPServer import CGIHTTPRequestHandler
from CGIHTTPServer import _url_collapse_path_split
from sys import stderr
from urlparse import urlparse
class BRATCGIHTTPRequestHandler(CGIHTTPRequestHandler):
def is_cgi(self):
if urlparse(self.path).path.endswith('.cgi'):
self.cgi_info = _url_collapse_path_split(self.path)
return True
else:
return CGIHTTPRequestHandler.is_cgi(self)
def main(args):
try:
try:
port = int(args[1])
except ValueError:
raise TypeError
except TypeError:
print >> stderr, '%s is not a valid port number' % args[1]
return -1
except IndexError:
port = 8000
print >> stderr, 'WARNING: This server is for testing purposes only!'
print >> stderr, ('    You can also use it for trying out brat before '
'deploying on a "real" web server such as Apache.')
print >> stderr, ('    Using this web server to run brat on an open '
'network is a security risk!')
print >> stderr
print >> stderr, 'You can access the test server on:'
print >> stderr
print >> stderr, '    http://localhost:%s/' % port
print >> stderr
simple_http_server_test(BRATCGIHTTPRequestHandler, HTTPServer)
if __name__ == '__main__':
from sys import argv
exit(main(argv))
import unittest
from bs4 import BeautifulSoup
from bs4.builder import (
builder_registry as registry,
HTMLParserTreeBuilder,
TreeBuilderRegistry,
)
try:
from bs4.builder import HTML5TreeBuilder
HTML5LIB_PRESENT = True
except ImportError:
HTML5LIB_PRESENT = False
try:
from bs4.builder import (
LXMLTreeBuilderForXML,
LXMLTreeBuilder,
)
LXML_PRESENT = True
except ImportError:
LXML_PRESENT = False
class BuiltInRegistryTest(unittest.TestCase):
def test_combination(self):
if LXML_PRESENT:
self.assertEqual(registry.lookup('fast', 'html'),
LXMLTreeBuilder)
if LXML_PRESENT:
self.assertEqual(registry.lookup('permissive', 'xml'),
LXMLTreeBuilderForXML)
self.assertEqual(registry.lookup('strict', 'html'),
HTMLParserTreeBuilder)
if HTML5LIB_PRESENT:
self.assertEqual(registry.lookup('html5lib', 'html'),
HTML5TreeBuilder)
def test_lookup_by_markup_type(self):
if LXML_PRESENT:
self.assertEqual(registry.lookup('html'), LXMLTreeBuilder)
self.assertEqual(registry.lookup('xml'), LXMLTreeBuilderForXML)
else:
self.assertEqual(registry.lookup('xml'), None)
if HTML5LIB_PRESENT:
self.assertEqual(registry.lookup('html'), HTML5TreeBuilder)
else:
self.assertEqual(registry.lookup('html'), HTMLParserTreeBuilder)
def test_named_library(self):
if LXML_PRESENT:
self.assertEqual(registry.lookup('lxml', 'xml'),
LXMLTreeBuilderForXML)
self.assertEqual(registry.lookup('lxml', 'html'),
LXMLTreeBuilder)
if HTML5LIB_PRESENT:
self.assertEqual(registry.lookup('html5lib'),
HTML5TreeBuilder)
self.assertEqual(registry.lookup('html.parser'),
HTMLParserTreeBuilder)
def test_beautifulsoup_constructor_does_lookup(self):
BeautifulSoup("", features="html")
BeautifulSoup("", features=["html", "fast"])
self.assertRaises(ValueError, BeautifulSoup,
"", features="no-such-feature")
class RegistryTest(unittest.TestCase):
def setUp(self):
self.registry = TreeBuilderRegistry()
def builder_for_features(self, *feature_list):
cls = type('Builder_' + '_'.join(feature_list),
(object,), {'features' : feature_list})
self.registry.register(cls)
return cls
def test_register_with_no_features(self):
builder = self.builder_for_features()
self.assertEqual(self.registry.lookup('foo'), None)
self.assertEqual(self.registry.lookup(), builder)
def test_register_with_features_makes_lookup_succeed(self):
builder = self.builder_for_features('foo', 'bar')
self.assertEqual(self.registry.lookup('foo'), builder)
self.assertEqual(self.registry.lookup('bar'), builder)
def test_lookup_fails_when_no_builder_implements_feature(self):
builder = self.builder_for_features('foo', 'bar')
self.assertEqual(self.registry.lookup('baz'), None)
def test_lookup_gets_most_recent_registration_when_no_feature_specified(self):
builder1 = self.builder_for_features('foo')
builder2 = self.builder_for_features('bar')
self.assertEqual(self.registry.lookup(), builder2)
def test_lookup_fails_when_no_tree_builders_registered(self):
self.assertEqual(self.registry.lookup(), None)
def test_lookup_gets_most_recent_builder_supporting_all_features(self):
has_one = self.builder_for_features('foo')
has_the_other = self.builder_for_features('bar')
has_both_early = self.builder_for_features('foo', 'bar', 'baz')
has_both_late = self.builder_for_features('foo', 'bar', 'quux')
lacks_one = self.builder_for_features('bar')
has_the_other = self.builder_for_features('foo')
self.assertEqual(self.registry.lookup('foo', 'bar'),
has_both_late)
self.assertEqual(self.registry.lookup('foo', 'bar', 'baz'),
has_both_early)
def test_lookup_fails_when_cannot_reconcile_requested_features(self):
builder1 = self.builder_for_features('foo', 'bar')
builder2 = self.builder_for_features('foo', 'baz')
self.assertEqual(self.registry.lookup('bar', 'baz'), None)
from unittest import TestCase
from util.commons_util.os.child_process import *
class TestChildProcess(TestCase):
def test_simple_exec(self):
self.assertEquals(basic_child_process(),
u'Hello from the child!\n')
def test_poll_status(self):
self.assertEquals(poll_status(), 'Exit status 0')
from unittest import TestCase
from util.commons_util.fundamentals.class_hierarchy import *
class TestProperty(TestCase):
def test_property_setter(self):
r = VoltageResistance(ohms=10)
r.voltage = 10
self.assertEquals(r.current, 1)
class TestDescriptor(TestCase):
def test_grade_descriptor(self):
class Exam(object):
math_grade = GradeDescriptor()
writing_grade = GradeDescriptor()
science_grade = GradeDescriptor()
exam1 = Exam()
exam2 = Exam()
with self.assertRaises(ValueError):
exam1.science_grade = 101
exam1.science_grade = 99
exam2.science_grade = 100
self.assertEquals(exam1.science_grade, 99)
self.assertEquals(exam2.science_grade, 100)
from unittest import TestCase
import pickle
from util.commons_util.fundamentals.pickle.copyreg_demo import *
class TestSerialization(TestCase):
def test_copyreg(self):
state = State()
state.points += 1000
serialized = pickle.dumps(state)
state_after = pickle.loads(serialized)
self.assertEquals(state_after.__dict__,
{'points': 1000, 'lives': 4, 'level': 0})
import random
from unittest import TestCase
from util.commons_util.fundamentals.data_structs import *
class TestDataStructs(TestCase):
def test_argsort(self):
A = [3, 2, 1]
ret = Sorter.argsort(A)
self.assertEqual(ret, [2, 1, 0])
def test_excel_column(self):
col = ExcelColumn()
self.assertEqual(list(col.columns(800))[-1], 'adt')
class TestDisplayer(TestCase):
def test_display(self):
dis = Displayer()
class A(object):
def __init__(self):
self.a = "abc"
self.b = 1.0
class B(object):
def __init__(self):
self.a = A()
self.b = 1.0
b = B()
self.assertEqual(str(dis.dump(b)), '{"a": {"a": "abc", "b": 1.0}, "b": 1.0}')
b_str =
self.assertEqual(dis.display(b), b_str)
class TestSearcher(TestCase):
def test_binary_search(self):
rand_lst = [int(1000*random.random()) for _ in xrange(100)]
target = rand_lst[0]
rand_lst.sort()
def predicate(idx):
if rand_lst[idx]==target:
return 0
elif rand_lst[idx]<target:
return -1
else:
return 1
idx = Searcher.binary_search(0, 100, predicate)
self.assertEqual(target, rand_lst[idx])
class TestWrapper(TestCase):
def test_unpack(self):
x = [random.randint(0, 100) for _ in xrange(100)]
y = [random.randint(0, 100) for _ in xrange(100)]
lst = zip(x, y)
a, b = Wrapper.unpack(lst)
self.assertEqual(a, tuple(x))
self.assertEqual(b, tuple(y))
"Test harness for doctests."
__metaclass__ = type
__all__ = [
'additional_tests',
]
import atexit
import doctest
import os
import unittest
DOCTEST_FLAGS = (
doctest.ELLIPSIS |
doctest.NORMALIZE_WHITESPACE |
doctest.REPORT_NDIFF)
from unittest import TestCase
from util.commons_util.fundamentals.generators import *
class TestGenerator(TestCase):
def test_coroutine(self):
itr = first_coroutine()
itr.next()
self.assertEquals(itr.send(1), "Received: 1")
self.assertEquals(itr.send(2), "Received: 2")
def test_yieldmin(self):
itr = minimize()
next(itr)
self.assertEquals(itr.send(10), 10)
self.assertEquals(itr.send(4), 4)
self.assertEquals(itr.send(22), 4)
self.assertEquals(itr.send(-1), -1)
import warnings
try:
from bs4.builder import HTML5TreeBuilder
HTML5LIB_PRESENT = True
except ImportError, e:
HTML5LIB_PRESENT = False
from bs4.element import SoupStrainer
from bs4.testing import (
HTML5TreeBuilderSmokeTest,
SoupTest,
skipIf,
)
@skipIf(
not HTML5LIB_PRESENT,
"html5lib seems not to be present, not testing its tree builder.")
class HTML5LibBuilderSmokeTest(SoupTest, HTML5TreeBuilderSmokeTest):
@property
def default_builder(self):
return HTML5TreeBuilder()
def test_soupstrainer(self):
strainer = SoupStrainer("b")
markup = "<p>A <b>bold</b> statement.</p>"
with warnings.catch_warnings(record=True) as w:
soup = self.soup(markup, parse_only=strainer)
self.assertEqual(
soup.decode(), self.document_for(markup))
self.assertTrue(
"the html5lib tree builder doesn't support parse_only" in
str(w[0].message))
def test_correctly_nested_tables(self):
markup = ('<table id="1">'
'<tr>'
"<td>Here's another table:"
'<table id="2">'
'<tr><td>foo</td></tr>'
'</table></td>')
self.assertSoupEquals(
markup,
'<table id="1"><tbody><tr><td>Here\'s another table:'
'<table id="2"><tbody><tr><td>foo</td></tr></tbody></table>'
'</td></tr></tbody></table>')
self.assertSoupEquals(
"<table><thead><tr><td>Foo</td></tr></thead>"
"<tbody><tr><td>Bar</td></tr></tbody>"
"<tfoot><tr><td>Baz</td></tr></tfoot></table>")
from bs4.testing import SoupTest, HTMLTreeBuilderSmokeTest
from bs4.builder import HTMLParserTreeBuilder
class HTMLParserTreeBuilderSmokeTest(SoupTest, HTMLTreeBuilderSmokeTest):
@property
def default_builder(self):
return HTMLParserTreeBuilder()
def test_namespaced_system_doctype(self):
pass
def test_namespaced_public_doctype(self):
pass
import re
import warnings
try:
from bs4.builder import LXMLTreeBuilder, LXMLTreeBuilderForXML
LXML_PRESENT = True
except ImportError, e:
LXML_PRESENT = False
from bs4 import (
BeautifulSoup,
BeautifulStoneSoup,
)
from bs4.element import Comment, Doctype, SoupStrainer
from bs4.testing import skipIf
from bs4.tests import test_htmlparser
from bs4.testing import (
HTMLTreeBuilderSmokeTest,
XMLTreeBuilderSmokeTest,
SoupTest,
skipIf,
)
@skipIf(
not LXML_PRESENT,
"lxml seems not to be present, not testing its tree builder.")
class LXMLTreeBuilderSmokeTest(SoupTest, HTMLTreeBuilderSmokeTest):
@property
def default_builder(self):
return LXMLTreeBuilder()
def test_out_of_range_entity(self):
self.assertSoupEquals(
"<p>foo&
self.assertSoupEquals(
"<p>foo&
self.assertSoupEquals(
"<p>foo&
def test_beautifulstonesoup_is_xml_parser(self):
with warnings.catch_warnings(record=False) as w:
soup = BeautifulStoneSoup("<b />")
self.assertEqual(u"<b/>", unicode(soup.b))
def test_real_xhtml_document(self):
markup = b
soup = self.soup(markup)
self.assertEqual(
soup.encode("utf-8").replace(b"\n", b''),
markup.replace(b'\n', b'').replace(
b'<?xml version="1.0" encoding="utf-8"?>', b''))
@skipIf(
not LXML_PRESENT,
"lxml seems not to be present, not testing its XML tree builder.")
class LXMLXMLTreeBuilderSmokeTest(SoupTest, XMLTreeBuilderSmokeTest):
@property
def default_builder(self):
return LXMLTreeBuilderForXML()
import sys
import os
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)),'..'))
from qfc.core import filter_files, get_weight
def _equals(marks_list1, marks_list2):
l1 = sorted(marks_list1)
l2 = sorted(marks_list2)
if len(l1) != len(l2):
return False
for i,_ in enumerate(l1):
if l1[i] != l2[i]:
return False
return True
def test_filter_files():
files = [
'/',
'/a/',
'/b/',
'/a/b',
'/a/b/c',
'/b/a/',
'/b/a/c',
'd',
'da'
]
assert(_equals(filter_files(files,''), ['/','d','da']))
assert(_equals(filter_files(files,'/'), ['/']))
assert(_equals(filter_files(files,'a'), ['/a/', '/b/a/', 'da']))
def test_weight():
assert(get_weight('a','') == 1001)
assert(get_weight('a/','') == 1000)
assert(get_weight('a/b/','') == 2000)
assert(get_weight('a/b/c','') == 3001)
assert(get_weight('a','a')  == 1001)
assert(get_weight('ab','a')  == 1021)
assert(get_weight('bab','a')  == 1111)
assert(get_weight('a_b','a')  == 1011)
assert(get_weight('root/a_b','a')  == 2011)
assert(get_weight('root/a_b_c_d_e_f_g_h_i_j_k','k')  == 2091)
assert(get_weight('a/b/c/d/e/f/g/h/i/j/k','k')  == 10001)
assert(get_weight('a/B/','b') == 2000)
from unittest import TestCase
from util.commons_util.fundamentals.serialization import *
class TestSerialization(TestCase):
def test_todict(self):
class BinaryTree(ToDictMixin):
def __init__(self, value, left=None, right=None):
self.value = value
self.left = left
self.right = right
tree = BinaryTree(10,
left=BinaryTree(7, right=BinaryTree(9)),
right=BinaryTree(13, left=BinaryTree(11)))
self.assertEquals(tree.to_dict(), {'right': {'right': None, 'value': 13, 'left': {'right': None, 'value': 11, 'left': None}}, 'value': 10, 'left': {'right': {'right': None, 'value': 9, 'left': None}, 'value': 7, 'left': None}})
import logging
import unittest
import sys
from bs4 import (
BeautifulSoup,
BeautifulStoneSoup,
)
from bs4.element import (
CharsetMetaAttributeValue,
ContentMetaAttributeValue,
SoupStrainer,
NamespacedAttribute,
)
import bs4.dammit
from bs4.dammit import EntitySubstitution, UnicodeDammit
from bs4.testing import (
SoupTest,
skipIf,
)
import warnings
try:
from bs4.builder import LXMLTreeBuilder, LXMLTreeBuilderForXML
LXML_PRESENT = True
except ImportError, e:
LXML_PRESENT = False
PYTHON_2_PRE_2_7 = (sys.version_info < (2,7))
PYTHON_3_PRE_3_2 = (sys.version_info[0] == 3 and sys.version_info < (3,2))
class TestDeprecatedConstructorArguments(SoupTest):
def test_parseOnlyThese_renamed_to_parse_only(self):
with warnings.catch_warnings(record=True) as w:
soup = self.soup("<a><b></b></a>", parseOnlyThese=SoupStrainer("b"))
msg = str(w[0].message)
self.assertTrue("parseOnlyThese" in msg)
self.assertTrue("parse_only" in msg)
self.assertEqual(b"<b></b>", soup.encode())
def test_fromEncoding_renamed_to_from_encoding(self):
with warnings.catch_warnings(record=True) as w:
utf8 = b"\xc3\xa9"
soup = self.soup(utf8, fromEncoding="utf8")
msg = str(w[0].message)
self.assertTrue("fromEncoding" in msg)
self.assertTrue("from_encoding" in msg)
self.assertEqual("utf8", soup.original_encoding)
def test_unrecognized_keyword_argument(self):
self.assertRaises(
TypeError, self.soup, "<a>", no_such_argument=True)
@skipIf(
not LXML_PRESENT,
"lxml not present, not testing BeautifulStoneSoup.")
def test_beautifulstonesoup(self):
with warnings.catch_warnings(record=True) as w:
soup = BeautifulStoneSoup("<markup>")
self.assertTrue(isinstance(soup, BeautifulSoup))
self.assertTrue("BeautifulStoneSoup class is deprecated")
class TestSelectiveParsing(SoupTest):
def test_parse_with_soupstrainer(self):
markup = "No<b>Yes</b><a>No<b>Yes <c>Yes</c></b>"
strainer = SoupStrainer("b")
soup = self.soup(markup, parse_only=strainer)
self.assertEqual(soup.encode(), b"<b>Yes</b><b>Yes <c>Yes</c></b>")
class TestEntitySubstitution(unittest.TestCase):
def setUp(self):
self.sub = EntitySubstitution
def test_simple_html_substitution(self):
s = u"foo\u2200\N{SNOWMAN}\u00f5bar"
self.assertEqual(self.sub.substitute_html(s),
u"foo&forall;\N{SNOWMAN}&otilde;bar")
def test_smart_quote_substitution(self):
quotes = b"\x91\x92foo\x93\x94"
dammit = UnicodeDammit(quotes)
self.assertEqual(self.sub.substitute_html(dammit.markup),
"&lsquo;&rsquo;foo&ldquo;&rdquo;")
def test_xml_converstion_includes_no_quotes_if_make_quoted_attribute_is_false(self):
s = 'Welcome to "my bar"'
self.assertEqual(self.sub.substitute_xml(s, False), s)
def test_xml_attribute_quoting_normally_uses_double_quotes(self):
self.assertEqual(self.sub.substitute_xml("Welcome", True),
'"Welcome"')
self.assertEqual(self.sub.substitute_xml("Bob's Bar", True),
'"Bob\'s Bar"')
def test_xml_attribute_quoting_uses_single_quotes_when_value_contains_double_quotes(self):
s = 'Welcome to "my bar"'
self.assertEqual(self.sub.substitute_xml(s, True),
"'Welcome to \"my bar\"'")
def test_xml_attribute_quoting_escapes_single_quotes_when_value_contains_both_single_and_double_quotes(self):
s = 'Welcome to "Bob\'s Bar"'
self.assertEqual(
self.sub.substitute_xml(s, True),
'"Welcome to &quot;Bob\'s Bar&quot;"')
def test_xml_quotes_arent_escaped_when_value_is_not_being_quoted(self):
quoted = 'Welcome to "Bob\'s Bar"'
self.assertEqual(self.sub.substitute_xml(quoted), quoted)
def test_xml_quoting_handles_angle_brackets(self):
self.assertEqual(
self.sub.substitute_xml("foo<bar>"),
"foo&lt;bar&gt;")
def test_xml_quoting_handles_ampersands(self):
self.assertEqual(self.sub.substitute_xml("AT&T"), "AT&amp;T")
def test_xml_quoting_ignores_ampersands_when_they_are_part_of_an_entity(self):
self.assertEqual(
self.sub.substitute_xml("&Aacute;T&T"),
"&Aacute;T&amp;T")
def test_quotes_not_html_substituted(self):
text = 'Bob\'s "bar"'
self.assertEqual(self.sub.substitute_html(text), text)
class TestEncodingConversion(SoupTest):
def setUp(self):
super(TestEncodingConversion, self).setUp()
self.unicode_data = u'<html><head><meta charset="utf-8"/></head><body><foo>Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!</foo></body></html>'
self.utf8_data = self.unicode_data.encode("utf-8")
self.assertEqual(
self.utf8_data,
b'<html><head><meta charset="utf-8"/></head><body><foo>Sacr\xc3\xa9 bleu!</foo></body></html>')
def test_ascii_in_unicode_out(self):
ascii = b"<foo>a</foo>"
soup_from_ascii = self.soup(ascii)
unicode_output = soup_from_ascii.decode()
self.assertTrue(isinstance(unicode_output, unicode))
self.assertEqual(unicode_output, self.document_for(ascii.decode()))
self.assertEqual(soup_from_ascii.original_encoding.lower(), "ascii")
def test_unicode_in_unicode_out(self):
soup_from_unicode = self.soup(self.unicode_data)
self.assertEqual(soup_from_unicode.decode(), self.unicode_data)
self.assertEqual(soup_from_unicode.foo.string, u'Sacr\xe9 bleu!')
self.assertEqual(soup_from_unicode.original_encoding, None)
def test_utf8_in_unicode_out(self):
soup_from_utf8 = self.soup(self.utf8_data)
self.assertEqual(soup_from_utf8.decode(), self.unicode_data)
self.assertEqual(soup_from_utf8.foo.string, u'Sacr\xe9 bleu!')
def test_utf8_out(self):
soup_from_unicode = self.soup(self.unicode_data)
self.assertEqual(soup_from_unicode.encode('utf-8'), self.utf8_data)
@skipIf(
PYTHON_2_PRE_2_7 or PYTHON_3_PRE_3_2,
"Bad HTMLParser detected; skipping test of non-ASCII characters in attribute name.")
def test_attribute_name_containing_unicode_characters(self):
markup = u'<div><a \N{SNOWMAN}="snowman"></a></div>'
self.assertEqual(self.soup(markup).div.encode("utf8"), markup.encode("utf8"))
class TestUnicodeDammit(unittest.TestCase):
def test_smart_quotes_to_unicode(self):
markup = b"<foo>\x91\x92\x93\x94</foo>"
dammit = UnicodeDammit(markup)
self.assertEqual(
dammit.unicode_markup, u"<foo>\u2018\u2019\u201c\u201d</foo>")
def test_smart_quotes_to_xml_entities(self):
markup = b"<foo>\x91\x92\x93\x94</foo>"
dammit = UnicodeDammit(markup, smart_quotes_to="xml")
self.assertEqual(
dammit.unicode_markup, "<foo>&
def test_smart_quotes_to_html_entities(self):
markup = b"<foo>\x91\x92\x93\x94</foo>"
dammit = UnicodeDammit(markup, smart_quotes_to="html")
self.assertEqual(
dammit.unicode_markup, "<foo>&lsquo;&rsquo;&ldquo;&rdquo;</foo>")
def test_smart_quotes_to_ascii(self):
markup = b"<foo>\x91\x92\x93\x94</foo>"
dammit = UnicodeDammit(markup, smart_quotes_to="ascii")
self.assertEqual(
dammit.unicode_markup, )
def test_detect_utf8(self):
utf8 = b"\xc3\xa9"
dammit = UnicodeDammit(utf8)
self.assertEqual(dammit.unicode_markup, u'\xe9')
self.assertEqual(dammit.original_encoding.lower(), 'utf-8')
def test_convert_hebrew(self):
hebrew = b"\xed\xe5\xec\xf9"
dammit = UnicodeDammit(hebrew, ["iso-8859-8"])
self.assertEqual(dammit.original_encoding.lower(), 'iso-8859-8')
self.assertEqual(dammit.unicode_markup, u'\u05dd\u05d5\u05dc\u05e9')
def test_dont_see_smart_quotes_where_there_are_none(self):
utf_8 = b"\343\202\261\343\203\274\343\202\277\343\202\244 Watch"
dammit = UnicodeDammit(utf_8)
self.assertEqual(dammit.original_encoding.lower(), 'utf-8')
self.assertEqual(dammit.unicode_markup.encode("utf-8"), utf_8)
def test_ignore_inappropriate_codecs(self):
utf8_data = u"R鐩瞜sm鏋歳g姘搒".encode("utf-8")
dammit = UnicodeDammit(utf8_data, ["iso-8859-8"])
self.assertEqual(dammit.original_encoding.lower(), 'utf-8')
def test_ignore_invalid_codecs(self):
utf8_data = u"R鐩瞜sm鏋歳g姘搒".encode("utf-8")
for bad_encoding in ['.utf8', '...', 'utF---16.!']:
dammit = UnicodeDammit(utf8_data, [bad_encoding])
self.assertEqual(dammit.original_encoding.lower(), 'utf-8')
def test_detect_html5_style_meta_tag(self):
for data in (
b'<html><meta charset="euc-jp" /></html>',
b"<html><meta charset='euc-jp' /></html>",
b"<html><meta charset=euc-jp /></html>",
b"<html><meta charset=euc-jp/></html>"):
dammit = UnicodeDammit(data, is_html=True)
self.assertEqual(
"euc-jp", dammit.original_encoding)
def test_last_ditch_entity_replacement(self):
doc = b
chardet = bs4.dammit.chardet_dammit
logging.disable(logging.WARNING)
try:
def noop(str):
return None
bs4.dammit.chardet_dammit = noop
dammit = UnicodeDammit(doc)
self.assertEqual(True, dammit.contains_replacement_characters)
self.assertTrue(u"\ufffd" in dammit.unicode_markup)
soup = BeautifulSoup(doc, "html.parser")
self.assertTrue(soup.contains_replacement_characters)
finally:
logging.disable(logging.NOTSET)
bs4.dammit.chardet_dammit = chardet
def test_sniffed_xml_encoding(self):
data = b'\xff\xfe<\x00a\x00>\x00\xe1\x00\xe9\x00<\x00/\x00a\x00>\x00'
dammit = UnicodeDammit(data)
self.assertEqual(u"<a>璋╄寘</a>", dammit.unicode_markup)
self.assertEqual("utf-16le", dammit.original_encoding)
def test_detwingle(self):
utf8 = (u"\N{SNOWMAN}" * 3).encode("utf8")
windows_1252 = (
u"\N{LEFT DOUBLE QUOTATION MARK}Hi, I like Windows!"
u"\N{RIGHT DOUBLE QUOTATION MARK}").encode("windows_1252")
doc = utf8 + windows_1252 + utf8
self.assertRaises(UnicodeDecodeError, doc.decode, "utf8")
fixed = UnicodeDammit.detwingle(doc)
self.assertEqual(
u"閳藉啠妲傞埥鍐ｆ窏i, I like Windows!閳ユ績妲傞埥鍐ｆ", fixed.decode("utf8"))
def test_detwingle_ignores_multibyte_characters(self):
for tricky_unicode_char in (
u"\N{LATIN SMALL LIGATURE OE}",
u"\N{LATIN SUBSCRIPT SMALL LETTER X}",
u"\xf0\x90\x90\x93",
):
input = tricky_unicode_char.encode("utf8")
self.assertTrue(input.endswith(b'\x93'))
output = UnicodeDammit.detwingle(input)
self.assertEqual(output, input)
class TestNamedspacedAttribute(SoupTest):
def test_name_may_be_none(self):
a = NamespacedAttribute("xmlns", None)
self.assertEqual(a, "xmlns")
def test_attribute_is_equivalent_to_colon_separated_string(self):
a = NamespacedAttribute("a", "b")
self.assertEqual("a:b", a)
def test_attributes_are_equivalent_if_prefix_and_name_identical(self):
a = NamespacedAttribute("a", "b", "c")
b = NamespacedAttribute("a", "b", "c")
self.assertEqual(a, b)
c = NamespacedAttribute("a", "b", None)
self.assertEqual(a, c)
d = NamespacedAttribute("a", "z", "c")
self.assertNotEqual(a, d)
e = NamespacedAttribute("z", "b", "c")
self.assertNotEqual(a, e)
class TestAttributeValueWithCharsetSubstitution(unittest.TestCase):
def test_content_meta_attribute_value(self):
value = CharsetMetaAttributeValue("euc-jp")
self.assertEqual("euc-jp", value)
self.assertEqual("euc-jp", value.original_value)
self.assertEqual("utf8", value.encode("utf8"))
def test_content_meta_attribute_value(self):
value = ContentMetaAttributeValue("text/html; charset=euc-jp")
self.assertEqual("text/html; charset=euc-jp", value)
self.assertEqual("text/html; charset=euc-jp", value.original_value)
self.assertEqual("text/html; charset=utf8", value.encode("utf8"))
import copy
import pickle
import re
import warnings
from bs4 import BeautifulSoup
from bs4.builder import (
builder_registry,
HTMLParserTreeBuilder,
)
from bs4.element import (
CData,
Doctype,
NavigableString,
SoupStrainer,
Tag,
)
from bs4.testing import (
SoupTest,
skipIf,
)
XML_BUILDER_PRESENT = (builder_registry.lookup("xml") is not None)
LXML_PRESENT = (builder_registry.lookup("lxml") is not None)
class TreeTest(SoupTest):
def assertSelects(self, tags, should_match):
self.assertEqual([tag.string for tag in tags], should_match)
def assertSelectsIDs(self, tags, should_match):
self.assertEqual([tag['id'] for tag in tags], should_match)
class TestFind(TreeTest):
def test_find_tag(self):
soup = self.soup("<a>1</a><b>2</b><a>3</a><b>4</b>")
self.assertEqual(soup.find("b").string, "2")
def test_unicode_text_find(self):
soup = self.soup(u'<h1>R鐩瞜sm鏋歳g姘搒</h1>')
self.assertEqual(soup.find(text=u'R鐩瞜sm鏋歳g姘搒'), u'R鐩瞜sm鏋歳g姘搒')
class TestFindAll(TreeTest):
def test_find_all_text_nodes(self):
soup = self.soup("<html>Foo<b>bar</b>\xbb</html>")
self.assertEqual(soup.find_all(text="bar"), [u"bar"])
self.assertEqual(
soup.find_all(text=["Foo", "bar"]), [u"Foo", u"bar"])
self.assertEqual(soup.find_all(text=re.compile('.*')),
[u"Foo", u"bar", u'\xbb'])
self.assertEqual(soup.find_all(text=True),
[u"Foo", u"bar", u'\xbb'])
def test_find_all_limit(self):
soup = self.soup("<a>1</a><a>2</a><a>3</a><a>4</a><a>5</a>")
self.assertSelects(soup.find_all('a', limit=3), ["1", "2", "3"])
self.assertSelects(soup.find_all('a', limit=1), ["1"])
self.assertSelects(
soup.find_all('a', limit=10), ["1", "2", "3", "4", "5"])
self.assertSelects(
soup.find_all('a', limit=0), ["1", "2", "3", "4", "5"])
def test_calling_a_tag_is_calling_findall(self):
soup = self.soup("<a>1</a><b>2<a id='foo'>3</a></b>")
self.assertSelects(soup('a', limit=1), ["1"])
self.assertSelects(soup.b(id="foo"), ["3"])
def test_find_all_with_self_referential_data_structure_does_not_cause_infinite_recursion(self):
soup = self.soup("<a></a>")
l = []
l.append(l)
self.assertEqual([], soup.find_all(l))
class TestFindAllBasicNamespaces(TreeTest):
def test_find_by_namespaced_name(self):
soup = self.soup('<mathml:msqrt>4</mathml:msqrt><a svg:fill="red">')
self.assertEqual("4", soup.find("mathml:msqrt").string)
self.assertEqual("a", soup.find(attrs= { "svg:fill" : "red" }).name)
class TestFindAllByName(TreeTest):
def setUp(self):
super(TreeTest, self).setUp()
self.tree =  self.soup()
def test_find_all_by_tag_name(self):
self.assertSelects(
self.tree.find_all('a'), ['First tag.', 'Nested tag.'])
def test_find_all_by_name_and_text(self):
self.assertSelects(
self.tree.find_all('a', text='First tag.'), ['First tag.'])
self.assertSelects(
self.tree.find_all('a', text=True), ['First tag.', 'Nested tag.'])
self.assertSelects(
self.tree.find_all('a', text=re.compile("tag")),
['First tag.', 'Nested tag.'])
def test_find_all_on_non_root_element(self):
self.assertSelects(self.tree.c.find_all('a'), ['Nested tag.'])
def test_calling_element_invokes_find_all(self):
self.assertSelects(self.tree('a'), ['First tag.', 'Nested tag.'])
def test_find_all_by_tag_strainer(self):
self.assertSelects(
self.tree.find_all(SoupStrainer('a')),
['First tag.', 'Nested tag.'])
def test_find_all_by_tag_names(self):
self.assertSelects(
self.tree.find_all(['a', 'b']),
['First tag.', 'Second tag.', 'Nested tag.'])
def test_find_all_by_tag_dict(self):
self.assertSelects(
self.tree.find_all({'a' : True, 'b' : True}),
['First tag.', 'Second tag.', 'Nested tag.'])
def test_find_all_by_tag_re(self):
self.assertSelects(
self.tree.find_all(re.compile('^[ab]$')),
['First tag.', 'Second tag.', 'Nested tag.'])
def test_find_all_with_tags_matching_method(self):
def id_matches_name(tag):
return tag.name == tag.get('id')
tree = self.soup()
self.assertSelects(
tree.find_all(id_matches_name), ["Match 1.", "Match 2."])
class TestFindAllByAttribute(TreeTest):
def test_find_all_by_attribute_name(self):
tree = self.soup()
self.assertSelects(tree.find_all(id='first'),
["Matching a.", "Matching b."])
def test_find_all_by_utf8_attribute_value(self):
peace = u"璇愯疁璇囩爾".encode("utf8")
data = u'<a title="璇愯疁璇囩爾"></a>'.encode("utf8")
soup = self.soup(data)
self.assertEqual([soup.a], soup.find_all(title=peace))
self.assertEqual([soup.a], soup.find_all(title=peace.decode("utf8")))
self.assertEqual([soup.a], soup.find_all(title=[peace, "something else"]))
def test_find_all_by_attribute_dict(self):
tree = self.soup()
self.assertSelects(tree.find_all(name='name1'),
["A tag called 'name1'."])
self.assertSelects(tree.find_all(attrs={'name' : 'name1'}),
["Name match."])
self.assertSelects(tree.find_all(attrs={'class' : 'class2'}),
["Class match."])
def test_find_all_by_class(self):
tree = self.soup()
self.assertSelects(tree.find_all('a', class_='1'), ['Class 1.'])
self.assertSelects(tree.find_all('c', class_='3'), ['Class 3 and 4.'])
self.assertSelects(tree.find_all('c', class_='4'), ['Class 3 and 4.'])
self.assertSelects(tree.find_all('a', '1'), ['Class 1.'])
self.assertSelects(tree.find_all(attrs='1'), ['Class 1.', 'Class 1.'])
self.assertSelects(tree.find_all('c', '3'), ['Class 3 and 4.'])
self.assertSelects(tree.find_all('c', '4'), ['Class 3 and 4.'])
def test_find_by_class_when_multiple_classes_present(self):
tree = self.soup("<gar class='foo bar'>Found it</gar>")
f = tree.find_all("gar", class_=re.compile("o"))
self.assertSelects(f, ["Found it"])
f = tree.find_all("gar", class_=re.compile("a"))
self.assertSelects(f, ["Found it"])
f = tree.find_all("gar", class_=re.compile("o b"))
self.assertSelects(f, [])
def test_find_all_with_non_dictionary_for_attrs_finds_by_class(self):
soup = self.soup("<a class='bar'>Found it</a>")
self.assertSelects(soup.find_all("a", re.compile("ba")), ["Found it"])
def big_attribute_value(value):
return len(value) > 3
self.assertSelects(soup.find_all("a", big_attribute_value), [])
def small_attribute_value(value):
return len(value) <= 3
self.assertSelects(
soup.find_all("a", small_attribute_value), ["Found it"])
def test_find_all_with_string_for_attrs_finds_multiple_classes(self):
soup = self.soup('<a class="foo bar"></a><a class="foo"></a>')
a, a2 = soup.find_all("a")
self.assertEqual([a, a2], soup.find_all("a", "foo"))
self.assertEqual([a], soup.find_all("a", "bar"))
self.assertEqual([a], soup.find_all("a", class_="foo bar"))
self.assertEqual([a], soup.find_all("a", "foo bar"))
self.assertEqual([], soup.find_all("a", "bar foo"))
def test_find_all_by_attribute_soupstrainer(self):
tree = self.soup()
strainer = SoupStrainer(attrs={'id' : 'first'})
self.assertSelects(tree.find_all(strainer), ['Match.'])
def test_find_all_with_missing_atribute(self):
tree = self.soup()
self.assertSelects(tree.find_all('a', id=None), ["No ID present."])
def test_find_all_with_defined_attribute(self):
tree = self.soup()
self.assertSelects(
tree.find_all(id=True), ["ID present.", "ID is empty."])
def test_find_all_with_numeric_attribute(self):
tree = self.soup()
expected = ["Unquoted attribute.", "Quoted attribute."]
self.assertSelects(tree.find_all(id=1), expected)
self.assertSelects(tree.find_all(id="1"), expected)
def test_find_all_with_list_attribute_values(self):
tree = self.soup()
self.assertSelects(tree.find_all(id=["1", "3", "4"]),
["1", "3"])
def test_find_all_with_regular_expression_attribute_value(self):
tree = self.soup()
self.assertSelects(tree.find_all(id=re.compile("^a+$")),
["One a.", "Two as."])
def test_find_by_name_and_containing_string(self):
soup = self.soup("<b>foo</b><b>bar</b><a>foo</a>")
a = soup.a
self.assertEqual([a], soup.find_all("a", text="foo"))
self.assertEqual([], soup.find_all("a", text="bar"))
self.assertEqual([], soup.find_all("a", text="bar"))
def test_find_by_name_and_containing_string_when_string_is_buried(self):
soup = self.soup("<a>foo</a><a><b><c>foo</c></b></a>")
self.assertEqual(soup.find_all("a"), soup.find_all("a", text="foo"))
def test_find_by_attribute_and_containing_string(self):
soup = self.soup('<b id="1">foo</b><a id="2">foo</a>')
a = soup.a
self.assertEqual([a], soup.find_all(id=2, text="foo"))
self.assertEqual([], soup.find_all(id=1, text="bar"))
class TestIndex(TreeTest):
def test_index(self):
tree = self.soup()
div = tree.div
for i, element in enumerate(div.contents):
self.assertEqual(i, div.index(element))
self.assertRaises(ValueError, tree.index, 1)
class TestParentOperations(TreeTest):
def setUp(self):
super(TestParentOperations, self).setUp()
self.tree = self.soup()
self.start = self.tree.b
def test_parent(self):
self.assertEqual(self.start.parent['id'], 'bottom')
self.assertEqual(self.start.parent.parent['id'], 'middle')
self.assertEqual(self.start.parent.parent.parent['id'], 'top')
def test_parent_of_top_tag_is_soup_object(self):
top_tag = self.tree.contents[0]
self.assertEqual(top_tag.parent, self.tree)
def test_soup_object_has_no_parent(self):
self.assertEqual(None, self.tree.parent)
def test_find_parents(self):
self.assertSelectsIDs(
self.start.find_parents('ul'), ['bottom', 'middle', 'top'])
self.assertSelectsIDs(
self.start.find_parents('ul', id="middle"), ['middle'])
def test_find_parent(self):
self.assertEqual(self.start.find_parent('ul')['id'], 'bottom')
def test_parent_of_text_element(self):
text = self.tree.find(text="Start here")
self.assertEqual(text.parent.name, 'b')
def test_text_element_find_parent(self):
text = self.tree.find(text="Start here")
self.assertEqual(text.find_parent('ul')['id'], 'bottom')
def test_parent_generator(self):
parents = [parent['id'] for parent in self.start.parents
if parent is not None and 'id' in parent.attrs]
self.assertEqual(parents, ['bottom', 'middle', 'top'])
class ProximityTest(TreeTest):
def setUp(self):
super(TreeTest, self).setUp()
self.tree = self.soup(
'<html id="start"><head></head><body><b id="1">One</b><b id="2">Two</b><b id="3">Three</b></body></html>')
class TestNextOperations(ProximityTest):
def setUp(self):
super(TestNextOperations, self).setUp()
self.start = self.tree.b
def test_next(self):
self.assertEqual(self.start.next_element, "One")
self.assertEqual(self.start.next_element.next_element['id'], "2")
def test_next_of_last_item_is_none(self):
last = self.tree.find(text="Three")
self.assertEqual(last.next_element, None)
def test_next_of_root_is_none(self):
self.assertEqual(self.tree.next_element, None)
def test_find_all_next(self):
self.assertSelects(self.start.find_all_next('b'), ["Two", "Three"])
self.start.find_all_next(id=3)
self.assertSelects(self.start.find_all_next(id=3), ["Three"])
def test_find_next(self):
self.assertEqual(self.start.find_next('b')['id'], '2')
self.assertEqual(self.start.find_next(text="Three"), "Three")
def test_find_next_for_text_element(self):
text = self.tree.find(text="One")
self.assertEqual(text.find_next("b").string, "Two")
self.assertSelects(text.find_all_next("b"), ["Two", "Three"])
def test_next_generator(self):
start = self.tree.find(text="Two")
successors = [node for node in start.next_elements]
tag, contents = successors
self.assertEqual(tag['id'], '3')
self.assertEqual(contents, "Three")
class TestPreviousOperations(ProximityTest):
def setUp(self):
super(TestPreviousOperations, self).setUp()
self.end = self.tree.find(text="Three")
def test_previous(self):
self.assertEqual(self.end.previous_element['id'], "3")
self.assertEqual(self.end.previous_element.previous_element, "Two")
def test_previous_of_first_item_is_none(self):
first = self.tree.find('html')
self.assertEqual(first.previous_element, None)
def test_previous_of_root_is_none(self):
pass
def test_find_all_previous(self):
self.assertSelects(
self.end.find_all_previous('b'), ["Three", "Two", "One"])
self.assertSelects(self.end.find_all_previous(id=1), ["One"])
def test_find_previous(self):
self.assertEqual(self.end.find_previous('b')['id'], '3')
self.assertEqual(self.end.find_previous(text="One"), "One")
def test_find_previous_for_text_element(self):
text = self.tree.find(text="Three")
self.assertEqual(text.find_previous("b").string, "Three")
self.assertSelects(
text.find_all_previous("b"), ["Three", "Two", "One"])
def test_previous_generator(self):
start = self.tree.find(text="One")
predecessors = [node for node in start.previous_elements]
b, body, head, html = predecessors
self.assertEqual(b['id'], '1')
self.assertEqual(body.name, "body")
self.assertEqual(head.name, "head")
self.assertEqual(html.name, "html")
class SiblingTest(TreeTest):
def setUp(self):
super(SiblingTest, self).setUp()
markup =
markup = re.compile("\n\s*").sub("", markup)
self.tree = self.soup(markup)
class TestNextSibling(SiblingTest):
def setUp(self):
super(TestNextSibling, self).setUp()
self.start = self.tree.find(id="1")
def test_next_sibling_of_root_is_none(self):
self.assertEqual(self.tree.next_sibling, None)
def test_next_sibling(self):
self.assertEqual(self.start.next_sibling['id'], '2')
self.assertEqual(self.start.next_sibling.next_sibling['id'], '3')
self.assertEqual(self.start.next_element['id'], '1.1')
def test_next_sibling_may_not_exist(self):
self.assertEqual(self.tree.html.next_sibling, None)
nested_span = self.tree.find(id="1.1")
self.assertEqual(nested_span.next_sibling, None)
last_span = self.tree.find(id="4")
self.assertEqual(last_span.next_sibling, None)
def test_find_next_sibling(self):
self.assertEqual(self.start.find_next_sibling('span')['id'], '2')
def test_next_siblings(self):
self.assertSelectsIDs(self.start.find_next_siblings("span"),
['2', '3', '4'])
self.assertSelectsIDs(self.start.find_next_siblings(id='3'), ['3'])
def test_next_sibling_for_text_element(self):
soup = self.soup("Foo<b>bar</b>baz")
start = soup.find(text="Foo")
self.assertEqual(start.next_sibling.name, 'b')
self.assertEqual(start.next_sibling.next_sibling, 'baz')
self.assertSelects(start.find_next_siblings('b'), ['bar'])
self.assertEqual(start.find_next_sibling(text="baz"), "baz")
self.assertEqual(start.find_next_sibling(text="nonesuch"), None)
class TestPreviousSibling(SiblingTest):
def setUp(self):
super(TestPreviousSibling, self).setUp()
self.end = self.tree.find(id="4")
def test_previous_sibling_of_root_is_none(self):
self.assertEqual(self.tree.previous_sibling, None)
def test_previous_sibling(self):
self.assertEqual(self.end.previous_sibling['id'], '3')
self.assertEqual(self.end.previous_sibling.previous_sibling['id'], '2')
self.assertEqual(self.end.previous_element['id'], '3.1')
def test_previous_sibling_may_not_exist(self):
self.assertEqual(self.tree.html.previous_sibling, None)
nested_span = self.tree.find(id="1.1")
self.assertEqual(nested_span.previous_sibling, None)
first_span = self.tree.find(id="1")
self.assertEqual(first_span.previous_sibling, None)
def test_find_previous_sibling(self):
self.assertEqual(self.end.find_previous_sibling('span')['id'], '3')
def test_previous_siblings(self):
self.assertSelectsIDs(self.end.find_previous_siblings("span"),
['3', '2', '1'])
self.assertSelectsIDs(self.end.find_previous_siblings(id='1'), ['1'])
def test_previous_sibling_for_text_element(self):
soup = self.soup("Foo<b>bar</b>baz")
start = soup.find(text="baz")
self.assertEqual(start.previous_sibling.name, 'b')
self.assertEqual(start.previous_sibling.previous_sibling, 'Foo')
self.assertSelects(start.find_previous_siblings('b'), ['bar'])
self.assertEqual(start.find_previous_sibling(text="Foo"), "Foo")
self.assertEqual(start.find_previous_sibling(text="nonesuch"), None)
class TestTagCreation(SoupTest):
def test_new_tag(self):
soup = self.soup("")
new_tag = soup.new_tag("foo", bar="baz")
self.assertTrue(isinstance(new_tag, Tag))
self.assertEqual("foo", new_tag.name)
self.assertEqual(dict(bar="baz"), new_tag.attrs)
self.assertEqual(None, new_tag.parent)
def test_tag_inherits_self_closing_rules_from_builder(self):
if XML_BUILDER_PRESENT:
xml_soup = BeautifulSoup("", "xml")
xml_br = xml_soup.new_tag("br")
xml_p = xml_soup.new_tag("p")
self.assertEqual(b"<br/>", xml_br.encode())
self.assertEqual(b"<p/>", xml_p.encode())
html_soup = BeautifulSoup("", "html")
html_br = html_soup.new_tag("br")
html_p = html_soup.new_tag("p")
self.assertEqual(b"<br/>", html_br.encode())
self.assertEqual(b"<p></p>", html_p.encode())
def test_new_string_creates_navigablestring(self):
soup = self.soup("")
s = soup.new_string("foo")
self.assertEqual("foo", s)
self.assertTrue(isinstance(s, NavigableString))
class TestTreeModification(SoupTest):
def test_attribute_modification(self):
soup = self.soup('<a id="1"></a>')
soup.a['id'] = 2
self.assertEqual(soup.decode(), self.document_for('<a id="2"></a>'))
del(soup.a['id'])
self.assertEqual(soup.decode(), self.document_for('<a></a>'))
soup.a['id2'] = 'foo'
self.assertEqual(soup.decode(), self.document_for('<a id2="foo"></a>'))
def test_new_tag_creation(self):
builder = builder_registry.lookup('html')()
soup = self.soup("<body></body>", builder=builder)
a = Tag(soup, builder, 'a')
ol = Tag(soup, builder, 'ol')
a['href'] = 'http://foo.com/'
soup.body.insert(0, a)
soup.body.insert(1, ol)
self.assertEqual(
soup.body.encode(),
b'<body><a href="http://foo.com/"></a><ol></ol></body>')
def test_append_to_contents_moves_tag(self):
doc =
soup = self.soup(doc)
second_para = soup.find(id='2')
bold = soup.b
soup.find(id='2').append(soup.b)
self.assertEqual(bold.parent, second_para)
self.assertEqual(
soup.decode(), self.document_for(
'<p id="1">Don\'t leave me .</p>\n'
'<p id="2">Don\'t leave!<b>here</b></p>'))
def test_replace_with_returns_thing_that_was_replaced(self):
text = "<a></a><b><c></c></b>"
soup = self.soup(text)
a = soup.a
new_a = a.replace_with(soup.c)
self.assertEqual(a, new_a)
def test_unwrap_returns_thing_that_was_replaced(self):
text = "<a><b></b><c></c></a>"
soup = self.soup(text)
a = soup.a
new_a = a.unwrap()
self.assertEqual(a, new_a)
def test_replace_tag_with_itself(self):
text = "<a><b></b><c>Foo<d></d></c></a><a><e></e></a>"
soup = self.soup(text)
c = soup.c
soup.c.replace_with(c)
self.assertEqual(soup.decode(), self.document_for(text))
def test_replace_tag_with_its_parent_raises_exception(self):
text = "<a><b></b></a>"
soup = self.soup(text)
self.assertRaises(ValueError, soup.b.replace_with, soup.a)
def test_insert_tag_into_itself_raises_exception(self):
text = "<a><b></b></a>"
soup = self.soup(text)
self.assertRaises(ValueError, soup.a.insert, 0, soup.a)
def test_replace_with_maintains_next_element_throughout(self):
soup = self.soup('<p><a>one</a><b>three</b></p>')
a = soup.a
b = a.contents[0]
a.insert(1, "two")
left, right = a.contents
left.replaceWith('')
right.replaceWith('')
self.assertEqual("three", soup.b.string)
def test_replace_final_node(self):
soup = self.soup("<b>Argh!</b>")
soup.find(text="Argh!").replace_with("Hooray!")
new_text = soup.find(text="Hooray!")
b = soup.b
self.assertEqual(new_text.previous_element, b)
self.assertEqual(new_text.parent, b)
self.assertEqual(new_text.previous_element.next_element, new_text)
self.assertEqual(new_text.next_element, None)
def test_consecutive_text_nodes(self):
soup = self.soup("<a><b>Argh!</b><c></c></a>")
soup.b.insert(1, "Hooray!")
self.assertEqual(
soup.decode(), self.document_for(
"<a><b>Argh!Hooray!</b><c></c></a>"))
new_text = soup.find(text="Hooray!")
self.assertEqual(new_text.previous_element, "Argh!")
self.assertEqual(new_text.previous_element.next_element, new_text)
self.assertEqual(new_text.previous_sibling, "Argh!")
self.assertEqual(new_text.previous_sibling.next_sibling, new_text)
self.assertEqual(new_text.next_sibling, None)
self.assertEqual(new_text.next_element, soup.c)
def test_insert_string(self):
soup = self.soup("<a></a>")
soup.a.insert(0, "bar")
soup.a.insert(0, "foo")
self.assertEqual(["foo", "bar"], soup.a.contents)
self.assertEqual(soup.a.contents[0].next_element, "bar")
def test_insert_tag(self):
builder = self.default_builder
soup = self.soup(
"<a><b>Find</b><c>lady!</c><d></d></a>", builder=builder)
magic_tag = Tag(soup, builder, 'magictag')
magic_tag.insert(0, "the")
soup.a.insert(1, magic_tag)
self.assertEqual(
soup.decode(), self.document_for(
"<a><b>Find</b><magictag>the</magictag><c>lady!</c><d></d></a>"))
b_tag = soup.b
self.assertEqual(b_tag.next_sibling, magic_tag)
self.assertEqual(magic_tag.previous_sibling, b_tag)
find = b_tag.find(text="Find")
self.assertEqual(find.next_element, magic_tag)
self.assertEqual(magic_tag.previous_element, find)
c_tag = soup.c
self.assertEqual(magic_tag.next_sibling, c_tag)
self.assertEqual(c_tag.previous_sibling, magic_tag)
the = magic_tag.find(text="the")
self.assertEqual(the.parent, magic_tag)
self.assertEqual(the.next_element, c_tag)
self.assertEqual(c_tag.previous_element, the)
def test_append_child_thats_already_at_the_end(self):
data = "<a><b></b></a>"
soup = self.soup(data)
soup.a.append(soup.b)
self.assertEqual(data, soup.decode())
def test_move_tag_to_beginning_of_parent(self):
data = "<a><b></b><c></c><d></d></a>"
soup = self.soup(data)
soup.a.insert(0, soup.d)
self.assertEqual("<a><d></d><b></b><c></c></a>", soup.decode())
def test_insert_works_on_empty_element_tag(self):
soup = self.soup("<br/>")
soup.br.insert(1, "Contents")
self.assertEqual(str(soup.br), "<br>Contents</br>")
def test_insert_before(self):
soup = self.soup("<a>foo</a><b>bar</b>")
soup.b.insert_before("BAZ")
soup.a.insert_before("QUUX")
self.assertEqual(
soup.decode(), self.document_for("QUUX<a>foo</a>BAZ<b>bar</b>"))
soup.a.insert_before(soup.b)
self.assertEqual(
soup.decode(), self.document_for("QUUX<b>bar</b><a>foo</a>BAZ"))
def test_insert_after(self):
soup = self.soup("<a>foo</a><b>bar</b>")
soup.b.insert_after("BAZ")
soup.a.insert_after("QUUX")
self.assertEqual(
soup.decode(), self.document_for("<a>foo</a>QUUX<b>bar</b>BAZ"))
soup.b.insert_after(soup.a)
self.assertEqual(
soup.decode(), self.document_for("QUUX<b>bar</b><a>foo</a>BAZ"))
def test_insert_after_raises_exception_if_after_has_no_meaning(self):
soup = self.soup("")
tag = soup.new_tag("a")
string = soup.new_string("")
self.assertRaises(ValueError, string.insert_after, tag)
self.assertRaises(NotImplementedError, soup.insert_after, tag)
self.assertRaises(ValueError, tag.insert_after, tag)
def test_insert_before_raises_notimplementederror_if_before_has_no_meaning(self):
soup = self.soup("")
tag = soup.new_tag("a")
string = soup.new_string("")
self.assertRaises(ValueError, string.insert_before, tag)
self.assertRaises(NotImplementedError, soup.insert_before, tag)
self.assertRaises(ValueError, tag.insert_before, tag)
def test_replace_with(self):
soup = self.soup(
"<p>There's <b>no</b> business like <b>show</b> business</p>")
no, show = soup.find_all('b')
show.replace_with(no)
self.assertEqual(
soup.decode(),
self.document_for(
"<p>There's  business like <b>no</b> business</p>"))
self.assertEqual(show.parent, None)
self.assertEqual(no.parent, soup.p)
self.assertEqual(no.next_element, "no")
self.assertEqual(no.next_sibling, " business")
def test_replace_first_child(self):
data = "<a><b></b><c></c></a>"
soup = self.soup(data)
soup.b.replace_with(soup.c)
self.assertEqual("<a><c></c></a>", soup.decode())
def test_replace_last_child(self):
data = "<a><b></b><c></c></a>"
soup = self.soup(data)
soup.c.replace_with(soup.b)
self.assertEqual("<a><b></b></a>", soup.decode())
def test_nested_tag_replace_with(self):
soup = self.soup(
)
remove_tag = soup.b
move_tag = soup.f
remove_tag.replace_with(move_tag)
self.assertEqual(
soup.decode(), self.document_for(
"<a>We<f>refuse</f></a><e>to<g>service</g></e>"))
self.assertEqual(remove_tag.parent, None)
self.assertEqual(remove_tag.find(text="right").next_element, None)
self.assertEqual(remove_tag.previous_element, None)
self.assertEqual(remove_tag.next_sibling, None)
self.assertEqual(remove_tag.previous_sibling, None)
self.assertEqual(move_tag.parent, soup.a)
self.assertEqual(move_tag.previous_element, "We")
self.assertEqual(move_tag.next_element.next_element, soup.e)
self.assertEqual(move_tag.next_sibling, None)
to_text = soup.find(text="to")
g_tag = soup.g
self.assertEqual(to_text.next_element, g_tag)
self.assertEqual(to_text.next_sibling, g_tag)
self.assertEqual(g_tag.previous_element, to_text)
self.assertEqual(g_tag.previous_sibling, to_text)
def test_unwrap(self):
tree = self.soup()
tree.em.unwrap()
self.assertEqual(tree.em, None)
self.assertEqual(tree.p.text, "Unneeded formatting is unneeded")
def test_wrap(self):
soup = self.soup("I wish I was bold.")
value = soup.string.wrap(soup.new_tag("b"))
self.assertEqual(value.decode(), "<b>I wish I was bold.</b>")
self.assertEqual(
soup.decode(), self.document_for("<b>I wish I was bold.</b>"))
def test_wrap_extracts_tag_from_elsewhere(self):
soup = self.soup("<b></b>I wish I was bold.")
soup.b.next_sibling.wrap(soup.b)
self.assertEqual(
soup.decode(), self.document_for("<b>I wish I was bold.</b>"))
def test_wrap_puts_new_contents_at_the_end(self):
soup = self.soup("<b>I like being bold.</b>I wish I was bold.")
soup.b.next_sibling.wrap(soup.b)
self.assertEqual(2, len(soup.b.contents))
self.assertEqual(
soup.decode(), self.document_for(
"<b>I like being bold.I wish I was bold.</b>"))
def test_extract(self):
soup = self.soup(
'<html><body>Some content. <div id="nav">Nav crap</div> More content.</body></html>')
self.assertEqual(len(soup.body.contents), 3)
extracted = soup.find(id="nav").extract()
self.assertEqual(
soup.decode(), "<html><body>Some content.  More content.</body></html>")
self.assertEqual(extracted.decode(), '<div id="nav">Nav crap</div>')
self.assertEqual(len(soup.body.contents), 2)
self.assertEqual(extracted.parent, None)
self.assertEqual(extracted.previous_element, None)
self.assertEqual(extracted.next_element.next_element, None)
content_1 = soup.find(text="Some content. ")
content_2 = soup.find(text=" More content.")
self.assertEqual(content_1.next_element, content_2)
self.assertEqual(content_1.next_sibling, content_2)
self.assertEqual(content_2.previous_element, content_1)
self.assertEqual(content_2.previous_sibling, content_1)
def test_extract_distinguishes_between_identical_strings(self):
soup = self.soup("<a>foo</a><b>bar</b>")
foo_1 = soup.a.string
bar_1 = soup.b.string
foo_2 = soup.new_string("foo")
bar_2 = soup.new_string("bar")
soup.a.append(foo_2)
soup.b.append(bar_2)
foo_1.extract()
bar_2.extract()
self.assertEqual(foo_2, soup.a.string)
self.assertEqual(bar_2, soup.b.string)
def test_clear(self):
soup = self.soup("<p><a>String <em>Italicized</em></a> and another</p>")
a = soup.a
soup.p.clear()
self.assertEqual(len(soup.p.contents), 0)
self.assertTrue(hasattr(a, "contents"))
em = a.em
a.clear(decompose=True)
self.assertFalse(hasattr(em, "contents"))
def test_string_set(self):
soup = self.soup("<a></a> <b><c></c></b>")
soup.a.string = "foo"
self.assertEqual(soup.a.contents, ["foo"])
soup.b.string = "bar"
self.assertEqual(soup.b.contents, ["bar"])
def test_string_set_does_not_affect_original_string(self):
soup = self.soup("<a><b>foo</b><c>bar</c>")
soup.b.string = soup.c.string
self.assertEqual(soup.a.encode(), b"<a><b>bar</b><c>bar</c></a>")
def test_set_string_preserves_class_of_string(self):
soup = self.soup("<a></a>")
cdata = CData("foo")
soup.a.string = cdata
self.assertTrue(isinstance(soup.a.string, CData))
class TestElementObjects(SoupTest):
def test_len(self):
soup = self.soup("<top>1<b>2</b>3</top>")
self.assertEqual(len(soup.contents), 1)
self.assertEqual(len(soup), 1)
self.assertEqual(len(soup.top), 3)
self.assertEqual(len(soup.top.contents), 3)
def test_member_access_invokes_find(self):
soup = self.soup('<b><i></i></b>')
self.assertEqual(soup.b, soup.find('b'))
self.assertEqual(soup.b.i, soup.find('b').find('i'))
self.assertEqual(soup.a, None)
def test_deprecated_member_access(self):
soup = self.soup('<b><i></i></b>')
with warnings.catch_warnings(record=True) as w:
tag = soup.bTag
self.assertEqual(soup.b, tag)
self.assertEqual(
'.bTag is deprecated, use .find("b") instead.',
str(w[0].message))
def test_has_attr(self):
soup = self.soup("<foo attr='bar'>")
self.assertTrue(soup.foo.has_attr('attr'))
self.assertFalse(soup.foo.has_attr('attr2'))
def test_attributes_come_out_in_alphabetical_order(self):
markup = '<b a="1" z="5" m="3" f="2" y="4"></b>'
self.assertSoupEquals(markup, '<b a="1" f="2" m="3" y="4" z="5"></b>')
def test_string(self):
soup = self.soup("<b>foo</b>")
self.assertEqual(soup.b.string, 'foo')
def test_empty_tag_has_no_string(self):
soup = self.soup("<b></b>")
self.assertEqual(soup.b.string, None)
def test_tag_with_multiple_children_has_no_string(self):
soup = self.soup("<a>foo<b></b><b></b></b>")
self.assertEqual(soup.b.string, None)
soup = self.soup("<a>foo<b></b>bar</b>")
self.assertEqual(soup.b.string, None)
soup = self.soup("<a>foo</b>")
soup.a.insert(1, "bar")
self.assertEqual(soup.a.string, None)
def test_tag_with_recursive_string_has_string(self):
soup = self.soup("<a><b>foo</b></a>")
self.assertEqual(soup.a.string, "foo")
self.assertEqual(soup.string, "foo")
def test_lack_of_string(self):
soup = self.soup("<b>f<i>e</i>o</b>")
self.assertFalse(soup.b.string)
soup = self.soup("<b></b>")
self.assertFalse(soup.b.string)
def test_all_text(self):
soup = self.soup("<a>a<b>r</b>   <r> t </r></a>")
self.assertEqual(soup.a.text, "ar  t ")
self.assertEqual(soup.a.get_text(strip=True), "art")
self.assertEqual(soup.a.get_text(","), "a,r, , t ")
self.assertEqual(soup.a.get_text(",", strip=True), "a,r,t")
class TestCDAtaListAttributes(SoupTest):
def test_single_value_becomes_list(self):
soup = self.soup("<a class='foo'>")
self.assertEqual(["foo"],soup.a['class'])
def test_multiple_values_becomes_list(self):
soup = self.soup("<a class='foo bar'>")
self.assertEqual(["foo", "bar"], soup.a['class'])
def test_multiple_values_separated_by_weird_whitespace(self):
soup = self.soup("<a class='foo\tbar\nbaz'>")
self.assertEqual(["foo", "bar", "baz"],soup.a['class'])
def test_attributes_joined_into_string_on_output(self):
soup = self.soup("<a class='foo\tbar'>")
self.assertEqual(b'<a class="foo bar"></a>', soup.a.encode())
def test_accept_charset(self):
soup = self.soup('<form accept-charset="ISO-8859-1 UTF-8">')
self.assertEqual(['ISO-8859-1', 'UTF-8'], soup.form['accept-charset'])
def test_cdata_attribute_applying_only_to_one_tag(self):
data = '<a accept-charset="ISO-8859-1 UTF-8"></a>'
soup = self.soup(data)
self.assertEqual('ISO-8859-1 UTF-8', soup.a['accept-charset'])
class TestPersistence(SoupTest):
"Testing features like pickle and deepcopy."
def setUp(self):
super(TestPersistence, self).setUp()
self.page =
self.tree = self.soup(self.page)
def test_pickle_and_unpickle_identity(self):
dumped = pickle.dumps(self.tree, 2)
loaded = pickle.loads(dumped)
self.assertEqual(loaded.__class__, BeautifulSoup)
self.assertEqual(loaded.decode(), self.tree.decode())
def test_deepcopy_identity(self):
copied = copy.deepcopy(self.tree)
self.assertEqual(copied.decode(), self.tree.decode())
def test_unicode_pickle(self):
html = u"<b>\N{SNOWMAN}</b>"
soup = self.soup(html)
dumped = pickle.dumps(soup, pickle.HIGHEST_PROTOCOL)
loaded = pickle.loads(dumped)
self.assertEqual(loaded.decode(), soup.decode())
class TestSubstitutions(SoupTest):
def test_default_formatter_is_minimal(self):
markup = u"<b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"
soup = self.soup(markup)
decoded = soup.decode(formatter="minimal")
self.assertEqual(
decoded,
self.document_for(
u"<b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"))
def test_formatter_html(self):
markup = u"<b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"
soup = self.soup(markup)
decoded = soup.decode(formatter="html")
self.assertEqual(
decoded,
self.document_for("<b>&lt;&lt;Sacr&eacute; bleu!&gt;&gt;</b>"))
def test_formatter_minimal(self):
markup = u"<b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"
soup = self.soup(markup)
decoded = soup.decode(formatter="minimal")
self.assertEqual(
decoded,
self.document_for(
u"<b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"))
def test_formatter_null(self):
markup = u"<b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"
soup = self.soup(markup)
decoded = soup.decode(formatter=None)
self.assertEqual(decoded,
self.document_for(u"<b><<Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!>></b>"))
def test_formatter_custom(self):
markup = u"<b>&lt;foo&gt;</b><b>bar</b>"
soup = self.soup(markup)
decoded = soup.decode(formatter = lambda x: x.upper())
self.assertEqual(
decoded,
self.document_for(u"<b><FOO></b><b>BAR</b>"))
def test_formatter_is_run_on_attribute_values(self):
markup = u'<a href="http://a.com?a=b&c=鑼">e</a>'
soup = self.soup(markup)
a = soup.a
expect_minimal = u'<a href="http://a.com?a=b&amp;c=鑼">e</a>'
self.assertEqual(expect_minimal, a.decode())
self.assertEqual(expect_minimal, a.decode(formatter="minimal"))
expect_html = u'<a href="http://a.com?a=b&amp;c=&eacute;">e</a>'
self.assertEqual(expect_html, a.decode(formatter="html"))
self.assertEqual(markup, a.decode(formatter=None))
expect_upper = u'<a href="HTTP://A.COM?A=B&C=鑴">E</a>'
self.assertEqual(expect_upper, a.decode(formatter=lambda x: x.upper()))
def test_prettify_accepts_formatter(self):
soup = BeautifulSoup("<html><body>foo</body></html>")
pretty = soup.prettify(formatter = lambda x: x.upper())
self.assertTrue("FOO" in pretty)
def test_prettify_outputs_unicode_by_default(self):
soup = self.soup("<a></a>")
self.assertEqual(unicode, type(soup.prettify()))
def test_prettify_can_encode_data(self):
soup = self.soup("<a></a>")
self.assertEqual(bytes, type(soup.prettify("utf-8")))
def test_html_entity_substitution_off_by_default(self):
markup = u"<b>Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!</b>"
soup = self.soup(markup)
encoded = soup.b.encode("utf-8")
self.assertEqual(encoded, markup.encode('utf-8'))
def test_encoding_substitution(self):
meta_tag = ('<meta content="text/html; charset=x-sjis" '
'http-equiv="Content-type"/>')
soup = self.soup(meta_tag)
self.assertEqual(soup.meta['content'], 'text/html; charset=x-sjis')
utf_8 = soup.encode("utf-8")
self.assertTrue(b"charset=utf-8" in utf_8)
euc_jp = soup.encode("euc_jp")
self.assertTrue(b"charset=euc_jp" in euc_jp)
shift_jis = soup.encode("shift-jis")
self.assertTrue(b"charset=shift-jis" in shift_jis)
utf_16_u = soup.encode("utf-16").decode("utf-16")
self.assertTrue("charset=utf-16" in utf_16_u)
def test_encoding_substitution_doesnt_happen_if_tag_is_strained(self):
markup = ('<head><meta content="text/html; charset=x-sjis" '
'http-equiv="Content-type"/></head><pre>foo</pre>')
strainer = SoupStrainer('pre')
soup = self.soup(markup, parse_only=strainer)
self.assertEqual(soup.contents[0].name, 'pre')
class TestEncoding(SoupTest):
def test_unicode_string_can_be_encoded(self):
html = u"<b>\N{SNOWMAN}</b>"
soup = self.soup(html)
self.assertEqual(soup.b.string.encode("utf-8"),
u"\N{SNOWMAN}".encode("utf-8"))
def test_tag_containing_unicode_string_can_be_encoded(self):
html = u"<b>\N{SNOWMAN}</b>"
soup = self.soup(html)
self.assertEqual(
soup.b.encode("utf-8"), html.encode("utf-8"))
def test_encoding_substitutes_unrecognized_characters_by_default(self):
html = u"<b>\N{SNOWMAN}</b>"
soup = self.soup(html)
self.assertEqual(soup.b.encode("ascii"), b"<b>&
def test_encoding_can_be_made_strict(self):
html = u"<b>\N{SNOWMAN}</b>"
soup = self.soup(html)
self.assertRaises(
UnicodeEncodeError, soup.encode, "ascii", errors="strict")
def test_decode_contents(self):
html = u"<b>\N{SNOWMAN}</b>"
soup = self.soup(html)
self.assertEqual(u"\N{SNOWMAN}", soup.b.decode_contents())
def test_encode_contents(self):
html = u"<b>\N{SNOWMAN}</b>"
soup = self.soup(html)
self.assertEqual(
u"\N{SNOWMAN}".encode("utf8"), soup.b.encode_contents(
encoding="utf8"))
def test_deprecated_renderContents(self):
html = u"<b>\N{SNOWMAN}</b>"
soup = self.soup(html)
self.assertEqual(
u"\N{SNOWMAN}".encode("utf8"), soup.b.renderContents())
class TestNavigableStringSubclasses(SoupTest):
def test_cdata(self):
soup = self.soup("")
cdata = CData("foo")
soup.insert(1, cdata)
self.assertEqual(str(soup), "<![CDATA[foo]]>")
self.assertEqual(soup.find(text="foo"), "foo")
self.assertEqual(soup.contents[0], "foo")
def test_cdata_is_never_formatted(self):
self.count = 0
def increment(*args):
self.count += 1
return "BITTER FAILURE"
soup = self.soup("")
cdata = CData("<><><>")
soup.insert(1, cdata)
self.assertEqual(
b"<![CDATA[<><><>]]>", soup.encode(formatter=increment))
self.assertEqual(1, self.count)
def test_doctype_ends_in_newline(self):
doctype = Doctype("foo")
soup = self.soup("")
soup.insert(1, doctype)
self.assertEqual(soup.encode(), b"<!DOCTYPE foo>\n")
class TestSoupSelector(TreeTest):
HTML =
def setUp(self):
self.soup = BeautifulSoup(self.HTML)
def assertSelects(self, selector, expected_ids):
el_ids = [el['id'] for el in self.soup.select(selector)]
el_ids.sort()
expected_ids.sort()
self.assertEqual(expected_ids, el_ids,
"Selector %s, expected [%s], got [%s]" % (
selector, ', '.join(expected_ids), ', '.join(el_ids)
)
)
assertSelect = assertSelects
def assertSelectMultiple(self, *tests):
for selector, expected_ids in tests:
self.assertSelect(selector, expected_ids)
def test_one_tag_one(self):
els = self.soup.select('title')
self.assertEqual(len(els), 1)
self.assertEqual(els[0].name, 'title')
self.assertEqual(els[0].contents, [u'The title'])
def test_one_tag_many(self):
els = self.soup.select('div')
self.assertEqual(len(els), 3)
for div in els:
self.assertEqual(div.name, 'div')
def test_tag_in_tag_one(self):
els = self.soup.select('div div')
self.assertSelects('div div', ['inner'])
def test_tag_in_tag_many(self):
for selector in ('html div', 'html body div', 'body div'):
self.assertSelects(selector, ['main', 'inner', 'footer'])
def test_tag_no_match(self):
self.assertEqual(len(self.soup.select('del')), 0)
def test_invalid_tag(self):
self.assertEqual(len(self.soup.select('tag%t')), 0)
def test_header_tags(self):
self.assertSelectMultiple(
('h1', ['header1']),
('h2', ['header2', 'header3']),
)
def test_class_one(self):
for selector in ('.onep', 'p.onep', 'html p.onep'):
els = self.soup.select(selector)
self.assertEqual(len(els), 1)
self.assertEqual(els[0].name, 'p')
self.assertEqual(els[0]['class'], ['onep'])
def test_class_mismatched_tag(self):
els = self.soup.select('div.onep')
self.assertEqual(len(els), 0)
def test_one_id(self):
for selector in ('div
self.assertSelects(selector, ['inner'])
def test_bad_id(self):
els = self.soup.select('#doesnotexist')
self.assertEqual(len(els), 0)
def test_items_in_id(self):
els = self.soup.select('div
self.assertEqual(len(els), 3)
for el in els:
self.assertEqual(el.name, 'p')
self.assertEqual(els[1]['class'], ['onep'])
self.assertFalse(els[0].has_key('class'))
def test_a_bunch_of_emptys(self):
for selector in ('div
self.assertEqual(len(self.soup.select(selector)), 0)
def test_multi_class_support(self):
for selector in ('.class1', 'p.class1', '.class2', 'p.class2',
'.class3', 'p.class3', 'html p.class2', 'div
self.assertSelects(selector, ['pmulti'])
def test_multi_class_selection(self):
for selector in ('.class1.class3', '.class3.class2',
'.class1.class2.class3'):
self.assertSelects(selector, ['pmulti'])
def test_child_selector(self):
self.assertSelects('.s1 > a', ['s1a1', 's1a2'])
self.assertSelects('.s1 > a span', ['s1a2s1'])
def test_attribute_equals(self):
self.assertSelectMultiple(
('p[class="onep"]', ['p1']),
('p[id="p1"]', ['p1']),
('[class="onep"]', ['p1']),
('[id="p1"]', ['p1']),
('link[rel="stylesheet"]', ['l1']),
('link[type="text/css"]', ['l1']),
('link[href="blah.css"]', ['l1']),
('link[href="no-blah.css"]', []),
('[rel="stylesheet"]', ['l1']),
('[type="text/css"]', ['l1']),
('[href="blah.css"]', ['l1']),
('[href="no-blah.css"]', []),
('p[href="no-blah.css"]', []),
('[href="no-blah.css"]', []),
)
def test_attribute_tilde(self):
self.assertSelectMultiple(
('p[class~="class1"]', ['pmulti']),
('p[class~="class2"]', ['pmulti']),
('p[class~="class3"]', ['pmulti']),
('[class~="class1"]', ['pmulti']),
('[class~="class2"]', ['pmulti']),
('[class~="class3"]', ['pmulti']),
('a[rel~="friend"]', ['bob']),
('a[rel~="met"]', ['bob']),
('[rel~="friend"]', ['bob']),
('[rel~="met"]', ['bob']),
)
def test_attribute_startswith(self):
self.assertSelectMultiple(
('[rel^="style"]', ['l1']),
('link[rel^="style"]', ['l1']),
('notlink[rel^="notstyle"]', []),
('[rel^="notstyle"]', []),
('link[rel^="notstyle"]', []),
('link[href^="bla"]', ['l1']),
('a[href^="http://"]', ['bob', 'me']),
('[href^="http://"]', ['bob', 'me']),
('[id^="p"]', ['pmulti', 'p1']),
('[id^="m"]', ['me', 'main']),
('div[id^="m"]', ['main']),
('a[id^="m"]', ['me']),
)
def test_attribute_endswith(self):
self.assertSelectMultiple(
('[href$=".css"]', ['l1']),
('link[href$=".css"]', ['l1']),
('link[id$="1"]', ['l1']),
('[id$="1"]', ['l1', 'p1', 'header1', 's1a1', 's2a1', 's1a2s1']),
('div[id$="1"]', []),
('[id$="noending"]', []),
)
def test_attribute_contains(self):
self.assertSelectMultiple(
('[rel*="style"]', ['l1']),
('link[rel*="style"]', ['l1']),
('notlink[rel*="notstyle"]', []),
('[rel*="notstyle"]', []),
('link[rel*="notstyle"]', []),
('link[href*="bla"]', ['l1']),
('a[href*="http://"]', ['bob', 'me']),
('[href*="http://"]', ['bob', 'me']),
('[id*="p"]', ['pmulti', 'p1']),
('div[id*="m"]', ['main']),
('a[id*="m"]', ['me']),
('[href*=".css"]', ['l1']),
('link[href*=".css"]', ['l1']),
('link[id*="1"]', ['l1']),
('[id*="1"]', ['l1', 'p1', 'header1', 's1a1', 's1a2', 's2a1', 's1a2s1']),
('div[id*="1"]', []),
('[id*="noending"]', []),
('[href*="."]', ['bob', 'me', 'l1']),
('a[href*="."]', ['bob', 'me']),
('link[href*="."]', ['l1']),
('div[id*="n"]', ['main', 'inner']),
('div[id*="nn"]', ['inner']),
)
def test_attribute_exact_or_hypen(self):
self.assertSelectMultiple(
('p[lang|="en"]', ['lang-en', 'lang-en-gb', 'lang-en-us']),
('[lang|="en"]', ['lang-en', 'lang-en-gb', 'lang-en-us']),
('p[lang|="fr"]', ['lang-fr']),
('p[lang|="gb"]', []),
)
def test_attribute_exists(self):
self.assertSelectMultiple(
('[rel]', ['l1', 'bob', 'me']),
('link[rel]', ['l1']),
('a[rel]', ['bob', 'me']),
('[lang]', ['lang-en', 'lang-en-gb', 'lang-en-us', 'lang-fr']),
('p[class]', ['p1', 'pmulti']),
('[blah]', []),
('p[blah]', []),
)
def test_select_on_element(self):
inner = self.soup.find("div", id="main")
selected = inner.select("div")
self.assertSelectsIDs(selected, ['inner'])
from unittest import TestCase
import multiprocessing as mp
import random
import string
class TestCounter(TestCase):
def test_increment(self):
pass
def test_value(self):
pass
def cube(x):
return x**3
class TestMp(TestCase):
def rand_string(self, length, output):
rand_str = ''.join(random.choice(
string.ascii_lowercase
+ string.ascii_uppercase
+ string.digits) for _ in range(length))
output.put(rand_str)
def test_generate_random_str(self):
output = mp.Queue()
processes = [mp.Process(target=self.rand_string, args=(5, output)) for x in range(4)]
for p in processes:
p.start()
for p in processes:
p.join()
results = [output.get() for p in processes]
self.assertEqual(len(results), 4)
self.assertTrue(all(map(lambda x: len(x)==5, results)))
def test_pool(self):
expected = [1, 8, 27, 64, 125, 216]
pool = mp.Pool(processes=4)
results = [pool.apply(cube, args=(x,)) for x in range(1, 7)]
self.assertEqual(results, expected)
pool = mp.Pool(processes=4)
results = pool.map(cube, range(1, 7))
self.assertEqual(results, expected)
pool = mp.Pool(processes=4)
results = [pool.apply_async(cube, args=(x,)) for x in range(1, 7)]
output = [p.get() for p in results]
self.assertEqual(output, expected)
class Solution(object):
def solve(self, cipher):
total, n, lst = cipher
f = [[0 for _ in xrange(n)] for _ in xrange(total + 1)]
for i in xrange(n):
if lst[i] < total + 1:
f[lst[i]][i] = 1
for k in xrange(1, total + 1):
for i in reversed(xrange(n)):
if k - lst[i] >= 0:
f[k][i] += f[k - lst[i]][i]
if i + 1 < n:
f[k][i] += f[k][i + 1]
return f[total][0]
if __name__ == "__main__":
import sys
f = open("1.in", "r")
solution = Solution()
N, M = map(int, f.readline().strip().split(' '))
lst = map(int, f.readline().strip().split(' '))
cipher = N, M, lst
s = "%s\n" % (solution.solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
matrix, pattern = cipher
R1, C1 = len(matrix), len(matrix[0])
R2, C2 = len(pattern), len(pattern[0])
dp = [[0 for _ in xrange(C1 + 1)] for _ in xrange(R1 + 1)]
for i in xrange(1, R1 + 1):
for j in xrange(1, C1 + 1):
dp[i][j] = dp[i - 1][j] + dp[i][j - 1] - dp[i - 1][j - 1] + matrix[i - 1][j - 1]
pattern_sum = sum([sum(pattern[i]) for i in xrange(R2)])
for i in xrange(R1 - R2 + 1):
for j in xrange(C1 - C2 + 1):
bottom = i + R2
left = j + C2
candidate_sum = dp[bottom][left] - dp[bottom][j] - dp[i][left] + dp[i][j]
if candidate_sum == pattern_sum:
matched = True
for a in xrange(R2):
for b in xrange(C2):
if matrix[i + a][j + b] != pattern[a][b]:
matched = False
break
if not matched:
break
if matched:
return "YES"
return "NO"
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
matrix = []
pattern = []
R, C = map(int, f.readline().strip().split(' '))
for i in xrange(R):
matrix.append(map(int, list(f.readline().strip())))
R, C = map(int, f.readline().strip().split(' '))
for i in xrange(R):
pattern.append(map(int, list(f.readline().strip())))
cipher = matrix, pattern
s = "%s\n" % (Solution().solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
start_ptr = 0
end_ptr = len(cipher) - 1
cnt = 0
while start_ptr < end_ptr:
ord1 = ord(cipher[start_ptr]) - ord('a')
ord2 = ord(cipher[end_ptr]) - ord('a')
cnt += abs(ord1 - ord2)
start_ptr += 1
end_ptr -= 1
return cnt
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = f.readline().strip()
s = "%s\n" % (Solution().solve(cipher))
print s,
import sys
class Solution:
def smallestDifference(self, A, B):
A.sort()
B.sort()
ret = sys.maxint
for a in A:
idx = self.bin_search(a, B)
ret = min(ret, abs(a-B[idx]))
if idx+1<len(B):
ret = min(ret, abs(a-B[idx+1]))
return ret
def bin_search(self, t, A):
l = 0
u = len(A)
while l<u:
m = (l+u)/2
if A[m]==t:
return m
elif A[m]>t:
u = m
else:
l = m+1
return l-1
if __name__=="__main__":
print Solution().smallestDifference([3, 4, 6, 7], [2, 3, 8, 9])
import signal
def signal_handler(signum, frame):
raise Exception("Timed out!")
signal.signal(signal.SIGALRM, signal_handler)
signal.alarm(10)
try:
while True:
pass
except Exception, msg:
print "Timed out!"
signal.alarm(0)
import datetime
class Timer(object):
def __init__(self):
self.s = None
self.e = None
def start(self):
self.s = datetime.datetime.now()
return self.s
def end(self):
self.e = datetime.datetime.now()
return self.e - self.s
class DirectedGraphNode:
def __init__(self, x):
self.label = x
self.neighbors = []
class Solution:
def topSort_error(self, graph):
node2neighbors = {}
for node in graph:
node2neighbors[node] = set(node.neighbors)
def cmp(a, b):
if a in node2neighbors[b]:
return 1
if b in node2neighbors[a]:
return -1
return 0
graph.sort(cmp=cmp)
return graph
def topSort_normal(self, graph):
pi = {}
for node in graph:
pi[node] = set()
for node in graph:
for nbr in node.neighbors:
pi[nbr].add(node)
ret = []
while graph:
i = 0
while i<len(graph):
if len(pi[graph[i]])!=0:
i += 1
else:
ret.append(graph[i])
for nbr in graph[i].neighbors:
if graph[i] in pi[nbr]:
pi[nbr].remove(graph[i])
graph.pop(i)
return ret
def topSort(self, graph):
unvisited = set(graph)
ret = []
while unvisited:
cur = unvisited.copy().pop()
self.dfs(cur, unvisited, ret)
return ret
def dfs(self, cur, unvisited, ret):
for nbr in cur.neighbors:
if nbr in unvisited:
self.dfs(nbr, unvisited, ret)
ret.push(0, cur)
unvisited.remove(cur)
from __future__ import generators
__version__ = '$Revision: 0.9 $'
__date__ = '$Date: 2007/03/27 04:15:26 $'
__credits__ =
try:
set
except NameError:
from sets import Set as set
from rad_util import is_rotated
class CycleError(Exception):
pass
def topsort(pairlist):
num_parents = {}
children = {}
for parent, child in pairlist:
if not num_parents.has_key( parent ):
num_parents[parent] = 0
if not num_parents.has_key( child ):
num_parents[child] = 0
num_parents[child] += 1
children.setdefault(parent, []).append(child)
answer = [x for x in num_parents.keys() if num_parents[x] == 0]
for parent in answer:
del num_parents[parent]
if children.has_key( parent ):
for child in children[parent]:
num_parents[child] -= 1
if num_parents[child] == 0:
answer.append( child )
del children[parent]
if num_parents:
raise CycleError(answer, num_parents, children)
return answer
def topsort_levels(pairlist):
num_parents = {}
children = {}
for parent, child in pairlist:
if not num_parents.has_key( parent ):
num_parents[parent] = 0
if not num_parents.has_key( child ):
num_parents[child] = 0
num_parents[child] += 1
children.setdefault(parent, []).append(child)
return topsort_levels_core(num_parents, children)
def topsort_levels_core(num_parents, children):
while 1:
level_parents = [x for x in num_parents.keys() if num_parents[x] == 0]
if not level_parents:
break
yield level_parents
for level_parent in level_parents:
del num_parents[level_parent]
if children.has_key(level_parent):
for level_parent_child in children[level_parent]:
num_parents[level_parent_child] -= 1
del children[level_parent]
if num_parents:
raise CycleError(num_parents, children)
else:
raise StopIteration
def find_cycles(parent_children):
cycles = []
visited_nodes = set()
for parent in parent_children:
if parent in visited_nodes:
continue
paths = [[parent]]
while paths:
path = paths.pop()
parent = path[-1]
try:
children = parent_children[parent]
except KeyError:
continue
for child in children:
if child in path:
cycle = path[path.index(child):]
is_dup = False
for other_cycle in cycles:
if is_rotated(other_cycle, cycle):
is_dup = True
break
if not is_dup:
cycles.append(cycle)
yield cycle
else:
paths.append(path + [child])
visited_nodes.add(child)
if __name__ == '__main__':
import sys
import doctest
doctest.testmod(sys.modules['__main__'])
import heapq
class Cell:
def __init__(self, i, j, h):
self.i = i
self.j = j
self.h = h
def __cmp__(self, other):
return self.h - other.h
class Solution(object):
def __init__(self):
self.dirs = [(-1, 0), (1, 0), (0, -1), (0, 1)]
def trapRainWater(self, mat):
if not mat: return 0
m, n = len(mat), len(mat[0])
visited = [[False for _ in xrange(n)] for _ in xrange(m)]
h = []
for i in xrange(m):
visited[i][0] = True
heapq.heappush(h, Cell(i, 0, mat[i][0]))
visited[i][n-1] = True
heapq.heappush(h, Cell(i, n-1, mat[i][n-1]))
for j in xrange(1, n-1):
visited[0][j] = True
heapq.heappush(h, Cell(0, j, mat[0][j]))
visited[m-1][j] = True
heapq.heappush(h, Cell(m-1, j, mat[m-1][j]))
trapped = 0
while h:
cur = heapq.heappop(h)
for dir in self.dirs:
I, J = cur.i+dir[0], cur.j+dir[1]
if 0 <= I < m and 0 <= J < n and not visited[I][J]:
nxt = Cell(I, J, mat[I][J])
if nxt.h < cur.h:
trapped += cur.h - nxt.h
nxt.h = cur.h
visited[I][J] = True
heapq.heappush(h, nxt)
return trapped
if __name__ == "__main__":
assert Solution().trapRainWater([
[12, 13, 0, 12],
[13, 4, 13, 12],
[13, 8, 10, 12],
[12, 13, 12, 12],
[13, 13, 13, 13]]
) == 14
assert Solution().trapRainWater([[9, 1, 10, 10], [9, 1, 2, 8], [2, 6, 5, 0], [6, 0, 9, 0]]) == 0
class TreeNode(object):
def __init__(self, val):
self.val = val
self.left, self.right = None, None
class Traverser(object):
def morris_inorder(self, root):
cur = root
while cur:
if not cur.left:
self.consume(cur)
cur = cur.right
else:
pre = cur.left
while pre.right and pre.right != cur:
pre = pre.right
if not pre.right:
pre.right = cur
cur = cur.left
else:
pre.right = None
self.consume(cur)
cur = cur.right
def morris_preorder(self, root):
cur = root
while cur:
if not cur.left:
self.consume(cur)
cur = cur.right
else:
pre = cur.left
while pre.right and pre.right != cur:
pre = pre.right
if not pre.right:
pre.right = cur
self.consume(cur)
cur = cur.left
else:
pre.right = None
cur = cur.right
def morris_postorder(self, root):
dummy = TreeNode(0)
dummy.left = root
cur = dummy
while cur:
if not cur.left:
cur = cur.right
else:
pre = cur.left
while pre.right and pre.right != cur:
pre = pre.right
if not pre.right:
pre.right = cur
cur = cur.left
else:
pre.right = None
self.consume_path(cur.left, pre)
cur = cur.right
def _reverse(self, fr, to):
if fr == to: return
cur = fr
nxt = cur.right
while cur and nxt and cur != to:
nxt.right, cur, nxt = cur, nxt, nxt.right
def consume_path(self, fr, to):
self._reverse(fr, to)
cur = to
self.consume(cur)
while cur != fr:
cur = cur.right
self.consume(cur)
self._reverse(to, fr)
def consume(self, node):
print node.val
if __name__ == "__main__":
root = TreeNode(6)
root.left = TreeNode(2)
root.left.left = TreeNode(1)
root.left.right = TreeNode(4)
root.left.right.left = TreeNode(3)
root.left.right.right = TreeNode(5)
root.right = TreeNode(7)
root.right.right = TreeNode(9)
root.right.right.left = TreeNode(8)
traverser = Traverser()
print traverser.morris_inorder.__name__
traverser.morris_inorder(root)
print traverser.morris_preorder.__name__
traverser.morris_preorder(root)
print traverser.morris_postorder.__name__
traverser.morris_postorder(root)
class Solution:
def triangleCount(self, S):
S.sort()
cnt = 0
for h in xrange(len(S)-1, 1, -1):
s = 0
e = h-1
while s<e:
if S[s]+S[e]>S[h]:
cnt += e-s
e -= 1
else:
s += 1
return cnt
if __name__ == "__main__":
assert Solution().triangleCount([3, 4, 6, 7]) == 3
from httplib import HTTPConnection, HTTPSConnection
from httplib import FORBIDDEN, MOVED_PERMANENTLY, NOT_FOUND, OK, TEMPORARY_REDIRECT
from sys import stderr
from urlparse import urlparse
CONNECTION_BY_SCHEME = {
'http': HTTPConnection,
'https': HTTPSConnection,
}
def _request_wrap(conn, method, url, body=None,
headers=None):
depth = 0
curr_conn = conn
curr_url = url
while depth < 100:
curr_conn.request(method, curr_url, body,
headers=headers if headers is not None else {})
res = curr_conn.getresponse()
if res.status not in (MOVED_PERMANENTLY, TEMPORARY_REDIRECT, ):
return res
res.read()
res_headers = dict(res.getheaders())
url_soup = urlparse(res_headers['location'])
try:
curr_conn = CONNECTION_BY_SCHEME[url_soup.scheme](url_soup.netloc)
except KeyError:
assert False, 'redirected to unknown scheme, dying'
curr_url = url_soup.path
depth += 1
assert False, 'redirects and moves lead us astray, dying'
def main(args):
if len(args) != 2:
print >> stderr, 'Usage: %s url_to_brat_installation' % (args[0], )
return -1
brat_url = args[1]
url_soup = urlparse(brat_url)
if url_soup.scheme:
try:
Connection = CONNECTION_BY_SCHEME[url_soup.scheme.split(':')[0]]
except KeyError:
print >> stderr, ('ERROR: Unknown url scheme %s, try http or '
'https') % url_soup.scheme
return -1
else:
path_soup = url_soup.path.split('/')
assumed_netloc = path_soup[0]
assumed_path = '/' + '/'.join(path_soup[1:])
print >> stderr, ('WARNING: No url scheme given, assuming scheme: '
'"http", netloc: "%s" and path: "%s"'
) % (assumed_netloc, assumed_path, )
url_soup = url_soup._replace(scheme='http', netloc=assumed_netloc,
path=assumed_path)
Connection = HTTPConnection
conn = Connection(url_soup.netloc)
res = _request_wrap(conn, 'HEAD', url_soup.path)
if res.status != OK:
print >> stderr, ('Unable to load "%s", please check the url.'
) % (brat_url, )
print >> stderr, ('Does the url you provdide point to your brat '
'installation?')
return -1
res.read()
ajax_cgi_path = url_soup.path + '/ajax.cgi'
ajax_cgi_url = url_soup._replace(path=ajax_cgi_path).geturl()
res = _request_wrap(conn, 'HEAD', ajax_cgi_path)
if res.status == FORBIDDEN:
print >> stderr, ('Received forbidden (403) when trying to access '
'"%s"') % (ajax_cgi_url, )
print ('Have you perhaps forgotten to enable execution of CGI in '
' your web server configuration?')
return -1
elif res.status != OK:
print >> stderr, ('Unable to load "%s", please check your url. Does '
'it point to your brat installation?') % (ajax_cgi_url, )
return -1
res_headers = dict(res.getheaders())
try:
content_type = res_headers['content-type']
except KeyError:
content_type = None
if content_type != 'application/json':
print >> stderr, ('Didn\'t receive json data when accessing "%s"%s.'
) % (ajax_cgi_url,
', instead we received %s' % content_type
if content_type is not None else '')
print >> stderr, ('Have you perhaps forgotten to add a handler for '
'CGI in your web server configuration?')
return -1
print 'Congratulations! Your brat server appears to be ready to run.'
print ('However, there is the possibility that there are further errors, '
'but at least the server should be capable of communicating '
'these errors to the client.')
return 0
if __name__ == '__main__':
from sys import argv
exit(main(argv))
class Solution(object):
def solve(self, cipher):
N, K, A, B = cipher
A.sort()
B.sort(reverse=True)
for i in xrange(N):
if not A[i] + B[i] >= K:
return "NO"
return "YES"
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
N, K = map(int, f.readline().strip().split(" "))
A = map(int, f.readline().strip().split(' '))
B = map(int, f.readline().strip().split(' '))
cipher = N, K, A, B
s = "%s\n" % (Solution().solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
a = map(set, cipher)
ret = a[0].intersection(a[1])
if len(ret) > 0:
return "YES"
else:
return "NO"
if __name__ == "__main__":
import sys
f = open("0.in", "r")
solution = Solution()
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = []
cipher.append(f.readline().strip())
cipher.append(f.readline().strip())
s = "%s\n" % (solution.solve(cipher))
print s,
class Solution(object):
def solve_TLE(self, cipher):
a = cipher[0]
counter = 0
for i in xrange(len(a)):
if a[i] == "0":
continue
for j in xrange(i, len(a)):
strength = a[i:j + 1]
strength = int(strength)
if strength & (strength - 1) == 0:
counter += 1
return counter
def solve(self, cipher):
def strength(self, a, i, j):
if a[i] == 0:
return 0
value = 0
for k in xrange(i, j + 1):
value = value * 10 + a[k]
return value
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = f.readline().strip().split(' ')
s = "%s\n" % (Solution().solve(cipher))
print s,
import nltk.data
import os
from nltk.tokenize.punkt import PunktWordTokenizer
from nltk.stem.porter import *
import math
sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')
stemmer = PorterStemmer()
text_auto = []
text_nonauto = []
print 'Processing datat in'
directory = os.path.dirname(os.path.realpath(__file__)) + '/raw_data/cleaned'
print 'dir:'+directory
for root, dirs, files in os.walk(directory):
for file in files:
if file.endswith(".txt") and (not ('(1)' in file)) and (not ('-2' in file)):
f=open(os.path.join(root,file), 'r')
text_nonauto.append((file,f.read()))
f.close()
elif file.endswith(".txt"):
f=open(os.path.join(root,file), 'r')
text_auto.append((file,f.read()))
f.close()
if not os.path.exists('Sents_split/non_auto/'):
os.makedirs('Sents_split/non_auto/')
if not os.path.exists('Sents_split/auto/'):
os.makedirs('Sents_split/auto/')
for ind, (video, text) in enumerate(text_nonauto):
xml_nonauto = '[non-automatic.xml]\n<transcripts>\n'
video = video[:(video.find('[English]'))]
url = text[:text.strip().find('\n')]
text = text[text.strip().find('\n'):]
sents = sent_detector.tokenize(text.strip())
cleaned = '<transcript'+' id=\"'+ str(ind+1)+ '\" title=\"'+video+'\" url=\"'+ url + '\" mode=\"non-automatic\">\n'
for s in sents:
s = s.replace('\n',' ') +'\n'
s = s.replace('.',' ')
s = s.lower()
cleaned += s
temp = PunktWordTokenizer().tokenize(s)
cleaned += '</transcript>\n'
xml_nonauto+= cleaned+'</transcripts>'
f = open('Sents_split/non_auto/'+str(ind+1)+'.txt','w')
f.write(xml_nonauto)
f.close()
for ind, (video, text) in enumerate(text_auto):
xml_auto = '[automatic.xml]\n<transcripts>\n'
video = video[:(video.find('[English]'))]
url = text[:text.strip().find('\n')]
text = text[text.strip().find('\n'):]
sents = sent_detector.tokenize(text.strip())
cleaned = '<transcript'+' id=\"'+ str(ind+1) + '\" title=\"'+video+'\" url=\"'+ url + '\" mode=\"automatic\">\n'
for s in sents:
s = s.replace('\n',' ') +'\n'
s = s.replace('.',' ')
s = s.lower()
cleaned += s
cleaned += '</transcript>\n'
xml_auto+= cleaned+'</transcripts>'
f = open('Sents_split/auto/'+str(ind+1)+'.txt','w')
f.write(xml_auto)
f.close()
from datetime import datetime
import pytz
class TimeParser():
dt_formats = [
'%Y-%m-%d %H:%M:%S %Z',
'%Y-%m-%d %H:%M:%S',
]
def parse(self, dt_str, dt_format):
return datetime.strptime(dt_str, dt_format)
def localtime(utc_dt, tz_str):
tz = pytz.timezone(tz_str)
local_dt = tz.normalize(utc_dt.astimezone(tz))
return local_dt
def utctime(dt, tz_str):
tz = pytz.timezone(tz_str)
local_dt = tz.localize(dt)
utc_dt = pytz.utc.normalize(local_dt.astimezone(pytz.utc))
return utc_dt
from . import ansi
import os
import math
def _get_terminal_columns():
_, columns = os.popen('stty size', 'r').read().split()
return int(columns)
def erase():
ansi.move_cursor_line_beggining()
ansi.erase_from_cursor_to_end()
def refresh(state):
erase()
lines, num_rows = _construct_output(state)
for line in lines:
print(line)
ansi.move_cursor_previous_lines(num_rows)
ansi.move_cursor_horizental(len(lines[0])+1)
ansi.flush()
def _construct_output(state):
columns = _get_terminal_columns()
def number_of_rows(line):
return int(math.ceil(float(len(line))/columns))
displayed_lines = []
num_rows = 0
prompt_line = 'Path: ' + state.input
displayed_lines.append(prompt_line)
num_rows += number_of_rows(prompt_line)
matches = state.get_matches()
if matches:
selected_command_index = matches.index(state.get_selected_match())
matches_to_display = matches[max(0, selected_command_index - 10 + 1):max(10, selected_command_index + 1)]
for index, m in enumerate(matches_to_display):
fm = ' ' + m
num_rows += number_of_rows(fm)
for w in state.input.split(' '):
if w:
fm = fm.replace(w, ansi.bold_text(w))
if m == state.get_selected_match():
fm = ansi.select_text(fm)
displayed_lines.append(fm)
else:
not_found_line = 'Nothing found'
displayed_lines.append(not_found_line)
num_rows += number_of_rows(not_found_line)
return displayed_lines, num_rows
class TreeNode(object):
def __init__(self, val):
self.val = val
self.left, self.right = None, None
class Solution(object):
def generateTrees(self, n):
return self.dfs(1, n+1)
def dfs(self, s, e):
ret = []
if s >= e:
return [None]
for i in xrange(s, e):
ls = self.dfs(s, i)
rs = self.dfs(i+1, e)
for l in ls:
for r in rs:
root = TreeNode(i)
root.left = l
root.right = r
ret.append(root)
return ret
class Solution:
def __init__(self):
self.cache = {}
def numTrees(self, n):
return self.dfs(n)
def dfs(self, n):
if n not in self.cache:
if n in (0, 1, 2):
self.cache[n] = max(1, n)
else:
s = 0
for i in xrange(1, n+1):
l = self.dfs(i-1)
r = self.dfs(n-i)
s += l*r
self.cache[n] = s
return self.cache[n]
if __name__ == "__main__":
print Solution().numTrees(3)
from . import constants
import sys
from .latin1prober import Latin1Prober
from .mbcsgroupprober import MBCSGroupProber
from .sbcsgroupprober import SBCSGroupProber
from .escprober import EscCharSetProber
import re
MINIMUM_THRESHOLD = 0.20
ePureAscii = 0
eEscAscii = 1
eHighbyte = 2
class UniversalDetector:
def __init__(self):
self._highBitDetector = re.compile(b'[\x80-\xFF]')
self._escDetector = re.compile(b'(\033|~{)')
self._mEscCharSetProber = None
self._mCharSetProbers = []
self.reset()
def reset(self):
self.result = {'encoding': None, 'confidence': 0.0}
self.done = False
self._mStart = True
self._mGotData = False
self._mInputState = ePureAscii
self._mLastChar = b''
if self._mEscCharSetProber:
self._mEscCharSetProber.reset()
for prober in self._mCharSetProbers:
prober.reset()
def feed(self, aBuf):
if self.done:
return
aLen = len(aBuf)
if not aLen:
return
if not self._mGotData:
if aBuf[:3] == '\xEF\xBB\xBF':
self.result = {'encoding': "UTF-8", 'confidence': 1.0}
elif aBuf[:4] == '\xFF\xFE\x00\x00':
self.result = {'encoding': "UTF-32LE", 'confidence': 1.0}
elif aBuf[:4] == '\x00\x00\xFE\xFF':
self.result = {'encoding': "UTF-32BE", 'confidence': 1.0}
elif aBuf[:4] == '\xFE\xFF\x00\x00':
self.result = {
'encoding': "X-ISO-10646-UCS-4-3412",
'confidence': 1.0
}
elif aBuf[:4] == '\x00\x00\xFF\xFE':
self.result = {
'encoding': "X-ISO-10646-UCS-4-2143",
'confidence': 1.0
}
elif aBuf[:2] == '\xFF\xFE':
self.result = {'encoding': "UTF-16LE", 'confidence': 1.0}
elif aBuf[:2] == '\xFE\xFF':
self.result = {'encoding': "UTF-16BE", 'confidence': 1.0}
self._mGotData = True
if self.result['encoding'] and (self.result['confidence'] > 0.0):
self.done = True
return
if self._mInputState == ePureAscii:
if self._highBitDetector.search(aBuf):
self._mInputState = eHighbyte
elif ((self._mInputState == ePureAscii) and
self._escDetector.search(self._mLastChar + aBuf)):
self._mInputState = eEscAscii
self._mLastChar = aBuf[-1:]
if self._mInputState == eEscAscii:
if not self._mEscCharSetProber:
self._mEscCharSetProber = EscCharSetProber()
if self._mEscCharSetProber.feed(aBuf) == constants.eFoundIt:
self.result = {
'encoding': self._mEscCharSetProber.get_charset_name(),
'confidence': self._mEscCharSetProber.get_confidence()
}
self.done = True
elif self._mInputState == eHighbyte:
if not self._mCharSetProbers:
self._mCharSetProbers = [MBCSGroupProber(), SBCSGroupProber(),
Latin1Prober()]
for prober in self._mCharSetProbers:
if prober.feed(aBuf) == constants.eFoundIt:
self.result = {'encoding': prober.get_charset_name(),
'confidence': prober.get_confidence()}
self.done = True
break
def close(self):
if self.done:
return
if not self._mGotData:
if constants._debug:
sys.stderr.write('no data received!\n')
return
self.done = True
if self._mInputState == ePureAscii:
self.result = {'encoding': 'ascii', 'confidence': 1.0}
return self.result
if self._mInputState == eHighbyte:
proberConfidence = None
maxProberConfidence = 0.0
maxProber = None
for prober in self._mCharSetProbers:
if not prober:
continue
proberConfidence = prober.get_confidence()
if proberConfidence > maxProberConfidence:
maxProberConfidence = proberConfidence
maxProber = prober
if maxProber and (maxProberConfidence > MINIMUM_THRESHOLD):
self.result = {'encoding': maxProber.get_charset_name(),
'confidence': maxProber.get_confidence()}
return self.result
if constants._debug:
sys.stderr.write('no probers hit minimum threshhold\n')
for prober in self._mCharSetProbers[0].mProbers:
if not prober:
continue
sys.stderr.write('%s confidence = %s\n' %
(prober.get_charset_name(),
prober.get_confidence()))
from __future__ import with_statement
import sys
import re
try:
import argparse
except ImportError:
from os.path import basename
from sys import path as sys_path
sys_path.append(join_path(basename(__file__), '../server/lib'))
import argparse
DEBUG=True
class ArgumentError(Exception):
def __init__(self, s):
self.errstr = s
def __str__(self):
return 'Argument error: %s' % (self.errstr)
class SyntaxError(Exception):
def __init__(self, line, errstr=None, line_num=None):
self.line = line
self.errstr = errstr
self.line_num = str(line_num) if line_num is not None else "(undefined)"
def __str__(self):
return 'Syntax error on line %s ("%s")%s' % (self.line_num, self.line, ": "+self.errstr if self.errstr is not None else "")
class ProcessingError(Exception):
pass
class Annotation(object):
COMMENT_TYPE = "<COMMENT>"
_typere = re.compile(r'^([a-zA-Z][a-zA-Z0-9_-]*)\b')
@staticmethod
def _parse_type(s):
if not s or s[0].isspace():
raise SyntaxError(s, "ID missing")
if s[0].isalnum() or s[0] == '*':
fields = s.split("\t")
if len(fields) < 2:
raise SyntaxError(s, "No TAB in annotation")
m = Annotation._typere.search(fields[1])
if not m:
raise SyntaxError(s, "Failed to parse type in \"%s\"" % fields[1])
return m.group(1)
elif s[0] == '#':
return Annotation.COMMENT_TYPE
else:
raise SyntaxError(s, "Unrecognized ID")
def __init__(self, s):
self.ann_string = s
self.type = Annotation._parse_type(s)
def __str__(self):
return self.ann_string
def argparser():
ap=argparse.ArgumentParser(description="Split merged BioNLP ST annotations into separate files.")
ap.add_argument("-a1", "--a1types", default="Protein", metavar="TYPE[,TYPE...]", help="Annotation types to place into .a1 file")
ap.add_argument("-a2", "--a2types", default="[OTHER]", metavar="TYPE[,TYPE...]", help="Annotation types to place into .a2 file")
ap.add_argument("-d", "--directory", default=None, metavar="DIR", help="Output directory")
ap.add_argument("-s", "--skipempty", default=False, action="store_true", help="Skip output for empty split files")
ap.add_argument("-i", "--idrewrite", default=False, action="store_true", help="Rewrite IDs following BioNLP ST conventions")
ap.add_argument("files", nargs='+', help="Files in merged BioNLP ST-flavored standoff")
return ap
def parse_annotations(annlines, fn="(unknown)"):
annotations = []
for ln, l in enumerate(annlines):
if not l.strip():
print >> sys.stderr, "Warning: ignoring empty line %d in %s" % (ln, fn)
continue
try:
annotations.append(Annotation(l))
except SyntaxError, e:
raise SyntaxError(l, e.errstr, ln)
return annotations
DEFAULT_TYPE = "<DEFAULT>"
def split_annotations(annotations, typemap):
d = {}
for a in annotations:
if a.type in typemap:
t = a.type
elif DEFAULT_TYPE in typemap:
t = DEFAULT_TYPE
else:
raise ArgumentError("Don't know where to place annotation of type '%s'" % a.type)
s = typemap[t]
if s not in d:
d[s] = []
d[s].append(a)
return d
def type_mapping(arg):
m = {}
for suff, typestr in (("a1", arg.a1types),
("a2", arg.a2types)):
for ts in typestr.split(","):
t = ts if ts != "[OTHER]" else DEFAULT_TYPE
if t in m:
raise ArgumentError("Split for '%s' ambiguous (%s or %s); check arguments." % (ts, m[t], suff))
m[t] = suff
return m
def output_file_name(fn, directory, suff):
import os.path
dir, base = os.path.split(fn)
root, ext = os.path.splitext(base)
if not directory:
directory = dir
return os.path.join(directory, root+"."+suff)
def annotation_lines(annotations):
return [str(a) for a in annotations]
def write_annotation_lines(fn, lines):
with open(fn, 'wt') as f:
for l in lines:
f.write(l)
def read_annotation_lines(fn):
with open(fn) as f:
return f.readlines()
def verify_split(origlines, splitlines):
orig = origlines[:]
split = []
for k in splitlines:
split.extend(splitlines[k])
orig.sort()
split.sort()
orig_only = []
split_only = []
oi, si = 0, 0
while oi < len(orig) and si < len(split):
if orig[oi] == split[si]:
oi += 1
si += 1
elif orig[oi] < split[si]:
orig_only.append(orig[oi])
oi += 1
else:
assert split[si] < orig[si]
split_only.append(split[si])
si += 1
while oi < len(orig):
orig_only.append(orig[oi])
oi += 1
while si < len(split):
split_only.append(split[si])
si += 1
difference_found = False
for l in split_only:
print >> sys.stderr, "Split error: split contains extra line '%s'" % l
difference_found = True
for l in orig_only:
if l.strip() == "":
continue
print >> sys.stderr, "Split error: split is missing line '%s'" % l
difference_found = True
if difference_found:
raise ProcessingError
def process_file(fn, typemap, directory, mandatory):
annlines = read_annotation_lines(fn)
annotations = parse_annotations(annlines)
splitann = split_annotations(annotations, typemap)
for t in mandatory:
splitann[t] = splitann.get(t, [])
splitlines = {}
for suff in splitann:
splitlines[suff] = annotation_lines(splitann[suff])
if DEBUG:
verify_split(annlines, splitlines)
for suff in splitann:
ofn = output_file_name(fn, directory, suff)
write_annotation_lines(ofn, splitlines[suff])
def main(argv=None):
if argv is None:
argv = sys.argv
arg = argparser().parse_args(argv[1:])
try:
typemap = type_mapping(arg)
except ArgumentError, e:
print >> sys.stderr, e
return 2
if arg.skipempty:
mandatory_outputs = []
else:
mandatory_outputs = ["a1", "a2"]
for fn in arg.files:
try:
process_file(fn, typemap, arg.directory, mandatory_outputs)
except IOError, e:
print >> sys.stderr, "Error: failed %s, skip processing (%s)" % (fn, e)
except SyntaxError, e:
print >> sys.stderr, "Error: failed %s, skip processing (%s)" % (fn, e)
except:
print >> sys.stderr, "Fatal: unexpected error processing %s" % fn
raise
return 0
if __name__ == "__main__":
sys.exit(main())
class Solution:
def updateBits(self, n, m, i, j):
mask = ((1<<32)-1)-((1<<j+1)-1)+((1<<i)-1)
ret = (n&mask)+(m<<i)
return self.twos_comp(ret, 32)
@staticmethod
def twos_comp(val, bits):
if val > 0 and val&(1<<(bits-1)) != 0:
val -= 1<<bits
return val
if __name__ == "__main__":
assert Solution().updateBits(-2147483648, 2147483647, 0, 30) == -1
assert Solution().updateBits(1, -1, 0, 31) == -1
n = int("10000000000", 2)
m = int("10101", 2)
assert bin(Solution().updateBits(n, m, 2, 6)) == "0b10001010100"
from django.conf.urls import include, url
from django.contrib import admin
from django.views.generic import TemplateView
from rake_app import views as rake_views
urlpatterns = [
url(r'^admin/', include(admin.site.urls)),
url(r'^$', rake_views.MainView.as_view()),
url(r'^about/$', TemplateView.as_view(template_name="about.html"))
]
from . import constants
from .charsetprober import CharSetProber
from .codingstatemachine import CodingStateMachine
from .mbcssm import UTF8SMModel
ONE_CHAR_PROB = 0.5
class UTF8Prober(CharSetProber):
def __init__(self):
CharSetProber.__init__(self)
self._mCodingSM = CodingStateMachine(UTF8SMModel)
self.reset()
def reset(self):
CharSetProber.reset(self)
self._mCodingSM.reset()
self._mNumOfMBChar = 0
def get_charset_name(self):
return "utf-8"
def feed(self, aBuf):
for c in aBuf:
codingState = self._mCodingSM.next_state(c)
if codingState == constants.eError:
self._mState = constants.eNotMe
break
elif codingState == constants.eItsMe:
self._mState = constants.eFoundIt
break
elif codingState == constants.eStart:
if self._mCodingSM.get_current_charlen() >= 2:
self._mNumOfMBChar += 1
if self.get_state() == constants.eDetecting:
if self.get_confidence() > constants.SHORTCUT_THRESHOLD:
self._mState = constants.eFoundIt
return self.get_state()
def get_confidence(self):
unlike = 0.99
if self._mNumOfMBChar < 6:
for i in range(0, self._mNumOfMBChar):
unlike = unlike * ONE_CHAR_PROB
return 1.0 - unlike
else:
return unlike
import os
from PIL import Image
import numpy as np
import random
def read_image(filename):
imarr = np.array([])
try:
im = Image.open(os.path.join(filename))
im = im.convert("L")
imarr = np.array(im, dtype=np.uint8)
except IOError as (errno, strerror):
print "I/O error({0}): {1}".format(errno, strerror)
except:
print "Cannot open image."
return imarr
def asRowMatrix(X):
if len(X) == 0:
return np.array([])
total = 1
for i in range(0, np.ndim(X[0])):
total = total * X[0].shape[i]
mat = np.empty([0, total], dtype=X[0].dtype)
for row in X:
mat = np.append(mat, row.reshape(1, -1), axis=0)
return np.asmatrix(mat)
def asColumnMatrix(X):
if len(X) == 0:
return np.array([])
total = 1
for i in range(0, np.ndim(X[0])):
total = total * X[0].shape[i]
mat = np.empty([total, 0], dtype=X[0].dtype)
for col in X:
mat = np.append(mat, col.reshape(-1, 1), axis=1)
return np.asmatrix(mat)
def minmax_normalize(X, low, high, minX=None, maxX=None, dtype=np.float):
if minX is None:
minX = np.min(X)
if maxX is None:
maxX = np.max(X)
minX = float(minX)
maxX = float(maxX)
X = X - minX
X = X / (maxX - minX)
X = X * (high - low)
X = X + low
return np.asarray(X, dtype=dtype)
def shuffle(X, y):
idx = np.argsort([random.random() for i in xrange(y.shape[0])])
return X[:, idx], y[idx]
def shuffle_array(X, y):
idx = np.argsort([random.random() for i in xrange(len(y))])
X = [X[i] for i in idx]
y = [y[i] for i in idx]
return X, y
def to_col_vec(row_vec):
return row_vec[:, np.newaxis]
def to_row_vec(col_vec):
return col_vec.reshape(1, -1)
import os
import sys
def get_list_from_file(file_path, list_name):
list = []
if os.path.exists(file_path):
file_in = open(file_path, "r")
list_string = ""
parsing_multiline_list = False
for line in file_in:
if list_name in line or parsing_multiline_list:
list_string += line
if ']' not in list_string:
parsing_multiline_list = True
else:
list = eval(list_string.split('=', 1)[1].strip())
break
file_in.close()
return list
def get_bool_from_file(file_path, bool_name, value_if_missing):
if os.path.exists(file_path):
file_in = open(file_path, "r")
bool_found = False
for line in file_in:
if bool_name in line:
bool = eval(line.split('=', 1)[1].strip())
bool_found = True
break
file_in.close()
if bool_found:
return bool
else:
return value_if_missing
def read_config_file():
modules_enabled  = ['all_modules']
examples_enabled = False
tests_enabled    = False
config_file_exists = False
dot_ns3rc_name = '.ns3rc'
dot_ns3rc_path = dot_ns3rc_name
if not os.path.exists(dot_ns3rc_path):
dot_ns3rc_path = os.path.expanduser('~/') + dot_ns3rc_name
if not os.path.exists(dot_ns3rc_path):
return (config_file_exists, modules_enabled, examples_enabled, tests_enabled)
config_file_exists = True
modules_enabled = get_list_from_file(dot_ns3rc_path, 'modules_enabled')
if not modules_enabled:
modules_enabled = ['all_modules']
value_if_missing = False
examples_enabled = get_bool_from_file(dot_ns3rc_path, 'examples_enabled', value_if_missing)
value_if_missing = False
tests_enabled = get_bool_from_file(dot_ns3rc_path, 'tests_enabled', value_if_missing)
return (config_file_exists, modules_enabled, examples_enabled, tests_enabled)
class Solution(object):
def solve(self, cipher):
N = int(cipher[0])
height = 1
for cycle in xrange(N):
if cycle & 1 == 0:
height *= 2
else:
height += 1
return height
if __name__ == "__main__":
import sys
f = sys.stdin
testcases = int(f.readline().strip())
for t in xrange(testcases):
cipher = f.readline().strip().split(' ')
s = "%s\n" % (Solution().solve(cipher))
print s,
from __future__ import absolute_import
import math as math
import random as random
import logging
import cv2
import numpy as np
from facerec_py.facerec.model import PredictableModel, AbstractPredictableModel
from util.commons_util.fundamentals.generators import frange
class TFPN(object):
def __init__(self, TP=0, FP=0, TN=0, FN=0):
self.rates = np.array([TP, FP, TN, FN], dtype=np.double)
@property
def TP(self):
return self.rates[0]
@TP.setter
def TP(self, value):
self.rates[0] = value
@property
def FP(self):
return self.rates[1]
@FP.setter
def FP(self, value):
self.rates[1] = value
@property
def TN(self):
return self.rates[2]
@TN.setter
def TN(self, value):
self.rates[2] = value
@property
def FN(self):
return self.rates[3]
@FN.setter
def FN(self, value):
self.rates[3] = value
def __add__(self, other):
return self.rates + other.rates
def __iadd__(self, other):
self.rates += other.rates
return self
def shuffle(X, y):
idx = np.argsort([random.random() for _ in xrange(len(y))])
X = [X[i] for i in idx]
y = y[idx]
return X, y
def slice_2d(X, rows, cols):
return [X[i][j] for j in cols for i in rows]
def precision(true_positives, false_positives):
return accuracy(true_positives, 0, false_positives, 0)
def accuracy(true_positives, true_negatives, false_positives, false_negatives, description=None):
true_positives = float(true_positives)
true_negatives = float(true_negatives)
false_positives = float(false_positives)
false_negatives = float(false_negatives)
if (true_positives + true_negatives + false_positives + false_negatives) < 1e-15:
return 0.0
return (true_positives + true_negatives) / (true_positives + false_positives + true_negatives + false_negatives)
class ValidationResult(object):
def __init__(self, true_positives, true_negatives, false_positives, false_negatives, description):
self.true_positives = true_positives
self.true_negatives = true_negatives
self.false_positives = false_positives
self.false_negatives = false_negatives
self.description = description
def __div(self, x, y):
if y < 1e-15:
return 0.0
return x/y
@property
def TPR(self):
return self.__div(self.true_positives, self.true_positives+self.false_negatives)
@property
def FPR(self):
return self.__div(self.false_positives, self.false_positives+self.true_negatives)
@property
def recall(self):
return self.__div(self.true_positives, self.true_positives+self.false_negatives)
@property
def precision(self):
return self.__div(self.true_positives, self.true_positives+self.false_positives)
@property
def total(self):
return self.true_negatives+self.true_positives+self.false_negatives+self.false_positives
@property
def accuracy(self):
return self.__div(self.true_positives+self.true_negatives, self.total)
@property
def F1(self):
return self.__div(2*self.precision*self.recall, self.precision+self.recall)
def __repr__(self):
return "ValidationResult (Description=%s, Precision=%.2f%%, Recall=%.2f%%, TPR=%.2f%%, FPR=%.2f%%, TP=%d, TN=%d, FP=%d, FN=%d)" % (
self.description, self.precision*100, self.recall*100, self.TPR*100, self.FPR*100, self.true_positives, self.true_negatives, self.false_positives, self.false_negatives)
class ValidationStrategy(object):
def __init__(self, model):
if not isinstance(model, AbstractPredictableModel):
raise TypeError("Validation can only validate the type PredictableModel.")
self.model = model
self.validation_results = []
def add(self, validation_result):
self.validation_results.append(validation_result)
def validate(self, X, y, description):
raise NotImplementedError("Every Validation module must implement the validate method!")
def print_results(self):
print self.model
for validation_result in self.validation_results:
print validation_result
def __repr__(self):
return "Validation Strategy (model=%s, results=%s)"%(self.model, self.validation_results)
class KFoldCrossValidation(ValidationStrategy):
def __init__(self, model, k=10, threshold_up=1, froze_shuffle=False, debug=True):
super(KFoldCrossValidation, self).__init__(model=model)
self.threshold_up = threshold_up
self.k = k
self.logger = logging.getLogger("facerec.validation.KFoldCrossValidation")
self._debug = debug
self.froze_shuffle = froze_shuffle
def validate(self, X, y, description="ExperimentName"):
if not self.froze_shuffle:
X, y = shuffle(X, y)
c = len(np.unique(y))
foldIndices = []
n = np.iinfo(np.int).max
for i in range(0, c):
idx = np.where(y == i)[0]
n = min(n, idx.shape[0])
foldIndices.append(idx.tolist());
if n < self.k:
self.k = n
foldSize = int(math.floor(n / self.k))
if self.threshold_up==0:
threshold_r = [0]
else:
threshold_r = frange(0, self.threshold_up, 0.001)
rates = {}
for threshold in threshold_r:
rates[threshold] = TFPN()
for i in range(0, self.k):
self.logger.info("Processing fold %d/%d." % (i + 1, self.k))
l = int(i * foldSize)
h = int((i + 1) * foldSize)
testIdx = slice_2d(foldIndices, rows=range(0, c), cols=range(l, h))
trainIdx = slice_2d(foldIndices, rows=range(0, c), cols=range(0, l))
trainIdx.extend(slice_2d(foldIndices, rows=range(0, c), cols=range(h, n)))
Xtrain = [X[t] for t in trainIdx]
ytrain = y[trainIdx]
self.model.compute(Xtrain, ytrain)
predictions = {}
for j in testIdx:
predictions[j] = self.model.predict(X[j])
if self.threshold_up == 0:
rates[threshold] += self.simple_evaluate(testIdx, predictions, X, y)
else:
for threshold in threshold_r:
rates[threshold] += self.binary_evaluate(testIdx, predictions, X, y, threshold)
for threshold in threshold_r:
r = rates[threshold]
self.add(ValidationResult(r.TP, r.TN, r.FP, r.FN, threshold))
def simple_evaluate(self, testIdX, predictions, X, y):
r = TFPN()
for j in testIdX:
prediction, info = predictions[j]
if prediction==y[j]:
r.TP += 1
else:
r.FP += 1
if self._debug:
self.display_prediction_error(X[j], y[j], prediction)
return r
def display_prediction_error(self, data, actual, predicted):
error_msg = "%d!=%d" % (actual, predicted)
self.logger.debug("prediction error, actual!=predicted: " + error_msg)
cv2.imshow(error_msg, data)
cv2.waitKey(1)
def binary_evaluate(self, testIdX, predictions, X, y, threshold):
r = TFPN()
for lbl in np.unique(y):
for j in testIdX:
_, info = predictions[j]
labels = info['labels']
idx = labels==lbl
sims = info['similarities']
sims = sims[idx]
sims = sims[:1]
score = np.sum(sims)/float(sims.size)
if score>threshold:
if lbl==y[j]:
r.TP += 1
else:
r.FP += 1
else:
if lbl==y[j]:
r.FN += 1
else:
r.TN += 1
return r
def __repr__(self):
return "k-Fold Cross Validation (model=%s, k=%s, results=%s)" % (self.model, self.k, self.validation_results)
class LeaveOneOutCrossValidation(ValidationStrategy):
def __init__(self, model, k=0):
super(LeaveOneOutCrossValidation, self).__init__(model=model)
self.logger = logging.getLogger("facerec.validation.LeaveOneOutCrossValidation")
self.k = k
def validate(self, X, y, description="ExperimentName"):
X, y = shuffle(X, y)
true_positives, false_positives, true_negatives, false_negatives = (0, 0, 0, 0)
if self.k==0:
self.k = y.shape[0]
for i in range(0, self.k):
self.logger.info("Processing fold %d/%d." % (i + 1, self.k))
trainIdx = []
trainIdx.extend(range(0, i))
trainIdx.extend(range(i + 1, self.k))
Xtrain = [X[t] for t in trainIdx]
ytrain = y[trainIdx]
self.model.compute(Xtrain, ytrain)
prediction = self.model.predict(X[i])[0]
if prediction == y[i]:
true_positives += 1
else:
false_positives += 1
self.add(ValidationResult(true_positives, true_negatives, false_positives, false_negatives, description))
def __repr__(self):
return "Leave-One-Out Cross Validation (model=%s, results=%s)"%(self.model, self.validation_results)
class LeaveOneClassOutCrossValidation(ValidationStrategy):
def __init__(self, model):
super(LeaveOneClassOutCrossValidation, self).__init__(model=model)
self.logger = logging.getLogger("facerec.validation.LeaveOneClassOutCrossValidation")
def validate(self, X, y, g, description="ExperimentName"):
true_positives, false_positives, true_negatives, false_negatives = (0, 0, 0, 0)
for i in range(0, len(np.unique(y))):
self.logger.info("Validating Class %s." % i)
trainIdx = np.where(y != i)[0]
testIdx = np.where(y == i)[0]
Xtrain = [X[t] for t in trainIdx]
gtrain = g[trainIdx]
self.model.compute(Xtrain, gtrain)
for j in testIdx:
prediction = self.model.predict(X[j])[0]
if prediction == g[j]:
true_positives += 1
else:
false_positives += 1
self.add(ValidationResult(true_positives, true_negatives, false_positives, false_negatives, description))
def __repr__(self):
return "Leave-One-Class-Out Cross Validation (model=%s, results=%s)"%(self.model, self.validation_results)
class SimpleValidation(ValidationStrategy):
def __init__(self, model):
super(SimpleValidation, self).__init__(model=model)
self.logger = logging.getLogger("facerec.validation.SimpleValidation")
def validate(self, Xtrain, ytrain, Xtest, ytest, description="ExperimentName"):
self.logger.info("Simple Validation.")
self.model.compute(Xtrain, ytrain)
self.logger.debug("Model computed.")
true_positives, false_positives, true_negatives, false_negatives = (0, 0, 0, 0)
count = 0
for i in ytest:
self.logger.debug("Predicting %s/%s." % (count, len(ytest)))
prediction = self.model.predict(Xtest[i])[0]
if prediction == ytest[i]:
true_positives += 1
else:
false_positives += 1
count += 1
self.add(ValidationResult(true_positives, true_negatives, false_positives, false_negatives, description))
def __repr__(self):
return "Simple Validation (model=%s)" % self.model
class Solution(object):
def solve(self, cipher):
N, A = cipher
l = N + 1
E = 0
for cur in A:
k = 0
for a in A:
if a >= cur:
k += 1
E += float(l) / (k + 1)
return "%.2f" % E
if __name__ == "__main__":
import sys
f = open("0.in", "r")
solution = Solution()
testcases = int(f.readline().strip())
for t in xrange(testcases):
N = int(f.readline().strip())
A = map(int, f.readline().strip().split(' '))
cipher = N, A
s = "%s\n" % (solution.solve(cipher))
print s,
import numpy as np
import cv2
from time import clock
from numpy import pi, sin, cos
import common
class VideoSynthBase(object):
def __init__(self, size=None, noise=0.0, bg = None, **params):
self.bg = None
self.frame_size = (640, 480)
if bg is not None:
self.bg = cv2.imread(bg, 1)
h, w = self.bg.shape[:2]
self.frame_size = (w, h)
if size is not None:
w, h = map(int, size.split('x'))
self.frame_size = (w, h)
self.bg = cv2.resize(self.bg, self.frame_size)
self.noise = float(noise)
def render(self, dst):
pass
def read(self, dst=None):
w, h = self.frame_size
if self.bg is None:
buf = np.zeros((h, w, 3), np.uint8)
else:
buf = self.bg.copy()
self.render(buf)
if self.noise > 0.0:
noise = np.zeros((h, w, 3), np.int8)
cv2.randn(noise, np.zeros(3), np.ones(3)*255*self.noise)
buf = cv2.add(buf, noise, dtype=cv2.CV_8UC3)
return True, buf
class Chess(VideoSynthBase):
def __init__(self, **kw):
super(Chess, self).__init__(**kw)
w, h = self.frame_size
self.grid_size = sx, sy = 10, 7
white_quads = []
black_quads = []
for i, j in np.ndindex(sy, sx):
q = [[j, i, 0], [j+1, i, 0], [j+1, i+1, 0], [j, i+1, 0]]
[white_quads, black_quads][(i + j) % 2].append(q)
self.white_quads = np.float32(white_quads)
self.black_quads = np.float32(black_quads)
fx = 0.9
self.K = np.float64([[fx*w, 0, 0.5*(w-1)],
[0, fx*w, 0.5*(h-1)],
[0.0,0.0,      1.0]])
self.dist_coef = np.float64([-0.2, 0.1, 0, 0])
self.t = 0
def draw_quads(self, img, quads, color = (0, 255, 0)):
img_quads = cv2.projectPoints(quads.reshape(-1, 3), self.rvec, self.tvec, self.K, self.dist_coef) [0]
img_quads.shape = quads.shape[:2] + (2,)
for q in img_quads:
cv2.fillConvexPoly(img, np.int32(q*4), color, cv2.CV_AA, shift=2)
def render(self, dst):
t = self.t
self.t += 1.0/30.0
sx, sy = self.grid_size
center = np.array([0.5*sx, 0.5*sy, 0.0])
phi = pi/3 + sin(t*3)*pi/8
c, s = cos(phi), sin(phi)
ofs = np.array([sin(1.2*t), cos(1.8*t), 0]) * sx * 0.2
eye_pos = center + np.array([cos(t)*c, sin(t)*c, s]) * 15.0 + ofs
target_pos = center + ofs
R, self.tvec = common.lookat(eye_pos, target_pos)
self.rvec = common.mtx2rvec(R)
self.draw_quads(dst, self.white_quads, (245, 245, 245))
self.draw_quads(dst, self.black_quads, (10, 10, 10))
classes = dict(chess=Chess)
def create_capture(source):
try: source = int(source)
except ValueError: pass
else:
return cv2.VideoCapture(source)
source = str(source).strip()
if source.startswith('synth'):
ss = filter(None, source.split(':'))
params = dict( s.split('=') for s in ss[1:] )
try: Class = classes[params['class']]
except: Class = VideoSynthBase
return Class(**params)
return cv2.VideoCapture(source)
presets = dict(
empty = 'synth:',
lena = 'synth:bg=../cpp/lena.jpg:noise=0.1',
chess = 'synth:class=chess:bg=../cpp/lena.jpg:noise=0.1:size=640x480'
)
if __name__ == '__main__':
import sys
import getopt
print 'USAGE: video.py [--shotdir <dir>] [source0] [source1] ...'
print "source: '<int>' or '<filename>' or 'synth:<params>'"
print
args, sources = getopt.getopt(sys.argv[1:], '', 'shotdir=')
args = dict(args)
shotdir = args.get('--shotdir', '.')
if len(sources) == 0:
sources = [ presets['chess'] ]
print 'Press SPACE to save current frame'
caps = map(create_capture, sources)
shot_idx = 0
while True:
imgs = []
for i, cap in enumerate(caps):
ret, img = cap.read()
imgs.append(img)
cv2.imshow('capture %d' % i, img)
ch = cv2.waitKey(1)
if ch == 27:
break
if ch == ord(' '):
for i, img in enumerate(imgs):
fn = '%s/shot_%d_%03d.bmp' % (shotdir, i, shot_idx)
cv2.imwrite(fn, img)
print fn, 'saved'
shot_idx += 1
import json
from django.http import HttpResponse
from django.shortcuts import render
from django.template.response import SimpleTemplateResponse
from django.utils.decorators import method_decorator
from django.views.decorators.csrf import csrf_exempt
from django.views.generic import TemplateView, View
from rake import rake
class MainView(View):
template_name = "tagging.html"
@method_decorator(csrf_exempt)
def dispatch(self, *args, **kwargs):
return super(MainView, self).dispatch(*args, **kwargs)
def get(self, request, *args, **kwargs):
return SimpleTemplateResponse(MainView.template_name)
def post(self, request):
dic = json.loads(request.body)
ret = rake.Rake().run(dic["text"])
ret = filter(lambda x: len(x.split(" ")) > 1, map(lambda x: x[0], ret))
ret = {"keywords": list(ret)}
return HttpResponse(json.dumps(ret))
from facerec_py.facerec.normalization import minmax
import os as os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
try:
from PIL import Image
except ImportError:
import Image
import math as math
def create_font(fontname='Tahoma', fontsize=10):
return { 'fontname': fontname, 'fontsize':fontsize }
def plot_gray(X,  sz=None, filename=None):
if not sz is None:
X = X.reshape(sz)
X = minmax(I, 0, 255)
fig = plt.figure()
implot = plt.imshow(np.asarray(Ig), cmap=cm.gray)
if filename is None:
plt.show()
else:
fig.savefig(filename, format="png", transparent=False)
def plot_eigenvectors(eigenvectors, num_components, sz, filename=None, start_component=0, rows = None, cols = None, title="Subplot", color=True):
if (rows is None) or (cols is None):
rows = cols = int(math.ceil(np.sqrt(num_components)))
num_components = np.min(num_components, eigenvectors.shape[1])
fig = plt.figure()
for i in range(start_component, num_components):
vi = eigenvectors[0:,i].copy()
vi = minmax(np.asarray(vi), 0, 255, dtype=np.uint8)
vi = vi.reshape(sz)
ax0 = fig.add_subplot(rows,cols,(i-start_component)+1)
plt.setp(ax0.get_xticklabels(), visible=False)
plt.setp(ax0.get_yticklabels(), visible=False)
plt.title("%s
if color:
implot = plt.imshow(np.asarray(vi))
else:
implot = plt.imshow(np.asarray(vi), cmap=cm.grey)
if filename is None:
fig.show()
else:
fig.savefig(filename, format="png", transparent=False)
def subplot(title, images, rows, cols, sptitle="subplot", sptitles=[], colormap=cm.gray, ticks_visible=True, filename=None):
fig = plt.figure()
fig.text(.5, .95, title, horizontalalignment='center')
for i in xrange(len(images)):
ax0 = fig.add_subplot(rows,cols,(i+1))
plt.setp(ax0.get_xticklabels(), visible=False)
plt.setp(ax0.get_yticklabels(), visible=False)
if len(sptitles) == len(images):
plt.title("%s
else:
plt.title("%s
plt.imshow(np.asarray(images[i]), cmap=colormap)
if filename is None:
plt.show()
else:
fig.savefig(filename)
from expr.feature import *
class WeightedHS(SpatialHistogram):
def __init__(self, lbp_operator=ExtendedLBP(3), sz=(8, 8), X=None, y=None):
super(WeightedHS, self).__init__(lbp_operator, sz)
self.weights = {}
self.Hs = {}
self.L = self.calculate_L(X)
self.X = X
self.y = y
def init_cache(self):
self.weights = {}
self.Hs = {}
def compute(self, X, y):
raise NotImplementedError("Not and won't be implemented.")
def hist_intersect(self, p, q):
p = np.asarray(p).flatten()
q = np.asarray(q).flatten()
sim = np.sum(np.minimum(p, q))
return sim
def get_weight(self, row, col):
args = (row, col)
if args not in self.weights:
self.weights[args] = self._get_weight(row, col)
return self.weights[args]
def _get_weight(self, row, col):
C = len(np.unique(self.y))
m_I = 0
for i in np.unique(self.y):
N_i = self.get_N(i)
Hs_i = self.get_Hs(i, row, col)
for k in xrange(len(Hs_i)):
for j in xrange(k):
m_I += self.hist_intersect(Hs_i[j], Hs_i[k])
m_I *= 2.0/(N_i*(N_i-1))
m_I *= 1.0/C
S2_I = 0
for i in np.unique(self.y):
Hs_i = self.get_Hs(i, row, col)
for k in xrange(len(Hs_i)):
for j in xrange(k):
S2_I += (self.hist_intersect(Hs_i[j], Hs_i[k])-m_I)**2
m_E = 0
for i in np.unique(self.y):
for j in np.unique(self.y[self.y != i]):
N_i = self.get_N(i)
N_j = self.get_N(j)
Hs_i = self.get_Hs(i, row, col)
Hs_j = self.get_Hs(j, row, col)
for h_i in Hs_i:
for h_j in Hs_j:
m_E += self.hist_intersect(h_i, h_j)
m_E *= 1.0/(N_i*N_j)
m_E *= 2.0/(C*(C-1))
S2_E = 0
for i in np.unique(self.y):
for j in np.unique(self.y[self.y!=i]):
Hs_i = self.get_Hs(i, row, col)
Hs_j = self.get_Hs(j, row, col)
for h_i in Hs_i:
for h_j in Hs_j:
S2_E += (self.hist_intersect(h_i, h_j)-m_E)**2
weight = (m_I-m_E)**2/(S2_I+S2_E)
return weight
def get_N(self, i):
return len(self.X[self.y==i])
def calculate_L(self, X):
L = []
for x in X:
L.append(self.lbp_operator(x))
return np.asarray(L)
def get_Hs(self, label, row, col):
args = (label, row, col)
if args not in self.Hs:
self.Hs[args] = self._get_Hs(label, row, col)
return self.Hs[args]
def _get_Hs(self, label, row, col):
L = self.L[self.y==label]
Hs = []
for l in L:
lbp_height, lbp_width = l.shape
grid_rows, grid_cols = self.sz
py = int(np.floor(lbp_height / grid_rows))
px = int(np.floor(lbp_width / grid_cols))
C = l[row * py:(row + 1) * py, col * px:(col + 1) * px]
Hs.append(super(WeightedHS, self)._get_histogram(C, row, col))
return Hs
def _get_histogram(self, C, row, col, normed=True):
return self.get_weight(row, col)* \
super(WeightedHS, self)._get_histogram(C, row, col)
class ConcatendatedWeightedHS(SpatialHistogram):
def __init__(self, lbp_operator=ExtendedLBP(radius=3), sz=(8, 8)):
super(ConcatendatedWeightedHS, self).__init__(lbp_operator, sz)
self.weights = None
def compute(self, X, y):
self.weights = self.construct_wights(X, y)
super(ConcatendatedWeightedHS, self).compute(X, y)
def construct_wights(self, X, y):
X = np.asarray(X)
n_gabors = X.shape[1]
weights = [WeightedHS(X=X[:, i, :, :], y=y) for i in xrange(n_gabors)]
return weights
def spatially_enhanced_histogram(self, X):
hists = []
for gabor_idx, x in enumerate(X):
hist = self.weights[gabor_idx].spatially_enhanced_histogram(x)
hists.extend(hist)
return np.asarray(hists)
class WeightedLGBPHS(ChainedFeature):
def __init__(self, n_orient=4, n_scale=2, lbp_operator=ExtendedLBP(radius=3)):
gabor = GaborFilterCv2(n_orient, n_scale)
lbp_hist = ConcatendatedWeightedHS(lbp_operator=lbp_operator)
super(WeightedLGBPHS, self).__init__(gabor, lbp_hist)
import sys
import ns.applications
import ns.core
import ns.internet
import ns.mobility
import ns.network
import ns.point_to_point
import ns.wifi
def SetPosition(node, position):
mobility = node.GetObject(ns.mobility.MobilityModel.GetTypeId())
mobility.SetPosition(position)
def GetPosition(node):
mobility = node.GetObject(ns.mobility.MobilityModel.GetTypeId())
return mobility.GetPosition()
def AdvancePosition(node):
pos = GetPosition(node);
pos.x += 5.0
if pos.x >= 210.0:
return
SetPosition(node, pos)
ns.core.Simulator.Schedule(ns.core.Seconds(1.0), AdvancePosition, node)
def main(argv):
ns.core.CommandLine().Parse(argv)
ns.network.Packet.EnablePrinting();
ns.core.Config.SetDefault("ns3::WifiRemoteStationManager::RtsCtsThreshold", ns.core.StringValue("0"))
ns.core.Config.SetDefault("ns3::WifiRemoteStationManager::FragmentationThreshold", ns.core.StringValue("2200"))
wifi = ns.wifi.WifiHelper.Default()
mobility = ns.mobility.MobilityHelper()
stas = ns.network.NodeContainer()
ap = ns.network.NodeContainer()
packetSocket = ns.network.PacketSocketHelper()
stas.Create(2)
ap.Create(1)
packetSocket.Install(stas)
packetSocket.Install(ap)
wifiPhy = ns.wifi.YansWifiPhyHelper.Default()
wifiChannel = ns.wifi.YansWifiChannelHelper.Default()
wifiPhy.SetChannel(wifiChannel.Create())
ssid = ns.wifi.Ssid("wifi-default")
wifi.SetRemoteStationManager("ns3::ArfWifiManager")
wifiMac = ns.wifi.NqosWifiMacHelper.Default()
wifiMac.SetType("ns3::StaWifiMac",
"Ssid", ns.wifi.SsidValue(ssid),
"ActiveProbing", ns.core.BooleanValue(False))
staDevs = wifi.Install(wifiPhy, wifiMac, stas)
wifiMac.SetType("ns3::ApWifiMac",
"Ssid", ns.wifi.SsidValue(ssid),
"BeaconGeneration", ns.core.BooleanValue(True),
"BeaconInterval", ns.core.TimeValue(ns.core.Seconds(2.5)))
wifi.Install(wifiPhy, wifiMac, ap)
mobility.Install(stas)
mobility.Install(ap)
ns.core.Simulator.Schedule(ns.core.Seconds(1.0), AdvancePosition, ap.Get(0))
socket = ns.network.PacketSocketAddress()
socket.SetSingleDevice(staDevs.Get(0).GetIfIndex())
socket.SetPhysicalAddress(staDevs.Get(1).GetAddress())
socket.SetProtocol(1)
onoff = ns.applications.OnOffHelper("ns3::PacketSocketFactory", ns.network.Address(socket))
onoff.SetAttribute("OnTime", ns.core.RandomVariableValue(ns.core.ConstantVariable(42)))
onoff.SetAttribute("OffTime", ns.core.RandomVariableValue(ns.core.ConstantVariable(0)))
apps = onoff.Install(ns.network.NodeContainer(stas.Get(0)))
apps.Start(ns.core.Seconds(0.5))
apps.Stop(ns.core.Seconds(43.0))
ns.core.Simulator.Stop(ns.core.Seconds(44.0))
ns.core.Simulator.Run()
ns.core.Simulator.Destroy()
return 0
if __name__ == '__main__':
sys.exit(main(sys.argv))
import sys
import ns.applications
import ns.core
import ns.flow_monitor
import ns.internet
import ns.mobility
import ns.network
import ns.olsr
import ns.wifi
DISTANCE = 100
NUM_NODES_SIDE = 3
def main(argv):
cmd = ns.core.CommandLine()
cmd.NumNodesSide = None
cmd.AddValue("NumNodesSide", "Grid side number of nodes (total number of nodes will be this number squared)")
cmd.Results = None
cmd.AddValue("Results", "Write XML results to file")
cmd.Plot = None
cmd.AddValue("Plot", "Plot the results using the matplotlib python module")
cmd.Parse(argv)
wifi = ns.wifi.WifiHelper.Default()
wifiMac = ns.wifi.NqosWifiMacHelper.Default()
wifiPhy = ns.wifi.YansWifiPhyHelper.Default()
wifiChannel = ns.wifi.YansWifiChannelHelper.Default()
wifiPhy.SetChannel(wifiChannel.Create())
ssid = ns.wifi.Ssid("wifi-default")
wifi.SetRemoteStationManager("ns3::ArfWifiManager")
wifiMac.SetType ("ns3::AdhocWifiMac",
"Ssid", ns.wifi.SsidValue(ssid))
internet = ns.internet.InternetStackHelper()
list_routing = ns.internet.Ipv4ListRoutingHelper()
olsr_routing = ns.olsr.OlsrHelper()
static_routing = ns.internet.Ipv4StaticRoutingHelper()
list_routing.Add(static_routing, 0)
list_routing.Add(olsr_routing, 100)
internet.SetRoutingHelper(list_routing)
ipv4Addresses = ns.internet.Ipv4AddressHelper()
ipv4Addresses.SetBase(ns.network.Ipv4Address("10.0.0.0"), ns.network.Ipv4Mask("255.255.255.0"))
port = 9
onOffHelper = ns.applications.OnOffHelper("ns3::UdpSocketFactory",
ns.network.Address(ns.network.InetSocketAddress(ns.network.Ipv4Address("10.0.0.1"), port)))
onOffHelper.SetAttribute("DataRate", ns.network.DataRateValue(ns.network.DataRate("100kbps")))
onOffHelper.SetAttribute("OnTime", ns.core.RandomVariableValue(ns.core.ConstantVariable(1)))
onOffHelper.SetAttribute("OffTime", ns.core.RandomVariableValue(ns.core.ConstantVariable(0)))
addresses = []
nodes = []
if cmd.NumNodesSide is None:
num_nodes_side = NUM_NODES_SIDE
else:
num_nodes_side = int(cmd.NumNodesSide)
for xi in range(num_nodes_side):
for yi in range(num_nodes_side):
node = ns.network.Node()
nodes.append(node)
internet.Install(ns.network.NodeContainer(node))
mobility = ns.mobility.ConstantPositionMobilityModel()
mobility.SetPosition(ns.core.Vector(xi*DISTANCE, yi*DISTANCE, 0))
node.AggregateObject(mobility)
devices = wifi.Install(wifiPhy, wifiMac, node)
ipv4_interfaces = ipv4Addresses.Assign(devices)
addresses.append(ipv4_interfaces.GetAddress(0))
for i, node in enumerate(nodes):
destaddr = addresses[(len(addresses) - 1 - i) % len(addresses)]
onOffHelper.SetAttribute("Remote", ns.network.AddressValue(ns.network.InetSocketAddress(destaddr, port)))
app = onOffHelper.Install(ns.network.NodeContainer(node))
app.Start(ns.core.Seconds(ns.core.UniformVariable(20, 30).GetValue()))
flowmon_helper = ns.flow_monitor.FlowMonitorHelper()
monitor = flowmon_helper.InstallAll()
monitor = flowmon_helper.GetMonitor()
monitor.SetAttribute("DelayBinWidth", ns.core.DoubleValue(0.001))
monitor.SetAttribute("JitterBinWidth", ns.core.DoubleValue(0.001))
monitor.SetAttribute("PacketSizeBinWidth", ns.core.DoubleValue(20))
ns.core.Simulator.Stop(ns.core.Seconds(44.0))
ns.core.Simulator.Run()
def print_stats(os, st):
print >> os, "  Tx Bytes: ", st.txBytes
print >> os, "  Rx Bytes: ", st.rxBytes
print >> os, "  Tx Packets: ", st.txPackets
print >> os, "  Rx Packets: ", st.rxPackets
print >> os, "  Lost Packets: ", st.lostPackets
if st.rxPackets > 0:
print >> os, "  Mean{Delay}: ", (st.delaySum.GetSeconds() / st.rxPackets)
print >> os, "  Mean{Jitter}: ", (st.jitterSum.GetSeconds() / (st.rxPackets-1))
print >> os, "  Mean{Hop Count}: ", float(st.timesForwarded) / st.rxPackets + 1
if 0:
print >> os, "Delay Histogram"
for i in range(st.delayHistogram.GetNBins () ):
print >> os, " ",i,"(", st.delayHistogram.GetBinStart (i), "-", \
st.delayHistogram.GetBinEnd (i), "): ", st.delayHistogram.GetBinCount (i)
print >> os, "Jitter Histogram"
for i in range(st.jitterHistogram.GetNBins () ):
print >> os, " ",i,"(", st.jitterHistogram.GetBinStart (i), "-", \
st.jitterHistogram.GetBinEnd (i), "): ", st.jitterHistogram.GetBinCount (i)
print >> os, "PacketSize Histogram"
for i in range(st.packetSizeHistogram.GetNBins () ):
print >> os, " ",i,"(", st.packetSizeHistogram.GetBinStart (i), "-", \
st.packetSizeHistogram.GetBinEnd (i), "): ", st.packetSizeHistogram.GetBinCount (i)
for reason, drops in enumerate(st.packetsDropped):
print "  Packets dropped by reason %i: %i" % (reason, drops)
monitor.CheckForLostPackets()
classifier = flowmon_helper.GetClassifier()
if cmd.Results is None:
for flow_id, flow_stats in monitor.GetFlowStats():
t = classifier.FindFlow(flow_id)
proto = {6: 'TCP', 17: 'UDP'} [t.protocol]
print "FlowID: %i (%s %s/%s --> %s/%i)" % \
(flow_id, proto, t.sourceAddress, t.sourcePort, t.destinationAddress, t.destinationPort)
print_stats(sys.stdout, flow_stats)
else:
print monitor.SerializeToXmlFile(cmd.Results, True, True)
if cmd.Plot is not None:
import pylab
delays = []
for flow_id, flow_stats in monitor.GetFlowStats():
tupl = classifier.FindFlow(flow_id)
if tupl.protocol == 17 and tupl.sourcePort == 698:
continue
delays.append(flow_stats.delaySum.GetSeconds() / flow_stats.rxPackets)
pylab.hist(delays, 20)
pylab.xlabel("Delay (s)")
pylab.ylabel("Number of Flows")
pylab.show()
return 0
if __name__ == '__main__':
sys.exit(main(sys.argv))
import math
import ns.wifi
import ns.network
import goocanvas
from visualizer.base import Link, transform_distance_canvas_to_simulation
class WifiLink(Link):
def __init__(self, parent_canvas_item, sta, dev):
self.node1 = sta
self.dev = dev
self.node2 = None
self.canvas_item = goocanvas.Group(parent=parent_canvas_item)
self.invisible_line = goocanvas.Polyline(parent=self.canvas_item,
line_width=25.0,
visibility=goocanvas.ITEM_HIDDEN)
self.visible_line = goocanvas.Polyline(parent=self.canvas_item,
line_width=1.0,
stroke_color_rgba=0xC00000FF,
line_dash=goocanvas.LineDash([2.0, 2.0 ]))
self.invisible_line.props.pointer_events = (goocanvas.EVENTS_STROKE_MASK
|goocanvas.EVENTS_FILL_MASK
|goocanvas.EVENTS_PAINTED_MASK)
self.canvas_item.set_data("pyviz-object", self)
self.canvas_item.lower(None)
self.set_ap(None)
def set_ap(self, ap):
if ap is self.node2:
return
if self.node2 is not None:
self.node2.remove_link(self)
self.node2 = ap
if self.node2 is None:
self.canvas_item.set_property("visibility", goocanvas.ITEM_HIDDEN)
else:
self.node2.add_link(self)
self.canvas_item.set_property("visibility", goocanvas.ITEM_VISIBLE)
self.update_points()
def update_points(self):
if self.node2 is None:
return
pos1_x, pos1_y = self.node1.get_position()
pos2_x, pos2_y = self.node2.get_position()
points = goocanvas.Points([(pos1_x, pos1_y), (pos2_x, pos2_y)])
self.visible_line.set_property("points", points)
self.invisible_line.set_property("points", points)
def destroy(self):
self.canvas_item.destroy()
self.node1 = None
self.node2 = None
def tooltip_query(self, tooltip):
pos1_x, pos1_y = self.node1.get_position()
pos2_x, pos2_y = self.node2.get_position()
dx = pos2_x - pos1_x
dy = pos2_y - pos1_y
d = transform_distance_canvas_to_simulation(math.sqrt(dx*dx + dy*dy))
mac = self.dev.GetMac()
tooltip.set_text(("WiFi link between STA Node %i and AP Node %i; distance=%.2f m.\n"
"SSID: %s\n"
"BSSID: %s")
% (self.node1.node_index, self.node2.node_index, d,
mac.GetSsid(), mac.GetBssid()))
class WifiLinkMonitor(object):
def __init__(self, dummy_viz):
self.access_points = {}
self.stations = []
def scan_nodes(self, viz):
for (sta_netdevice, viz_node, wifi_link) in self.stations:
wifi_link.destroy()
self.access_points = {}
self.stations = []
for node in viz.nodes.itervalues():
ns3_node = ns.network.NodeList.GetNode(node.node_index)
for devI in range(ns3_node.GetNDevices()):
dev = ns3_node.GetDevice(devI)
if not isinstance(dev, ns.wifi.WifiNetDevice):
continue
wifi_mac = dev.GetMac()
if isinstance(wifi_mac, ns.wifi.StaWifiMac):
wifi_link = WifiLink(viz.links_group, node, dev)
self.stations.append((dev, node, wifi_link))
elif isinstance(wifi_mac, ns.wifi.ApWifiMac):
bssid = ns.network.Mac48Address.ConvertFrom(dev.GetAddress())
self.access_points[str(bssid)] = node
def simulation_periodic_update(self, viz):
for (sta_netdevice, viz_node, wifi_link) in self.stations:
if not sta_netdevice.IsLinkUp():
wifi_link.set_ap(None)
continue
bssid = str(sta_netdevice.GetMac().GetBssid())
if bssid == '00:00:00:00:00:00':
wifi_link.set_ap(None)
continue
ap = self.access_points[bssid]
wifi_link.set_ap(ap)
def update_view(self, viz):
for (dummy_sta_netdevice, dummy_viz_node, wifi_link) in self.stations:
if wifi_link is not None:
wifi_link.update_points()
def register(viz):
link_monitor = WifiLinkMonitor(viz)
viz.connect("simulation-periodic-update", link_monitor.simulation_periodic_update)
viz.connect("update-view", link_monitor.update_view)
viz.connect("topology-scanned", link_monitor.scan_nodes)
class Solution:
def woodCut(self, L, k):
if not L:
return 0
maxa = max(L)
lo = 0
hi = maxa+1
while lo < hi:
m = (lo+hi)/2
if m == 0:
return m
cnt = 0
for l in L:
cnt += l/m
if cnt >= k:
lo = m+1
else:
hi = m
return lo-1
if __name__ == "__main__":
assert Solution().woodCut([2147483644, 2147483645, 2147483646, 2147483647], 4) == 2147483644
class TrieNode(object):
def __init__(self, char):
self.char = char
self.word = None
self.children = {}
def __repr__(self):
return repr(self.char)
class Trie(object):
def __init__(self):
self.root = TrieNode(None)
def add(self, word):
word = word.lower()
cur = self.root
for c in word:
if c not in cur.children:
cur.children[c] = TrieNode(c)
cur = cur.children[c]
cur.word = word
class Solution:
directions = [(0, 1), (0, -1), (-1, 0), (1, 0)]
def wordSearchII_TLE(self, board, words):
trie = Trie()
for word in words:
trie.add(word)
ret = set()
visited = set()
for i in xrange(len(board)):
for j in xrange(len(board[0])):
self.dfs(board, i, j, trie.root, visited, ret)
return list(ret)
def dfs(self, board, i, j, parent, visited, ret):
c = board[i][j]
visited.add((i, j))
if c in parent.children:
cur = parent.children[c]
if cur.word:
ret.add(cur.word)
for direction in Solution.directions:
row = i+direction[0]
col = j+direction[1]
if 0 <= row < len(board) and 0 <= col < len(board[0]) and (row, col) not in visited:
self.dfs(board, row, col, cur, visited, ret)
visited.remove((i, j))
def wordSearchII(self, board, words):
ret = []
for word in words:
trie = Trie()
trie.add(word)
visited = set()
r = set()
found = False
for i in xrange(len(board)):
if not found:
for j in xrange(len(board[0])):
self.dfs2(board, i, j, trie.root, visited, r)
if len(r) == 1:
ret.append(r.pop())
found = True
break
return ret
def dfs2(self, board, i, j, parent, visited, ret):
c = board[i][j]
visited.add((i, j))
if c in parent.children:
cur = parent.children[c]
if cur.word:
ret.add(cur.word)
for direction in Solution.directions:
row = i+direction[0]
col = j+direction[1]
if 0 <= row < len(board) and 0 <= col < len(board[0]) and (row, col) not in visited and not ret:
self.dfs2(board, row, col, cur, visited, ret)
visited.remove((i, j))
if __name__ == "__main__":
board = ["aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
"aaaaaaaaaaaaaaaaaaaaaaaaaaaaab"]
words = {"baaaaaaaaaaaaa", "a", "aa", "aaaa", "aaaax", "abaaabbaz"}
assert Solution().wordSearchII(board, words) == ['a', 'aa', 'aaaa', 'baaaaaaaaaaaaa']
import os
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "tagr.settings")
from django.core.wsgi import get_wsgi_application
from whitenoise.django import DjangoWhiteNoise
application = get_wsgi_application()
application = DjangoWhiteNoise(application)
import os
import os.path
import sys
import subprocess
import shlex
import Options
import Utils
import Logs
import TaskGen
import Build
import re
from waflib.Errors import WafError
APPNAME=None
VERSION=None
bld=None
def get_command_template(env, arguments=()):
cmd = Options.options.command_template or '%s'
for arg in arguments:
cmd = cmd + " " + arg
return cmd
if hasattr(os.path, "relpath"):
relpath = os.path.relpath
else:
def relpath(path, start=os.path.curdir):
if not path:
raise ValueError("no path specified")
start_list = os.path.abspath(start).split(os.path.sep)
path_list = os.path.abspath(path).split(os.path.sep)
i = len(os.path.commonprefix([start_list, path_list]))
rel_list = [os.path.pardir] * (len(start_list)-i) + path_list[i:]
if not rel_list:
return os.path.curdir
return os.path.join(*rel_list)
from waflib import Context
def find_program(program_name, env):
launch_dir = os.path.abspath(Context.launch_dir)
found_programs = []
for obj in bld.all_task_gen:
if not getattr(obj, 'is_ns3_program', False):
continue
if not (obj.path.abspath().startswith(launch_dir)
or obj.path.abspath(env).startswith(launch_dir)):
continue
name1 = obj.target
name2 = os.path.join(relpath(obj.path.abspath(), launch_dir), obj.target)
names = [name1, name2]
found_programs.extend(names)
if program_name in names:
return obj
raise ValueError("program '%s' not found; available programs are: %r"
% (program_name, found_programs))
def get_proc_env(os_env=None):
env = bld.env
if sys.platform == 'linux2':
pathvar = 'LD_LIBRARY_PATH'
elif sys.platform == 'darwin':
pathvar = 'DYLD_LIBRARY_PATH'
elif sys.platform == 'win32':
pathvar = 'PATH'
elif sys.platform == 'cygwin':
pathvar = 'PATH'
elif sys.platform.startswith('freebsd'):
pathvar = 'LD_LIBRARY_PATH'
else:
Logs.warn(("Don't know how to configure "
"dynamic library path for the platform %r;"
" assuming it's LD_LIBRARY_PATH.") % (sys.platform,))
pathvar = 'LD_LIBRARY_PATH'
proc_env = dict(os.environ)
if os_env is not None:
proc_env.update(os_env)
if pathvar is not None:
if pathvar in proc_env:
proc_env[pathvar] = os.pathsep.join(list(env['NS3_MODULE_PATH']) + [proc_env[pathvar]])
else:
proc_env[pathvar] = os.pathsep.join(list(env['NS3_MODULE_PATH']))
pymoddir = bld.path.find_dir('bindings/python').get_bld().abspath()
pyvizdir = bld.path.find_dir('src/visualizer').abspath()
if 'PYTHONPATH' in proc_env:
proc_env['PYTHONPATH'] = os.pathsep.join([pymoddir, pyvizdir] + [proc_env['PYTHONPATH']])
else:
proc_env['PYTHONPATH'] = os.pathsep.join([pymoddir, pyvizdir])
if 'PATH' in proc_env:
proc_env['PATH'] = os.pathsep.join(list(env['NS3_EXECUTABLE_PATH']) + [proc_env['PATH']])
else:
proc_env['PATH'] = os.pathsep.join(list(env['NS3_EXECUTABLE_PATH']))
return proc_env
def run_argv(argv, env, os_env=None, cwd=None, force_no_valgrind=False):
proc_env = get_proc_env(os_env)
if Options.options.valgrind and not force_no_valgrind:
if Options.options.command_template:
raise WafError("Options --command-template and --valgrind are conflicting")
if not env['VALGRIND']:
raise WafError("valgrind is not installed")
argv = [env['VALGRIND'], "--leak-check=full", "--show-reachable=yes", "--error-exitcode=1"] + argv
proc = subprocess.Popen(argv, env=proc_env, cwd=cwd, stderr=subprocess.PIPE)
error = False
for line in proc.stderr:
sys.stderr.write(line)
if "== LEAK SUMMARY" in line:
error = True
retval = proc.wait()
if retval == 0 and error:
retval = 1
else:
try:
WindowsError
except NameError:
retval = subprocess.Popen(argv, env=proc_env, cwd=cwd).wait()
else:
try:
retval = subprocess.Popen(argv, env=proc_env, cwd=cwd).wait()
except WindowsError, ex:
raise WafError("Command %s raised exception %s" % (argv, ex))
if retval:
signame = None
if retval < 0:
import signal
for name, val in vars(signal).iteritems():
if len(name) > 3 and name[:3] == 'SIG' and name[3] != '_':
if val == -retval:
signame = name
break
if signame:
raise WafError("Command %s terminated with signal %s."
" Run it under a debugger to get more information "
"(./waf --run <program> --command-template=\"gdb --args %%s <args>\")." % (argv, signame))
else:
raise WafError("Command %s exited with code %i" % (argv, retval))
return retval
def get_run_program(program_string, command_template=None):
env = bld.env
if command_template in (None, '%s'):
argv = shlex.split(program_string)
program_name = argv[0]
try:
program_obj = find_program(program_name, env)
except ValueError, ex:
raise WafError(str(ex))
program_node = program_obj.path.find_or_declare(program_obj.target)
execvec = [program_node.abspath()] + argv[1:]
else:
program_name = program_string
try:
program_obj = find_program(program_name, env)
except ValueError, ex:
raise WafError(str(ex))
program_node = program_obj.path.find_or_declare(program_obj.target)
tmpl = command_template % (program_node.abspath(),)
execvec = shlex.split(tmpl.replace('\\', '\\\\'))
return program_name, execvec
def run_program(program_string, env, command_template=None, cwd=None, visualize=False):
dummy_program_name, execvec = get_run_program(program_string, command_template)
if cwd is None:
if (Options.options.cwd_launch):
cwd = Options.options.cwd_launch
else:
cwd = Options.cwd_launch
if visualize:
execvec.append("--SimulatorImplementationType=ns3::VisualSimulatorImpl")
return run_argv(execvec, env, cwd=cwd)
def run_python_program(program_string, env, visualize=False):
env = bld.env
execvec = shlex.split(program_string)
if (Options.options.cwd_launch):
cwd = Options.options.cwd_launch
else:
cwd = Options.cwd_launch
if visualize:
execvec.append("--SimulatorImplementationType=ns3::VisualSimulatorImpl")
return run_argv([env['PYTHON'][0]] + execvec, env, cwd=cwd)
def monkey_patch_Runner_start():
from waflib import Task
def start(self):
self.total = self.bld.total()
while not self.stop:
self.refill_task_list()
tsk = self.get_next_task()
if not tsk:
if self.count:
continue
else:
break
if tsk.hasrun:
self.processed += 1
continue
if self.stop:
break
try:
st = tsk.runnable_status()
except Exception:
self.processed += 1
if not self.stop and self.bld.keep:
tsk.hasrun = Task.SKIPPED
if self.bld.keep == 1:
self.stop = True
continue
tsk.err_msg = Utils.ex_stack()
tsk.hasrun = Task.EXCEPTION
self.error_handler(tsk)
continue
if st == Task.ASK_LATER:
self.postpone(tsk)
elif st == Task.SKIP_ME:
self.processed += 1
tsk.hasrun = Task.SKIPPED
self.add_more_tasks(tsk)
else:
tsk.position = (self.processed, self.total)
self.count += 1
tsk.master = self
self.processed += 1
if self.numjobs == 1:
tsk.process()
else:
self.add_task(tsk)
while self.error and self.count:
self.get_out()
assert (self.count == 0 or self.stop)
self.free_task_pool()
from waflib.Runner import Parallel
Parallel.start = start
import os
import re
entities = ['Ingredient','Amount','Unit','Recipe']
auto_tag_set = []
nonauto_tag_set = []
def init_dict(dictOfdict):
for e in entities:
if not (e in dictOfdict):
dictOfdict[e] = dict()
def get_xml_content(file_path):
f = open(file_path)
content = f.read()
content = pre_format(content)
return get_xml_entity(content)
def get_ann_content(file_path):
f = open(file_path)
content = f.read()
return get_ann_entity(content)
def process_files_in_dir(dir):
dir = os.path.dirname(os.path.realpath(__file__)) + ('/'+dir)
for root, dirs, files in os.walk(dir):
for file in sorted(files):
if(file.endswith('.xml')):
auto_tag_set.append(get_xml_content(os.path.join(root,file)))
if(file.endswith('.ann')):
nonauto_tag_set.append(get_ann_content(os.path.join(root,file)))
def get_ann_entity(content):
entity_dict = dict()
init_dict(entity_dict)
content = content.split('\n')
for line in content:
token = line.split('\t')
if("T" in token[0]):
tag_name = token[1].split(' ')[0]
if(token[2] in entity_dict[tag_name]):
entity_dict[tag_name][token[2]] += 1
else:
entity_dict[tag_name][token[2]] = 1
return entity_dict
def get_xml_entity(content):
entity_dict = dict()
init_dict(entity_dict)
for e in entities:
e_reg = re.compile('<'+e + '>(?P<'+e+'>[^<]+)</'+e+'>');
for i in e_reg.findall(content):
if(i in entity_dict[e]):
entity_dict[e][i] += 1
else:
entity_dict[e][i] = 1
return entity_dict
def pre_format(content):
content = re.sub("<entity type=\"(\w+)\">([^<]+)</entity>", "<\g<1>>\g<2></\g<1>>", content)
content = content.replace("<s>", "")
content = content.replace("</B-Ingredient> <I-Ingredient>", " ")
content = content.replace("</I-Ingredient> <I-Ingredient>", " ")
content = content.replace("</B-Recipe> <I-Recipe>", " ")
content = content.replace("</I-Recipe> <I-Recipe>", " ")
content = content.replace("</B-Amount> <I-Amount>", " ")
content = content.replace("</I-Amount> <I-Amount>", " ")
content = content.replace("</B-Unit> <I-Unit>", " ")
content = content.replace("</I-Unit> <I-Unit>", " ")
content = content.replace("</I-", "</")
content = content.replace("</B-", "</")
content = content.replace("<B-", "<")
content = content.replace("<I-", "<")
return content
def calc_diff_by_entity(nonauto_tag_set,auto_tag_set):
diff_matrix = dict()
init_dict(diff_matrix)
for key, value in diff_matrix.iteritems():
value['FP'] = 0
value['TP'] = 0
value['FN'] = 0
for article in zip(nonauto_tag_set,auto_tag_set):
for entity in entities:
for key, value in article[0][entity].iteritems():
if key in article[1][entity]:
if article[1][entity][key] - value > 0:
diff_matrix[entity]['FP'] += (article[1][entity][key] - value)
else:
diff_matrix[entity]['FN'] += (value - article[1][entity][key])
diff_matrix[entity]['TP'] += min(article[1][entity][key],value)
else:
diff_matrix[entity]['FN'] += value
for key, value in article[1][entity].iteritems():
if not key in article[0][entity]:
diff_matrix[entity]['FP'] += value
return diff_matrix
process_files_in_dir('tagged_data')
confusion_matrix = calc_diff_by_entity(nonauto_tag_set,auto_tag_set)
for key, value in confusion_matrix.iteritems():
if value['TP'] == 0:
precision = 0
recall = 0
f_measure = 0
else:
precision = 1.0 * value['TP'] / (value['TP'] + value['FP'])
recall = 1.0 * value['TP'] / (value['TP'] + value['FN'])
f_measure = 2.0 * (precision * recall)/(precision + recall)
print key+':\tPrecision-'+str("{0:.4f}".format(precision))+'\tRecall-'+str("{0:.4f}".format(recall))+'\tF-measure-'+str("{0:.4f}".format(f_measure))
MOD = 10 ** 9 + 7
BIT_CNT = 10 ** 5
SHIFT_CNT = 314159
N = BIT_CNT + SHIFT_CNT
class Solution(object):
def solve(self, cipher):
a, b = cipher
len_a = len(a)
len_b = len(b)
a_array = [0 for _ in xrange(N)]
b_array = [0 for _ in xrange(N)]
for ind, val in enumerate(a):
a_array[len_a - 1 - ind] = int(val)
for ind, val in enumerate(b):
b_array[len_b - 1 - ind] = int(val)
dp = [[0, 0] for _ in xrange(N + 1)]
for i in xrange(1, N + 1):
dp[i][0] = dp[i - 1][0] + 1 if b_array[i - 1] == 0 else dp[i - 1][0]
dp[i][1] = dp[i - 1][1] + 1 if b_array[i - 1] == 1 else dp[i - 1][1]
result = 0
sig = 1
for i in xrange(N):
if i < SHIFT_CNT:
cnt_zero = dp[i + 1][0] + SHIFT_CNT - i
cnt_one = dp[i + 1][1]
else:
cnt_zero = dp[len_b][0] - dp[i - SHIFT_CNT][0] + SHIFT_CNT
cnt_one = dp[len_b][1] - dp[i - SHIFT_CNT][1]
cur_bit_sum = (a_array[
i] ^ 0) * cnt_zero
cur_bit_sum += (a_array[i] ^ 1) * cnt_one
result = (result + sig * cur_bit_sum) % MOD
sig = (sig * 2) % MOD
return result
if __name__ == "__main__":
import sys
f = open("1.in", "r")
a = f.readline().strip()
b = f.readline().strip()
cipher = (a, b)
s = "%s\n" % (Solution().solve(cipher))
print s,
class Solution(object):
def solve(self, cipher):
length, lst = cipher
return reduce(lambda x, y: x | y, lst) * 2 ** (length - 1) % (10 ** 9 + 7)
if __name__ == "__main__":
import sys
f = open("1.in", "r")
testcases = int(f.readline().strip())
for t in xrange(testcases):
length = int(f.readline().strip())
lst = map(lambda x: int(x), f.readline().strip().split(" "))
cipher = [length, lst]
s = "%s\n" % (Solution().solve(cipher))
print s,
